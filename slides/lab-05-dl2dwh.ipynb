{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8667df4b",
   "metadata": {},
   "source": [
    "# From data lake to data warehouse\n",
    "\n",
    "Disclaimer:\n",
    "\n",
    "- Link to the [AWS academy login](https://awsacademy.instructure.com/login/canvas): https://awsacademy.instructure.com/login/canvas\n",
    "- At the end of the lab, *remember to Stop/Destroy the created services*. (Why?)\n",
    "- *Upload the Notebook to Sagemaker* (not to COLAB!)\n",
    "- The second part of the lab requires [Tableau Desktop](https://www.tableau.com/products/desktop/download) installed on your machine\n",
    "\n",
    "Known issues:\n",
    "\n",
    "- AWS classroom does not work on *Safari* and *Firefox*.\n",
    "    - Solution: use Google Chrome\n",
    "- Tableau Desktop had problems on *macOS* when connecting to Postgres.\n",
    "    - Solution: use the lab's computers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5256ac",
   "metadata": {},
   "source": [
    "# Data lake vs Data warehouse\n",
    "\n",
    "**Data warehouse** and **data lake** serve different needs and use cases.\n",
    "\n",
    "A *data lake* stores relational data from business applications, and non-relational data\n",
    "\n",
    "- The structure of the data or schema is not defined when data is captured (*schema on read*)\n",
    "- You can store all of your data without careful design or the need to know what questions you might need answers \n",
    "\n",
    "A *data warehouse* is a database optimized to analyze relational data coming from business applications\n",
    "\n",
    "- The data structure and schema are defined in advance to optimize for fast SQL queries (*schema on write*)\n",
    "- The results are typically used for operational reporting and analysis\n",
    "- Data is cleaned, enriched, and transformed so it can act as the single source of truth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a616d40",
   "metadata": {},
   "source": [
    "# Roadmap\n",
    "\n",
    "**Goal**: build a sub-module of a decision support system, namely a DWH to monitor historical trends of soil moisture\n",
    "\n",
    "Necessary steps:\n",
    "\n",
    "1. Create a data lake (AWS S3)\n",
    "2. Collect and store the sensor data (manually)\n",
    "   - KISS: we start with a .csv with sensor data\n",
    "3. Do ETL (AWS SageMaker)\n",
    "4. Build a (relational) data warehouse (AWS RDS)\n",
    "5. Query the data warehouse (Tableau)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78105037",
   "metadata": {},
   "source": [
    "# 1. Create a data lake\n",
    "\n",
    "Log in to the [AWS console](https://awsacademy.instructure.com/login/canvas)\n",
    "\n",
    ":::: {.columns}\n",
    "::: {.column width=40%}\n",
    "\n",
    "![Click on `Dashbord`](https://user-images.githubusercontent.com/18005592/200340672-756adacd-bad6-4aca-b7ca-8c03ff20d928.png)\n",
    "\n",
    ":::\n",
    "::: {.column width=40%}\n",
    "\n",
    "![Click on `Courses`](https://user-images.githubusercontent.com/18005592/200342442-edaa7560-95a2-47d1-b6b2-ccc4ae9abe0c.png)\n",
    "\n",
    ":::\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc19b5e",
   "metadata": {},
   "source": [
    "# Start the lab\n",
    "\n",
    "![Click on `Start Lab`](https://user-images.githubusercontent.com/18005592/200342733-326a05b7-9f6e-438f-9749-1322412d7321.png)\n",
    "\n",
    "When AWS is green, click on it\n",
    "\n",
    "![Click on `AWS`](https://user-images.githubusercontent.com/18005592/200343321-444d3d2b-3e95-4296-baaa-29cf10616736.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44aa5aae",
   "metadata": {},
   "source": [
    "# Welcome to the AWS Console!\n",
    "\n",
    "![AWS Console](https://user-images.githubusercontent.com/18005592/200344531-88e92bbb-c0c0-456e-a532-a116d8d330f4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1101baa",
   "metadata": {},
   "source": [
    "# Data Lake\n",
    "\n",
    "AWS Simple Storage Service (S3)\n",
    "\n",
    "- A serverless object storage service offering industry-leading scalability, data availability, security, and performance. \n",
    "- Customers of all sizes and industries can store and protect any amount of data for virtually any use case, such as data lakes\n",
    "\n",
    "Create two buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a9ade0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_bucket = \"s3://landing-raw-wateringsensors-1234/\"\n",
    "output_bucket = \"s3://staging-clean-wateringsensors-12345/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f894ac84",
   "metadata": {},
   "source": [
    ":::: {.columns}\n",
    "::: {.column width=50%}\n",
    "\n",
    "![](https://user-images.githubusercontent.com/18005592/200345832-d3522fdb-92ee-4457-8a78-5c0449af6bc4.png)\n",
    "\n",
    ":::\n",
    "::: {.column width=50%}\n",
    "\n",
    "![](https://user-images.githubusercontent.com/18005592/200346937-410c49dc-6685-447c-9b18-4970f1954e6c.png)\n",
    "\n",
    ":::\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560b2ee5",
   "metadata": {},
   "source": [
    "# 2. Collect and store the sensor data (manually)\n",
    "\n",
    "KISS: we start with a .csv with sensor data\n",
    "\n",
    "- [http://big.csr.unibo.it/projects/nosql-datasets/watering-data-1661269649253.csv](http://big.csr.unibo.it/projects/nosql-datasets/watering-data-1661269649253.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5eb53e",
   "metadata": {},
   "source": [
    "# 3. Do ETL\n",
    "\n",
    "We need a working environment: Amazon SageMaker\n",
    "\n",
    "- Fully managed service that provides machine learning (ML) capabilities for data scientists and developers to prepare, build, train, and deploy high-quality ML models efficiently\n",
    "\n",
    "![SageMaker](https://user-images.githubusercontent.com/18005592/200364098-6390f3a4-e1cf-4041-9d88-ab425ed9933b.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3baaeb56",
   "metadata": {},
   "source": [
    "# Creating a notebook instance\n",
    "\n",
    ":::: {.columns}\n",
    "::: {.column width=50%}\n",
    "\n",
    "![Create a notebook instance](https://user-images.githubusercontent.com/18005592/200364480-53d6fe54-aac6-431c-a664-87712f82d2cf.png)\n",
    "\n",
    ":::\n",
    "::: {.column width=50%}\n",
    "\n",
    "![When ready, Open Jupyter](https://user-images.githubusercontent.com/18005592/200364714-37992354-a047-440e-bfe3-12df1e1264ad.png)\n",
    "\n",
    ":::\n",
    "::::\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b089bb",
   "metadata": {},
   "source": [
    "# Upload the notebook\n",
    "\n",
    "![Upload the notebook](https://user-images.githubusercontent.com/18005592/200364905-e6b7f5b6-ee52-4e8e-9df3-b2e8b9b5afb0.png)\n",
    "\n",
    "![Set the kernel](https://user-images.githubusercontent.com/18005592/200365269-0b85f661-a0c8-4902-9c93-eb978b5226bd.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cc5d68",
   "metadata": {},
   "source": [
    "# Hands on!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cfa5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install awswrangler==3.4.2\n",
    "!pip install pandas==2.1.2\n",
    "!pip install scikit-learn==1.3.0\n",
    "!pip install seaborn==0.12.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca0e463",
   "metadata": {},
   "outputs": [],
   "source": [
    "import awswrangler as wr\n",
    "import pandas as pd\n",
    "file_name = \"watering-data-1661269649253.csv\"  # name of the dataset\n",
    "df = pd.read_csv(\"http://big.csr.unibo.it/projects/nosql-datasets/\" + file_name)  # import the dataset from unibo's server\n",
    "wr.s3.to_csv(df, path=input_bucket + file_name)  # write it to the data lake"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183d1eb2",
   "metadata": {},
   "source": [
    "# 3. Do ETL (AWS SageMaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682cf9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input_bucket + file_name)\n",
    "df = wr.s3.read_csv(input_bucket + file_name)  # import the data\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edeaf727",
   "metadata": {},
   "source": [
    "Data understanding\n",
    "\n",
    "- `plantRow`: name of the field in which we have the sensors\n",
    "- `detectedValueTypeId`: type of the sensor data\n",
    "- `xx`, `yy`, and `zz`: displacement of the sensor with respect to the dripper\n",
    "- `value`: measurement\n",
    "- `unit`: unit of measurement\n",
    "- `timestamp`: when the measurement has been recorded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38910ff0",
   "metadata": {},
   "source": [
    "# Data profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5537bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b514e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcfc360",
   "metadata": {},
   "source": [
    "# Data distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9731dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot(df, cols = 5):\n",
    "    rows = math.ceil(len(df.columns) / cols)\n",
    "    fig, axs = fig, ax = plt.subplots(rows, cols, figsize = (3 * cols, 2 * rows))\n",
    "    for i, x in enumerate(df.columns):\n",
    "        ax = axs[int(i / cols)][i % cols]\n",
    "        df[x].hist(ax=ax)\n",
    "        ax.set_title(x)\n",
    "    fig.tight_layout()\n",
    "plot(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53462b02",
   "metadata": {},
   "source": [
    "#\n",
    "\n",
    "The `zz` column contains missing values and a single non-null value (`0`), what should we do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f143cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"zz\" in df.columns:\n",
    "    df = df.drop(columns=[\"zz\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd5ad61",
   "metadata": {},
   "source": [
    "#\n",
    "\n",
    "- Do we need to store the `plantRow`?\n",
    "- Do the sensors from the same `detectedValueTypeId` share the same `unit`?\n",
    "- Do we care about all the sensor types (i.e., `detectedValueTypeId`)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce01db2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"detectedValueTypeId\"]).nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d7ca2b",
   "metadata": {},
   "source": [
    "#\n",
    "\n",
    "Drop the \"useless\" columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5a859a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What should we drop?\n",
    "# df = df.drop([\"plantRow\", \"unit\"], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e5cdcf",
   "metadata": {},
   "source": [
    "# \n",
    "\n",
    "Drop the useless rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17325843",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"detectedValueTypeId\"] == \"GRND_WATER_G\"]\n",
    "df = df.drop([\"detectedValueTypeId\"], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3a2a27",
   "metadata": {},
   "source": [
    "Take a better look at the sensor data over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e14700da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot():\n",
    "    fig, ax = plt.subplots(figsize=(4,3))\n",
    "    for key, grp in df.sort_values(by=[\"timestamp\"]).groupby(['xx', 'yy']):\n",
    "        ax = grp.plot(ax=ax, kind='line', x='timestamp', y='value', label=key)\n",
    "\n",
    "    ax.set_xticklabels([pd.to_datetime(tm, unit='s').strftime('%Y-%m-%d %H:%M:%S') for tm in ax.get_xticks()], rotation = 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22743fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e73331",
   "metadata": {},
   "source": [
    "#\n",
    "\n",
    "Snapshots of sensor data at different timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1233bc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot():\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(12, 3), sharey=True)\n",
    "    for i, timestamp in enumerate([1628950550, 1626309949, 1627101007]):\n",
    "        df[df[\"timestamp\"] == timestamp].plot.scatter(ax=ax[i], x='xx', y='yy', c='value', cmap='seismic_r', s=100, title=pd.to_datetime(timestamp, unit='s').strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    fig.tight_layout()\n",
    "plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1310deb8",
   "metadata": {},
   "source": [
    "What if we bin our data hourly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e5fd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot():\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(12, 3), sharey=True)\n",
    "    for i, timestamp in enumerate([1628950550, 1626309949, 1627101007]):\n",
    "        df[df[\"timestamp\"].apply(lambda x: int(x / (60 * 60))) == int(timestamp / (60 * 60))].plot.scatter(ax=ax[i], x='xx', y='yy', c='value', cmap='seismic_r', s=100, title=pd.to_datetime(int(timestamp / (60 * 60)) * 60 * 60, unit='s').strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    fig.tight_layout()\n",
    "plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5551952",
   "metadata": {},
   "source": [
    "# Data preparation\n",
    "\n",
    "- Bin data hourly, average the soil moisture for each sensor \n",
    "- Create derived attributes (e.g., time/sensor hierarchy) useful for posterior analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e7162d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"timestamp\"] = df[\"timestamp\"].apply(lambda x: int(x / 3600) * 3600)  # bin the time by hours\n",
    "df1 = df.groupby([\"plantRow\", \"timestamp\", \"xx\", \"yy\"])[\"value\"].mean().reset_index()  # compute the average humidity\n",
    "df1[\"hour\"] = [pd.to_datetime(tm, unit='s').strftime('%Y-%m-%d %H') for tm in df1[\"timestamp\"]]  # format the hour\n",
    "df1[\"date\"] = [pd.to_datetime(tm, unit='s').strftime('%Y-%m-%d') for tm in df1[\"timestamp\"]]  # format the date\n",
    "df1[\"month\"] = [pd.to_datetime(tm, unit='s').strftime('%Y-%m') for tm in df1[\"timestamp\"]]  # format the month\n",
    "df1[\"year\"] = [pd.to_datetime(tm, unit='s').strftime('%Y') for tm in df1[\"timestamp\"]]  # format the year\n",
    "df1[\"timestamp\"] = [pd.to_datetime(tm, unit='s').strftime('%Y-%m-%d %H:%M:%S') for tm in df1[\"timestamp\"]]  # format the timestamp\n",
    "\n",
    "df2 = df1.copy(deep=True)\n",
    "df2[\"sensor\"] = df2.apply(lambda x: \"(\" + str(x[\"xx\"]) + \", \" + str(x[\"yy\"]) + \")\", axis=1)\n",
    "df2 = df2.rename({\"xx\": \"dist\", \"yy\": \"depth\", \"plantRow\": \"plant\"}, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d97ee8",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26dbd46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54338cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8156650b",
   "metadata": {},
   "source": [
    "Finally, save the data back to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "830e03b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wr.s3.to_csv(df=df1, path=output_bucket + \"cleaned-v1-\" + file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba51608f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wr.s3.to_csv(df=df2, path=output_bucket + \"cleaned-v2-\" + file_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a989db87",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e031b8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "databases = wr.catalog.databases()\n",
    "databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcb84de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tables = wr.catalog.tables()\n",
    "df_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eabf9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = df2[[\"sensor\", \"value\", \"timestamp\"]].pivot(index='timestamp', columns='sensor')\n",
    "pdf.columns = pdf.columns.droplevel(0)\n",
    "pdf = pdf.reset_index().rename_axis(None, axis=1)\n",
    "pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cf21eee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# sns.pairplot(pdf)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "96f4739a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wr.s3.to_csv(df=pdf, path=output_bucket + \"/pivot.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91a76cf",
   "metadata": {},
   "source": [
    "# 4. Build a (relational) data warehouse (AWS RDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930523a3",
   "metadata": {},
   "source": [
    "Amazon Relational Database Service (Amazon RDS) \n",
    "- A collection of managed services that makes it simple to set up, operate, and scale relational databases in the cloud\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6412a5e",
   "metadata": {},
   "source": [
    "![image](https://user-images.githubusercontent.com/18005592/200369753-f6d9e73e-6d7f-4d4b-bad6-311528e51629.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbdcce4b",
   "metadata": {},
   "source": [
    "# Create a database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b63f0c",
   "metadata": {},
   "source": [
    "![image](https://github.com/w4bo/welaser/assets/18005592/ec3cdca6-548f-4370-95ca-107fcbb215ed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552bd301",
   "metadata": {},
   "source": [
    "# Create a database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1960e26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd = \"bigdata2023\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea232279",
   "metadata": {},
   "source": [
    "![image](https://user-images.githubusercontent.com/18005592/200370529-ae695d6f-9629-49bb-ae13-a4f5caeb9a0d.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b836384",
   "metadata": {},
   "source": [
    "# Create a database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572224dd",
   "metadata": {},
   "source": [
    "![image](https://user-images.githubusercontent.com/18005592/200373378-f257ef56-aea9-4eb3-a922-2a4a3b2a1d11.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209efb52",
   "metadata": {},
   "source": [
    "# Create a database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e93804",
   "metadata": {},
   "source": [
    "By default, even if you have set \"Public accessibility\" to \"Yes\", the \"Security Group\" is still not allowing external connections yet.\n",
    "\n",
    "- Virtual private clouds (VPC): a VPC is a virtual network that closely resembles a traditional network that you'd operate in your own data center\n",
    "- A security group acts as a virtual firewall for your AWS instances to control incoming/outgoing traffic\n",
    "    - When you launch an instance, you can specify one or more security groups\n",
    "    - If you don't specify a security group, Amazon EC2 uses the default security group\n",
    "- Your AWS account automatically has a default security group for the default VPC in each Region"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9803caf2",
   "metadata": {},
   "source": [
    "# Create a database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdc3924",
   "metadata": {},
   "source": [
    "From [Default security groups (2022-11-15)](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/default-custom-security-groups.html#default-security-group)\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/18005592/201981163-0bd75761-be85-41ea-aaf9-6af66e3e41ac.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d357218f",
   "metadata": {},
   "source": [
    "# Create a database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75917a5b",
   "metadata": {},
   "source": [
    "You can add or remove inbound and outbound rules for any default security group.\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/18005592/201690868-abdd53f7-c6b5-48d4-89ce-e9f6f374a8ce.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa54142",
   "metadata": {},
   "source": [
    "# Create a database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94450a7",
   "metadata": {},
   "source": [
    "![image](https://user-images.githubusercontent.com/18005592/201691253-db130df8-c31a-4c6f-aa69-34cf4d89f0e2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baebcf99",
   "metadata": {},
   "source": [
    "# Create a database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f05dc6",
   "metadata": {},
   "source": [
    "![image](https://user-images.githubusercontent.com/18005592/201691398-a16f467e-c6cd-4dd9-8fc3-f31b45740ec4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf8b221",
   "metadata": {},
   "source": [
    "# Create a database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457b3bbb",
   "metadata": {},
   "source": [
    "What is the schema of our dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47629a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a727234",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = wr.s3.read_csv(output_bucket + \"cleaned-v2-\" + file_name)\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55ad925",
   "metadata": {},
   "source": [
    "- Is this schema normalized?\n",
    "- Is this the schema you are used to when building DWH?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8921cba",
   "metadata": {},
   "source": [
    "# Creating the DWH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6814e4f1",
   "metadata": {},
   "source": [
    "We need to distinguish the fact and the dimension tables:\n",
    "\n",
    "- FT: Measurement\n",
    "- DT1: Time\n",
    "- DT2: Sensor\n",
    "\n",
    "How?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a89b087",
   "metadata": {},
   "source": [
    "# DT Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297a2de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_time = raw_data[[\"timestamp\", \"date\", \"month\", \"year\"]].drop_duplicates()\n",
    "dt_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3550c47",
   "metadata": {},
   "source": [
    "# DT Sensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e210c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_sensor = raw_data[[\"sensor\", \"dist\", \"depth\", \"plant\"]].drop_duplicates()\n",
    "dt_sensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29751832",
   "metadata": {},
   "source": [
    "# FT measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafff377",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_mea = raw_data[[\"sensor\", \"timestamp\", \"value\"]].drop_duplicates()\n",
    "ft_mea"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f06745a",
   "metadata": {},
   "source": [
    "# \n",
    "\n",
    "We need to connect to the database..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf5b71e",
   "metadata": {},
   "source": [
    "![image](https://user-images.githubusercontent.com/18005592/200372868-4881edde-4f7f-4024-8ffb-cc3836d1a367.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fa271c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "host = \"sensor-dwh1.crxqb7bplkfq.us-east-1.rds.amazonaws.com\"\n",
    "port = 5432\n",
    "user = \"postgres\"\n",
    "db = \"postgres\"\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "s = 'postgresql://{}:{}@{}:{}/{}'.format(user, pwd, host, str(port), db)\n",
    "engine = create_engine(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2484e21",
   "metadata": {},
   "source": [
    "#\n",
    "\n",
    "... and just write the tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5798247",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_sensor.to_sql('sensor', engine, index=False, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab5d16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_time.to_sql('date', engine, index=False, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a8a014",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_mea.to_sql('measurement', engine, index=False, if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882485a6",
   "metadata": {},
   "source": [
    "## 5. Query the data warehouse (Tableau)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee1ba93",
   "metadata": {},
   "source": [
    "![image](https://user-images.githubusercontent.com/18005592/200375443-c023c9f7-6df4-4717-91a6-4d9ea230eaea.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57002c8c",
   "metadata": {},
   "source": [
    "Tasks\n",
    "\n",
    "1. Build the hierarchies by following the functional dependencies\n",
    "2. Plot the average soil moisture (`avg(value)`) by `sensor` and `date`. Is soil moisture behaving as expected for all sensors?\n",
    "3. Plot the standard deviation of the soil moisture for every sensor. What can you tell from this visualization?"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
