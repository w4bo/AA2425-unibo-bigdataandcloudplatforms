<!DOCTYPE html>
<html lang="en"><head>
<script src="slides_files/libs/quarto-html/tabby.min.js"></script>
<script src="slides_files/libs/quarto-html/popper.min.js"></script>
<script src="slides_files/libs/quarto-html/tippy.umd.min.js"></script>
<link href="slides_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="slides_files/libs/quarto-html/light-border.css" rel="stylesheet">
<link href="slides_files/libs/quarto-html/quarto-html.min.css" rel="stylesheet" data-mode="light">
<link href="slides_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.4.549">

  <meta name="author" content="Matteo Francia   DISI — University of Bologna   m.francia@unibo.it">
  <title>Big Data and Cloud Platforms (Module 2)</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="slides_files/libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="slides_files/libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
  </style>
  <link rel="stylesheet" href="slides_files/libs/revealjs/dist/theme/quarto.css">
  <link href="slides_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="slides_files/libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="slides_files/libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="slides_files/libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">

  .callout {
    margin-top: 1em;
    margin-bottom: 1em;  
    border-radius: .25rem;
  }

  .callout.callout-style-simple { 
    padding: 0em 0.5em;
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
    display: flex;
  }

  .callout.callout-style-default {
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
  }

  .callout .callout-body-container {
    flex-grow: 1;
  }

  .callout.callout-style-simple .callout-body {
    font-size: 1rem;
    font-weight: 400;
  }

  .callout.callout-style-default .callout-body {
    font-size: 0.9rem;
    font-weight: 400;
  }

  .callout.callout-titled.callout-style-simple .callout-body {
    margin-top: 0.2em;
  }

  .callout:not(.callout-titled) .callout-body {
      display: flex;
  }

  .callout:not(.no-icon).callout-titled.callout-style-simple .callout-content {
    padding-left: 1.6em;
  }

  .callout.callout-titled .callout-header {
    padding-top: 0.2em;
    margin-bottom: -0.2em;
  }

  .callout.callout-titled .callout-title  p {
    margin-top: 0.5em;
    margin-bottom: 0.5em;
  }
    
  .callout.callout-titled.callout-style-simple .callout-content  p {
    margin-top: 0;
  }

  .callout.callout-titled.callout-style-default .callout-content  p {
    margin-top: 0.7em;
  }

  .callout.callout-style-simple div.callout-title {
    border-bottom: none;
    font-size: .9rem;
    font-weight: 600;
    opacity: 75%;
  }

  .callout.callout-style-default  div.callout-title {
    border-bottom: none;
    font-weight: 600;
    opacity: 85%;
    font-size: 0.9rem;
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-default div.callout-content {
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-simple .callout-icon::before {
    height: 1rem;
    width: 1rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 1rem 1rem;
  }

  .callout.callout-style-default .callout-icon::before {
    height: 0.9rem;
    width: 0.9rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 0.9rem 0.9rem;
  }

  .callout-title {
    display: flex
  }
    
  .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  .callout.no-icon::before {
    display: none !important;
  }

  .callout.callout-titled .callout-body > .callout-content > :last-child {
    padding-bottom: 0.5rem;
    margin-bottom: 0;
  }

  .callout.callout-titled .callout-icon::before {
    margin-top: .5rem;
    padding-right: .5rem;
  }

  .callout:not(.callout-titled) .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  /* Callout Types */

  div.callout-note {
    border-left-color: #4582ec !important;
  }

  div.callout-note .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEU0lEQVRYCcVXTWhcVRQ+586kSUMMxkyaElstCto2SIhitS5Ek8xUKV2poatCcVHtUlFQk8mbaaziwpWgglJwVaquitBOfhQXFlqlzSJpFSpIYyXNjBNiTCck7x2/8/LeNDOZxDuEkgOXe++553zfefee+/OYLOXFk3+1LLrRdiO81yNqZ6K9cG0P3MeFaMIQjXssE8Z1JzLO9ls20MBZX7oG8w9GxB0goaPrW5aNMp1yOZIa7Wv6o2ykpLtmAPs/vrG14Z+6d4jpbSKuhdcSyq9wGMPXjonwmESXrriLzFGOdDBLB8Y6MNYBu0dRokSygMA/mrun8MGFN3behm6VVAwg4WR3i6FvYK1T7MHo9BK7ydH+1uurECoouk5MPRyVSBrBHMYwVobG2aOXM07sWrn5qgB60rc6mcwIDJtQrnrEr44kmy+UO9r0u9O5/YbkS9juQckLed3DyW2XV/qWBBB3ptvI8EUY3I9p/67OW+g967TNr3Sotn3IuVlfMLVnsBwH4fsnebJvyGm5GeIUA3jljERmrv49SizPYuq+z7c2H/jlGC+Ghhupn/hcapqmcudB9jwJ/3jvnvu6vu5lVzF1fXyZuZZ7U8nRmVzytvT+H3kilYvH09mLWrQdwFSsFEsxFVs5fK7A0g8gMZjbif4ACpKbjv7gNGaD8bUrlk8x+KRflttr22JEMRUbTUwwDQScyzPgedQHZT0xnx7ujw2jfVfExwYHwOsDTjLdJ2ebmeQIlJ7neo41s/DrsL3kl+W2lWvAga0tR3zueGr6GL78M3ifH0rGXrBC2aAR8uYcIA5gwV8zIE8onoh8u0Fca/ciF7j1uOzEnqcIm59sEXoGc0+z6+H45V1CvAvHcD7THztu669cnp+L0okAeIc6zjbM/24LgGM1gZk7jnRu1aQWoU9sfUOuhrmtaPIO3YY1KLLWZaEO5TKUbMY5zx8W9UJ6elpLwKXbsaZ4EFl7B4bMtDv0iRipKoDQT2sNQI9b1utXFdYisi+wzZ/ri/1m7QfDgEuvgUUEIJPq3DhX/5DWNqIXDOweC2wvIR90Oq3lDpdMIgD2r0dXvGdsEW5H6x6HLRJYU7C69VefO1x8Gde1ZFSJLfWS1jbCnhtOPxmpfv2LXOA2Xk2tvnwKKPFuZ/oRmwBwqRQDcKNeVQkYcOjtWVBuM/JuYw5b6isojIkYxyYAFn5K7ZBF10fea52y8QltAg6jnMqNHFBmGkQ1j+U43HMi2xMar1Nv0zGsf1s8nUsmUtPOOrbFIR8bHFDMB5zL13Gmr/kGlCkUzedTzzmzsaJXhYawnA3UmARpiYj5ooJZiUoxFRtK3X6pgNPv+IZVPcnwbOl6f+aBaO1CNvPW9n9LmCp01nuSaTRF2YxHqZ8DYQT6WsXT+RD6eUztwYLZ8rM+rcPxamv1VQzFUkzFXvkiVrySGQgJNvXHJAxiU3/NwiC03rSf05VBaPtu/Z7/B8Yn/w7eguloAAAAAElFTkSuQmCC');
  }

  div.callout-note.callout-style-default .callout-title {
    background-color: #dae6fb
  }

  div.callout-important {
    border-left-color: #d9534f !important;
  }

  div.callout-important .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEKklEQVRYCcVXTWhcVRS+575MJym48A+hSRFr00ySRQhURRfd2HYjk2SSTokuBCkU2o0LoSKKraKIBTcuFCoidGFD08nkBzdREbpQ1EDNIv8qSGMFUboImMSZd4/f9zJv8ibJMC8xJQfO3HPPPef7zrvvvnvviIkpC9nsw0UttFunbUhpFzFtarSd6WJkStVMw5xyVqYTvkwfzuf/5FgtkVoB0729j1rjXwThS7Vio+Mo6DNnvLfahoZ+i/o32lULuJ3NNiz7q6+pyAUkJaFF6JwaM2lUJlV0MlnQn5aTRbEu0SEqHUa0A4AdiGuB1kFXRfVyg5d87+Dg4DL6m2TLAub60ilj7A1Ec4odSAc8X95sHh7+ZRPCFo6Fnp7HfU/fBng/hi10CjCnWnJjsxvDNxWw0NfV6Rv5GgP3I3jGWXumdTD/3cbEOP2ZbOZp69yniG3FQ9z1jD7bnBu9Fc2tKGC2q+uAJOQHBDRiZX1x36o7fWBs7J9ownbtO+n0/qWkvW7UPIfc37WgT6ZGR++EOJyeQDSb9UB+DZ1G6DdLDzyS+b/kBCYGsYgJbSQHuThGKRcw5xdeQf8YdNHsc6ePXrlSYMBuSIAFTGAtQo+VuALo4BX83N190NWZWbynBjhOHsmNfFWLeL6v+ynsA58zDvvAC8j5PkbOcXCMg2PZFk3q8MjI7WAG/Dp9AwP7jdGBOOQkAvlFUB+irtm16I1Zw9YBcpGTGXYmk3kQIC/Cds55l+iMI3jqhjAuaoe+am2Jw5GT3Nbz3CkE12NavmzN5+erJW7046n/CH1RO/RVa8lBLozXk9uqykkGAyRXLWlLv5jyp4RFsG5vGVzpDLnIjTWgnRy2Rr+tDKvRc7Y8AyZq10jj8DqXdnIRNtFZb+t/ZRtXcDiVnzpqx8mPcDWxgARUqx0W1QB9MeUZiNrV4qP+Ehc+BpNgATsTX8ozYKL2NtFYAHc84fG7ndxUPr+AR/iQSns7uSUufAymwDOb2+NjK27lEFocm/EE2WpyIy/Hi66MWuMKJn8RvxIcj87IM5Vh9663ziW36kR0HNenXuxmfaD8JC7tfKbrhFr7LiZCrMjrzTeGx+PmkosrkNzW94ObzwocJ7A1HokLolY+AvkTiD/q1H0cN48c5EL8Crkttsa/AXQVDmutfyku0E7jShx49XqV3MFK8IryDhYVbj7Sj2P2eBxwcXoe8T8idsKKPRcnZw1b+slFTubwUwhktrfnAt7J++jwQtLZcm3sr9LQrjRzz6cfMv9aLvgmnAGvpoaGLxM4mAEaLV7iAzQ3oU0IvD5x9ix3yF2RAAuYAOO2f7PEFWCXZ4C9Pb2UsgDeVnFSpbFK7/IWu7TPTvBqzbGdCHOJQSxiEjt6IyZmxQyEJHv6xyQsYk//moVFsN2zP6fRImjfq7/n/wFDguUQFNEwugAAAABJRU5ErkJggg==');
  }

  div.callout-important.callout-style-default .callout-title {
    background-color: #f7dddc
  }

  div.callout-warning {
    border-left-color: #f0ad4e !important;
  }

  div.callout-warning .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAETklEQVRYCeVWW2gcVRg+58yaTUnizqbipZeX4uWhBEniBaoUX1Ioze52t7sRq6APio9V9MEaoWlVsFasRq0gltaAPuxms8lu0gcviE/FFOstVbSIxgcv6SU7EZqmdc7v9+9mJtNks51NTUH84ed889/PP+cmxP+d5FIbMJmNbpREu4WUkiTtCicKny0l1pIKmBzovF2S+hIJHX8iEu3hZJ5lNZGqyRrGSIQpq15AzF28jgpeY6yk6GVdrfFqdrD6Iw+QlB8g0YS2g7dyQmXM/IDhBhT0UCiRf59lfqmmDvzRt6kByV/m4JjtzuaujMUM2c5Z2d6JdKrRb3K2q6mA+oYVz8JnDdKPmmNthzkAk/lN63sYPgevrguc72aZX/L9C6x09GYyxBgCX4NlvyGUHOKELlm5rXeR1kchuChJt4SSwyddZRXgvwMGvYo4QSlk3/zkHD8UHxwVJA6zjZZqP8v8kK8OWLnIZtLyCAJagYC4rTGW/9Pqj92N/c+LUaAj27movwbi19tk/whRCIE7Q9vyI6yvRpftAKVTdUjOW40X3h5OXsKCdmFcx0xlLJoSuQngnrJe7Kcjm4OMq9FlC7CMmScQANuNvjfP3PjGXDBaUQmbp296S5L4DrpbrHN1T87ZVEZVCzg1FF0Ft+dKrlLukI+/c9ENo+TvlTDbYFvuKPtQ9+l052rXrgKoWkDAFnvh0wTOmYn8R5f4k/jN/fZiCM1tQx9jQQ4ANhqG4hiL0qIFTGViG9DKB7GYzgubnpofgYRwO+DFjh0Zin2m4b/97EDkXkc+f6xYAPX0KK2I/7fUQuwzuwo/L3AkcjugPNixC8cHf0FyPjWlItmLxWw4Ou9YsQCr5fijMGoD/zpdRy95HRysyXA74MWOnscpO4j2y3HAVisw85hX5+AFBRSHt4ShfLFkIMXTqyKFc46xdzQM6XbAi702a7sy04J0+feReMFKp5q9esYLCqAZYw/k14E/xcLLsFElaornTuJB0svMuJINy8xkIYuL+xPAlWRceH6+HX7THJ0djLUom46zREu7tTkxwmf/FdOZ/sh6Q8qvEAiHpm4PJ4a/doJe0gH1t+aHRgCzOvBvJedEK5OFE5jpm4AGP2a8Dxe3gGJ/pAutug9Gp6he92CsSsWBaEcxGx0FHytmIpuqGkOpldqNYQK8cSoXvd+xLxXADw0kf6UkJNFtdo5MOgaLjiQOQHcn+A6h5NuL2s0qsC2LOM75PcF3yr5STuBSAcGG+meA14K/CI21HcS4LBT6tv0QAh8Dr5l93AhZzG5ZJ4VxAqdZUEl9z7WJ4aN+svMvwHHL21UKTd1mqvChH7/Za5xzXBBKrUcB0TQ+Ulgkfbi/H/YT5EptrGzsEK7tR1B7ln9BBwckYfMiuSqklSznIuoIIOM42MQO+QnduCoFCI0bpkzjCjddHPN/F+2Yu+sd9bKNpVwHhbS3LluK/0zgfwD0xYI5dXuzlQAAAABJRU5ErkJggg==');
  }

  div.callout-warning.callout-style-default .callout-title {
    background-color: #fcefdc
  }

  div.callout-tip {
    border-left-color: #02b875 !important;
  }

  div.callout-tip .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAADr0lEQVRYCe1XTWgTQRj9ZjZV8a9SPIkKgj8I1bMHsUWrqYLVg4Ue6v9BwZOxSYsIerFao7UiUryIqJcqgtpimhbBXoSCVxUFe9CTiogUrUp2Pt+3aUI2u5vdNh4dmMzOzHvvezuz8xNFM0mjnbXaNu1MvFWRXkXEyE6aYOYJpdW4IXuA4r0fo8qqSMDBU0v1HJUgVieAXxzCsdE/YJTdFcVIZQNMyhruOMJKXYFoLfIfIvVIMWdsrd+Rpd86ZmyzzjJmLStqRn0v8lzkb4rVIXvnpScOJuAn2ACC65FkPzEdEy4TPWRLJ2h7z4cArXzzaOdKlbOvKKX25Wl00jSnrwVxAg3o4dRxhO13RBSdNvH0xSARv3adTXbBdTf64IWO2vH0LT+cv4GR1DJt+DUItaQogeBX/chhbTBxEiZ6gftlDNXTrvT7co4ub5A6gp9HIcHvzTa46OS5fBeP87Qm0fQkr4FsYgVQ7Qg+ZayaDg9jhg1GkWj8RG6lkeSacrrHgDaxdoBiZPg+NXV/KifMuB6//JmYH4CntVEHy/keA6x4h4CU5oFy8GzrBS18cLJMXcljAKB6INjWsRcuZBWVaS3GDrqB7rdapVIeA+isQ57Eev9eCqzqOa81CY05VLd6SamW2wA2H3SiTbnbSxmzfp7WtKZkqy4mdyAlGx7ennghYf8voqp9cLSgKdqNfa6RdRsAAkPwRuJZNbpByn+RrJi1RXTwdi8RQF6ymDwGMAtZ6TVE+4uoKh+MYkcLsT0Hk8eAienbiGdjJHZTpmNjlbFJNKDVAp2fJlYju6IreQxQ08UJDNYdoLSl6AadO+fFuCQqVMB1NJwPm69T04Wv5WhfcWyfXQB+wXRs1pt+nCknRa0LVzSA/2B+a9+zQJadb7IyyV24YAxKp2Jqs3emZTuNnKxsah+uabKbMk7CbTgJx/zIgQYErIeTKRQ9yD9wxVof5YolPHqaWo7TD6tJlh7jQnK5z2n3+fGdggIOx2kaa2YI9QWarc5Ce1ipNWMKeSG4DysFF52KBmTNMmn5HqCFkwy34rDg05gDwgH3bBi+sgFhN/e8QvRn8kbamCOhgrZ9GJhFDgfcMHzFb6BAtjKpFhzTjwv1KCVuxHvCbsSiEz4CANnj84cwHdFXAbAOJ4LTSAawGWFn5tDhLMYz6nWeU2wJfIhmIJBefcd/A5FWQWGgrWzyORZ3Q6HuV+Jf0Bj+BTX69fm1zWgK7By1YTXchFDORywnfQ7GpzOo6S+qECrsx2ifVQAAAABJRU5ErkJggg==');
  }

  div.callout-tip.callout-style-default .callout-title {
    background-color: #ccf1e3
  }

  div.callout-caution {
    border-left-color: #fd7e14 !important;
  }

  div.callout-caution .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAACV0lEQVRYCdVWzWoUQRCuqp2ICBLJXgITZL1EfQDBW/bkzUMUD7klD+ATSHBEfAIfQO+iXsWDxJsHL96EHAwhgzlkg8nBg25XWb0zIb0zs9muYYWkoKeru+vn664fBqElyZNuyh167NXJ8Ut8McjbmEraKHkd7uAnAFku+VWdb3reSmRV8PKSLfZ0Gjn3a6Xlcq9YGb6tADjn+lUfTXtVmaZ1KwBIvFI11rRXlWlatwIAAv2asaa9mlB9wwygiDX26qaw1yYPzFXg2N1GgG0FMF8Oj+VIx7E/03lHx8UhvYyNZLN7BwSPgekXXLribw7w5/c8EF+DBK5idvDVYtEEwMeYefjjLAdEyQ3M9nfOkgnPTEkYU+sxMq0BxNR6jExrAI31H1rzvLEfRIdgcv1XEdj6QTQAS2wtstEALLG1yEZ3QhH6oDX7ExBSFEkFINXH98NTrme5IOaaA7kIfiu2L8A3qhH9zRbukdCqdsA98TdElyeMe5BI8Rs2xHRIsoTSSVFfCFCWGPn9XHb4cdobRIWABNf0add9jakDjQJpJ1bTXOJXnnRXHRf+dNL1ZV1MBRCXhMbaHqGI1JkKIL7+i8uffuP6wVQAzO7+qVEbF6NbS0LJureYcWXUUhH66nLR5rYmva+2tjRFtojkM2aD76HEGAD3tPtKM309FJg5j/K682ywcWJ3PASCcycH/22u+Bh7Aa0ehM2Fu4z0SAE81HF9RkB21c5bEn4Dzw+/qNOyXr3DCTQDMBOdhi4nAgiFDGCinIa2owCEChUwD8qzd03PG+qdW/4fDzjUMcE1ZpIAAAAASUVORK5CYII=');
  }

  div.callout-caution.callout-style-default .callout-title {
    background-color: #ffe5d0
  }

  </style>
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">Big Data and Cloud Platforms (Module 2)</h1>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Matteo Francia <br> DISI — University of Bologna <br> m.francia@unibo.it 
</div>
</div>
</div>

</section>
<section id="hi" class="title-slide slide level1 center">
<h1>Hi!</h1>
<ul>
<li>Matteo Francia, Ph.D.
<ul>
<li>Email: <a href="mailto:m.francia@unibo.it">m.francia@unibo.it</a></li>
<li>Assistant Professor (junior) @ DISI, UniBO</li>
<li>www: <a href="https://www.unibo.it/sitoweb/m.francia/en">https://www.unibo.it/sitoweb/m.francia/en</a></li>
</ul></li>
<li>Research topics
<ul>
<li>Big data / database</li>
<li>Precision agriculture and spatio-temporal analytics</li>
</ul></li>
<li>BIG (Business Intelligence Group)
<ul>
<li><a href="https://big.csr.unibo.it/teaching/">https://big.csr.unibo.it/</a></li>
</ul></li>
</ul>
</section>

<section id="table-of-contents-and-exam" class="title-slide slide level1 center">
<h1>Table of Contents and Exam</h1>
<ul>
<li>Handling data pipelines in the Cloud
<ul>
<li>Introduction to <strong>data platforms</strong>: shifting from databases to well-integrated data ecosystems</li>
<li>Definition of <strong>cloud computing</strong> and taxonomy of cloud services</li>
<li>Introduction to the most <strong>relevant cloud platforms</strong></li>
<li>Introduction to the <strong>billing models</strong> of cloud computing services</li>
<li>Cluster <strong>migration</strong>: on-premises vs on-cloud</li>
<li>Real <strong>case studies + labs</strong></li>
</ul></li>
<li>Seminars by companies working with cloud and big data platforms</li>
<li>Connect the dots
<ul>
<li>Information systems, BI, data mining, big data, and machine learning</li>
</ul></li>
<li>… <strong>all these points</strong> will be part of the oral examination!:)</li>
</ul>
</section>

<section id="table-of-contents-and-exam-1" class="title-slide slide level1 center">
<h1>Table of Contents and Exam</h1>
<ul>
<li>Questions on all (<strong>theoretical</strong> and <strong>practical</strong>) aspects of the course
<ul>
<li>A <strong>single session </strong> with both teachers</li>
<li>Exam covers <strong>both modules</strong></li>
<li><strong>Seminars and labs</strong> are included</li>
<li><strong>Interaction during the lectures/labs </strong> is considered in the final evaluation</li>
</ul></li>
<li>No scheduled dates, just come <strong>when you are ready</strong>
<ul>
<li>Send an email to <a href="mailto:enrico.gallinucci@unibo.it">enrico.gallinucci@unibo.it</a> to book an appointment</li>
<li>At least one week in advance</li>
</ul></li>
<li>According to the University’s regulation
<ul>
<li>Exams must be in presence</li>
<li><strong>Cannot refuse a grade more than once</strong></li>
</ul></li>
<li>Be prepared: you have to wait <strong>1 month before trying again</strong> (in any case)</li>
</ul>
</section>

<section id="so-far" class="title-slide slide level1 center">
<h1>So far</h1>
<blockquote>
<p>Digital transformation</p>
<p>The process of using digital technologies to create new — or modify existing — business processes, culture, and customer experiences to meet changing business and market requirements</p>
</blockquote>
<ul>
<li>You have acquainted/practiced with <strong>on-premises</strong> solutions
<ul>
<li>You were given a working hardware cluster</li>
<li>… to deploy software applications on Hadoop-based stack</li>
</ul></li>
<li>In the perspective of digital transformation, let us guess
<ul>
<li>How would you start from scratch?</li>
<li>How much time would it take?</li>
</ul></li>
</ul>
</section>

<section id="so-far-1" class="title-slide slide level1 center">
<h1>So far</h1>
<ul>
<li>No easy answers</li>
<li>Big-data (distributed) architectures require a lot of skills
<ul>
<li><strong>Configuration</strong>: how do I set up dozens of new machines?</li>
<li><strong>Networking</strong>: how do I cable dozens of machines?</li>
<li><strong>Management</strong>: how do I replace a broken disk?</li>
<li><strong>Upgrade</strong>: how do I extend the cluster with new services/machines?</li>
<li>(energy and cooling, software licenses, insurance…)</li>
</ul></li>
</ul>
<p><a href="https://aws.amazon.com/compliance/data-center/data-centers/">https://aws.amazon.com/compliance/data-center/data-centers/</a></p>
</section>

<section id="so-far-2" class="title-slide slide level1 center">
<h1>So far</h1>
<ul>
<li><p>Two sides of the same coin, and your profile is a perfect? fit</p>
<ul>
<li>Technological perspective
<ul>
<li>How do we configure a distributed environment?</li>
<li>How do we set up/integrate/control independent services?</li>
<li>How do we orchestrate data flows?</li>
</ul></li>
<li>Business perspective
<ul>
<li>Can we afford to spend resources on tasks that are not mission oriented?</li>
<li>No free lunch, each choice has cost/benefit</li>
<li>How much time does it take to master a technology?</li>
<li>How many people do I need?</li>
</ul></li>
</ul></li>
<li><p>… but first, which are our <strong>data needs</strong>?</p></li>
<li><p>Can we afford to spend resources on tasks that are not mission oriented?</p>
<ul>
<li>Mission: a statement used by a company to explain its purpose(s)</li>
</ul></li>
</ul>
</section>

<section id="teaching-material" class="title-slide slide level1 center">
<h1>Teaching material</h1>
<div class="columns">
<div class="column" style="width:25%;">
<p><img data-src="imgs/slides0.png"></p>
</div><div class="column" style="width:25%;">
<p><img data-src="imgs/slides1.jpg"></p>
</div><div class="column" style="width:25%;">
<p><img data-src="imgs/slides2.jpg"></p>
</div><div class="column" style="width:25%;">
<p><img data-src="imgs/slides5.png"></p>
</div><div class="column" style="width:33%;">
<p><img data-src="imgs/slides3.png"></p>
</div><div class="column" style="width:33%;">
<p><img data-src="imgs/slides4.png"></p>
</div>
</div>
</section>

<section id="teaching-material-1" class="title-slide slide level1 center">
<h1>Teaching material</h1>
<ul>
<li>You will find all you need in these slides</li>
<li>However, keeping up the pace with data platforms and cloud is hard
<ul>
<li>There is a rapid development of technologies, and not all of them will survive</li>
<li>Books are easily outdated with respect to cutting-edge services and technologies</li>
<li>Research papers (often) describe solutions that are not commercial yet</li>
<li>(IRL) You will need to deal with a lot of (bad) documentation, online articles, etc.</li>
</ul></li>
<li>Rule of thumb
<ul>
<li>Understand the general concepts</li>
<li>Do not be afraid of change</li>
<li>Connect the dots… and ask questions!</li>
</ul></li>
</ul>
</section>

<section id="newsection" class="title-slide slide level1 center">
<h1>– newsection –</h1>

</section>

<section id="from-databases-to-data-platforms" class="title-slide slide level1 center">
<h1>From databases to data platforms</h1>

</section>

<section id="how-did-we-get-here" class="title-slide slide level1 center">
<h1>How did we get here?</h1>
<ul>
<li><strong>Data-Driven Innovation</strong>
<ul>
<li>Use of data and <em>analytics</em> to foster new products, processes and markets</li>
<li>Drive discovery and execution of innovation, achieving new services with a business value</li>
</ul></li>
<li><strong>Analytics</strong>
<ul>
<li>A catch-all term for different business intelligence (BI)- and application-related initiatives
<ul>
<li>E.g., of analyzing information from a particular domain</li>
<li>E.g., applying BI capabilities to a specific content area (e.g., sales, service, supply chain)</li>
</ul></li>
</ul></li>
<li><strong>Advanced Analytics</strong>
<ul>
<li>(Semi-)Autonomous examination of data to discover deeper insights, make predictions, or generate recommendations (e.g., through data/text mining and machine learning)</li>
</ul></li>
<li><strong>Augmented Analytics</strong>
<ul>
<li>Use of technologies such as machine learning and AI to assist with data preparation, insight generation and insight explanation to augment how people explore and analyze data</li>
</ul></li>
</ul>
<p><a href="https://www.gartner.com/en/information-technology/glossary">https://www.gartner.com/en/information-technology/glossary</a> (accessed 2022-08-01)</p>
</section>

<section id="how-did-we-get-here-1" class="title-slide slide level1 center">
<h1>How did we get here?</h1>

<img data-src="imgs/slides6.png" class="r-stretch"></section>

<section id="data-platform" class="title-slide slide level1 center">
<h1>Data platform</h1>
<ul>
<li>Companies are collecting tons of data to enable advanced analytics
<ul>
<li>Raw data is difficult to obtain, interpret, and maintain</li>
<li>Data is more and more heterogeneous</li>
<li>There is need for curating data to make it <em>consumable</em></li>
</ul></li>
<li>Where are we <em>collecting/processing</em> data?
<ul>
<li>Getting <em>value</em> from data <em>is not</em> (only) a matter of <em>storage</em></li>
<li>Need integrated and multilevel analytical skills and techniques</li>
</ul></li>
<li>Getting <em>value</em> from data <em>is not</em> (only) a matter of <em>storage</em>
<ul>
<li>Any example?</li>
</ul></li>
</ul>
<blockquote>
<p>“It is a capital mistake to theorize before one has data. Insensibly, one begins to twist the facts to suit theories,&nbsp;instead of theories to suit facts.”</p>
<p>– Sherlock Holmes</p>
</blockquote>
</section>

<section id="case-study-photo-gallery" class="title-slide slide level1 center">
<h1>Case study: photo gallery</h1>
<div class="columns">
<div class="column" style="width:50%;">
<p><img data-src="imgs/slides7.png"></p>
</div><div class="column" style="width:50%;">
<p><img data-src="imgs/slides8.png"></p>
</div>
</div>
</section>

<section id="data-platform-1" class="title-slide slide level1 center">
<h1>Data platform</h1>
<div class="columns">
<div class="column" style="width:50%;">
<blockquote>
<p>Database</p>
<p>“A database is a <em>structured and persistent collection</em> of information about some aspect of the real world organized and stored in a way that facilitates efficient retrieval and modification. The structure of a database is determined by an <em>abstract data model</em>. Primarily, it is this structure that differentiates a database from a data file.”</p>
</blockquote>
</div><div class="column" style="width:50%;">
<p><img data-src="imgs/20.svg"></p>
</div>
</div>
<p>Özsu M.T. (2018) Database. In: Encyclopedia of Database Systems. Springer, New York, NY. <a href="https://doi.org/10.1007/978-1-4614-8265-9_80734">https://doi.org/10.1007/978-1-4614-8265-9_80734</a></p>
</section>

<section id="data-platform-2" class="title-slide slide level1 center">
<h1>Data platform</h1>
<div class="columns">
<div class="column" style="width:50%;">
<blockquote>
<p>Data Warehouse</p>
<p>“A collection of data that supports decision-making processes. It provides the following features: subject-oriented, integrated and consistent, not volatile.”</p>
</blockquote>
</div><div class="column" style="width:50%;">
<p><img data-src="imgs/21.svg"></p>
</div>
</div>
<p>Matteo Golfarelli and Stefano Rizzi. <em>Data warehouse design: Modern principles and methodologies</em> . McGraw-Hill, Inc., 2009.</p>
</section>

<section id="oltp-vs-olap" class="title-slide slide level1 center">
<h1>OLTP vs OLAP?</h1>

</section>

<section id="data-platform-oltp-vs-olap" class="title-slide slide level1 center">
<h1>Data platform: OLTP vs OLAP</h1>
<table>
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">Characteristic</th>
<th style="text-align: center;">OLTP</th>
<th style="text-align: center;">OLAP</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Nature</td>
<td style="text-align: center;">Constant transactions (queries/updates)</td>
<td style="text-align: center;">Periodic large updates, complex queries</td>
</tr>
<tr class="even">
<td style="text-align: center;">Examples</td>
<td style="text-align: center;">Accounting database, online retail transactions</td>
<td style="text-align: center;">Reporting, decision support</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Type</td>
<td style="text-align: center;">Operational data</td>
<td style="text-align: center;">Consolidated data</td>
</tr>
<tr class="even">
<td style="text-align: center;">Data retention</td>
<td style="text-align: center;">Short-term (2-6 months)</td>
<td style="text-align: center;">Long-term (2-5 years)</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Storage</td>
<td style="text-align: center;">Gigabytes (GB)</td>
<td style="text-align: center;">Terabytes (TB) / Petabytes (PB)</td>
</tr>
<tr class="even">
<td style="text-align: center;">Users</td>
<td style="text-align: center;">Many</td>
<td style="text-align: center;">Few</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Protection</td>
<td style="text-align: center;">Robust, constant data protection and fault tolerance</td>
<td style="text-align: center;">Periodic protection</td>
</tr>
</tbody>
</table>
</section>

<section id="data-platform-3" class="title-slide slide level1 center">
<h1>Data platform</h1>
<div class="columns">
<div class="column" style="width:50%;">
<blockquote>
<p>Schemaless databases</p>
<p>There is no predefined schema the data must conform to before it’s added to the database. As a result, you don’t need to know the structure of your data, enabling you to store all your data more easily and quickly.</p>
</blockquote>
</div><div class="column" style="width:50%;">
<p><img data-src="imgs/24.svg"></p>
</div>
</div>
</section>

<section id="data-platform-4" class="title-slide slide level1 center">
<h1>Data platform</h1>
<div class="columns">
<div class="column" style="width:50%;">
<blockquote>
<p>Data lake</p>
<p>“A DL is a <em>central repository</em> system for <em>storage, processing, and analysis of raw data</em>, in which the data is kept in its <em>original format and is processed to be queried only when needed</em>. It can <em>store a varied amount of formats</em> in big data ecosystems, from unstructured, semi-structured, to structured data sources”</p>
</blockquote>
</div><div class="column" style="width:50%;">
<p><img data-src="imgs/slides9.jpg"></p>
</div>
</div>
<p>Couto, Julia, et al.&nbsp;“A Mapping Study about Data Lakes: An Improved Definition and Possible Architectures.” <em>SEKE</em> . 2019.</p>
<p><a href="https://dunnsolutions.com/business-analytics/big-data-analytics/data-lake-consulting">https://dunnsolutions.com/business-analytics/big-data-analytics/data-lake-consulting</a></p>
</section>

<section id="data-platform-5" class="title-slide slide level1 center">
<h1>Data platform</h1>

<img data-src="imgs/26.svg" class="r-stretch"></section>

<section id="dwh-vs-data-lake" class="title-slide slide level1 center">
<h1>DWH vs Data Lake?</h1>

</section>

<section id="data-platform-dwh-vs-data-lake" class="title-slide slide level1 center">
<h1>Data platform: DWH vs Data Lake</h1>
<table>
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">Characteristics</th>
<th style="text-align: center;">Data warehouse</th>
<th style="text-align: center;">Data lake</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Data</td>
<td style="text-align: center;">Relational</td>
<td style="text-align: center;">Non-relational and relational</td>
</tr>
<tr class="even">
<td style="text-align: center;">Schema</td>
<td style="text-align: center;">Designed prior to implementation (schema-on-write)</td>
<td style="text-align: center;">Written at the time of analysis&nbsp;(schema-on-read)</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Price/performance</td>
<td style="text-align: center;">Fastest query results using higher cost storage</td>
<td style="text-align: center;">Query results getting faster using&nbsp;low-cost storage</td>
</tr>
<tr class="even">
<td style="text-align: center;">Data quality</td>
<td style="text-align: center;">Highly curated data that serves as the central version of the truth</td>
<td style="text-align: center;">Any data, which may or may not be curated (e.g., raw data)</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Users</td>
<td style="text-align: center;">Business analysts</td>
<td style="text-align: center;">Data scientists, data developers, and business analysts (using curated data)</td>
</tr>
<tr class="even">
<td style="text-align: center;">Analytics</td>
<td style="text-align: center;">Batch reporting, BI, and visualizations</td>
<td style="text-align: center;">Machine learning, predictive analytics, data discovery, and profiling.</td>
</tr>
</tbody>
</table>
</section>

<section id="data-platform-6" class="title-slide slide level1 center">
<h1>Data platform</h1>
<ul>
<li>Data lakes have increasingly taken the role of data hubs
<ul>
<li>Eliminate up-front costs of ingestion and ETL since data are stored in original format</li>
<li>Once in DL, data are available for analysis by everyone in the organization</li>
</ul></li>
<li>Drawing a sharp line been storage/computation/analysis is hard
<ul>
<li>Is a database just storage?</li>
<li>What about SQL/OLAP?</li>
</ul></li>
<li>Blurring of the architectural borderlines
<ul>
<li>DL is often replaced by “data platform” or “data ecosystem”</li>
<li>Encompass systems supporting data-intensive storage, computation, analysis</li>
</ul></li>
</ul>
</section>

<section id="data-platform-7" class="title-slide slide level1 center">
<h1>Data platform</h1>
<ul>
<li>A data platform is a <strong>centralized</strong> infrastructure that facilitates the ingestion, storage, management, and exploitation of large volumes of heterogeneous data. It provides a collection of <strong>independent</strong> and <strong>well-integrated</strong> services meeting <strong>end-to-end</strong> data needs.
<ul>
<li><strong>Centralized</strong>: is conceptually a single and unified component</li>
<li><strong>Independent</strong>: a service is not coupled with any other</li>
<li><strong>Well-integrated</strong>: services have interfaces that enable easy and frictionless composition</li>
<li><strong>End-to-end</strong>: services cover the entire data life cycle</li>
</ul></li>
<li>Rationale: relieve users from complexity of administration and provision
<ul>
<li>Not only technological skills, but also privacy, access control, etc.</li>
<li>Users should only focus on functional aspects</li>
</ul></li>
</ul>
</section>

<section id="data-platform-8" class="title-slide slide level1 center">
<h1>Data platform</h1>
<ul>
<li>Are we done? No!
<ul>
<li>Lacking smart support to govern the complexity of data and transformations</li>
<li>Data transformations must be governed to prevent DP turning into a swamp
<ul>
<li>Amplified in data science, with data scientists prevailing data architects</li>
<li>Leverage descriptive metadata and maintenance to keep control over data</li>
</ul></li>
</ul></li>
</ul>
</section>

<section id="which-functionalities-for-automated-data-management-can-you-think-about" class="title-slide slide level1 center">
<h1>Which functionalities for (automated) data management can you think about?</h1>

</section>

<section id="managing-data-platforms" class="title-slide slide level1 center">
<h1>Managing data platforms</h1>
<ul>
<li>Data provenance</li>
<li>Compression</li>
<li>Data profiling</li>
<li>Entity resolution</li>
<li>Data versioning</li>
<li>…</li>
</ul>
</section>

<section id="data-provenance" class="title-slide slide level1 center">
<h1>Data provenance</h1>
<ul>
<li>Provenance (also referred to as lineage, pedigree, parentage, genealogy)
<ul>
<li>The description of the origins of data and the process by which it arrived at the database</li>
<li>Not only data products (e.g., tables, files), but also the processes that created them</li>
</ul></li>
<li>Examples of use cases
<ul>
<li>Business domain. <em>Users traditionally work with an </em> <em>organized data schema</em> <em>, where the structure and </em> <em>semantics of the data in use is shared</em> _ across the corporation or even B2B. Yet, a large proportion of businesses deal with <strong>bad quality data</strong>. <strong>Sources</strong> of bad data __need to be identified __and corrected to avoid costly errors in business forecasting._</li>
<li>Scientific/research domain. <em>Data</em> used in the scientific field can be <em>ad hoc</em> and driven by _individual researchers <em>or small communities. The scientific field is moving <em>towards more collaborative research</em> and organizational boundaries are disappearing. <em>Sharing data and metadata across organizations is essential</em>, leading to a convergence on common schemes to ensure compatibility. Issues of <em>trust</em>, <em>quality</em>, and <em>copyright</em> of data are significant when using third-party data in such a loosely connected network.</em></li>
</ul></li>
</ul>
<p>Simmhan, Yogesh L., Beth Plale, and Dennis Gannon. “A survey of data provenance techniques.” <em>Computer Science Department, Indiana University, Bloomington IN</em> 47405 (2005): 69.</p>
</section>

<section id="data-provenance-1" class="title-slide slide level1 center">
<h1>Data provenance</h1>
<ul>
<li>Astronomers are creating an international Virtual Observatory
<ul>
<li>A <em>federation</em> of all the world significant astronomical <em>data resources</em> coupled with <em>provision of the computational resources </em> needed to exploit the data scientifically</li>
<li>Astronomy changed from being an individualistic to a <em>collective enterprise</em></li>
<li>Telescope time is devoted/allocated to systematic sky surveys and analysis is performed using data from the archives</li>
<li>Astronomers are <em>increasingly relying on data that they did not take themselves</em></li>
<li>Raw data bear <em>many instrumental signatures that must be removed </em> in the process of generating data products</li>
</ul></li>
</ul>

<img data-src="imgs/slides14.jpg" class="r-stretch"><p>Mann, Bob. “Some data derivation and provenance issues in astronomy.” <em>Workshop on Data Derivation and Provenance, Chicago</em> . 2002.</p>
<p><a href="https://www.esa.int/Science_Exploration/Space_Science/Webb/Webb_inspects_the_heart_of_the_Phantom_Galaxy">https://www.esa.int/Science_Exploration/Space_Science/Webb/Webb_inspects_the_heart_of_the_Phantom_Galaxy</a> (accessed 2022-08-01)</p>
</section>

<section id="data-provenance-2" class="title-slide slide level1 center">
<h1>Data provenance</h1>

<img data-src="imgs/slides15.png" class="r-stretch"><p>Simmhan, Yogesh L., Beth Plale, and Dennis Gannon. “A survey of data provenance techniques.” <em>Computer Science Department, Indiana University, Bloomington IN</em> 47405 (2005): 69.</p>
</section>

<section id="data-provenance-3" class="title-slide slide level1 center">
<h1>Data provenance</h1>
<ul>
<li>Granularity
<ul>
<li><em>Fine-grained</em> (instance level): tracking data items (e.g., a tuple in a dataset) transformations</li>
<li><em>Coarse-grained</em> (schema-level): tracking dataset transformations</li>
</ul></li>
<li>Queries
<ul>
<li><em>Where</em> provenance: given some output, which inputs did the output come from?</li>
<li><em>How</em> provenance: given some output, how were the inputs manipulated?</li>
<li><em>Why</em> provenance: given some output, why was data generated?
<ul>
<li>E.g., in the form of a proof tree that locates source data items contributing to its creation</li>
</ul></li>
</ul></li>
</ul>
<p>Simmhan, Yogesh L., Beth Plale, and Dennis Gannon. “A survey of data provenance techniques.” <em>Computer Science Department, Indiana University, Bloomington IN</em> 47405 (2005): 69.</p>
<p>Ikeda, Robert, and Jennifer Widom. <em>Data lineage: A survey</em> . Stanford InfoLab, 2009.</p>
</section>

<section id="data-provenance-4" class="title-slide slide level1 center">
<h1>Data provenance</h1>
<ul>
<li>Data provenance, an example of data management
<ul>
<li>Metadata pertaining to the history of a data item</li>
<li>Pipeline including the origin of objects and operations they are subjected to</li>
<li>We have a standard: <a href="https://www.w3.org/TR/prov-dm/">https://www.w3.org/TR/prov-dm/</a></li>
</ul></li>
</ul>

<img data-src="imgs/slides16.png" class="r-stretch"><p><a href="https://www.w3.org/TR/prov-dm/">https://www.w3.org/TR/prov-dm/</a></p>
</section>

<section id="data-provenance-5" class="title-slide slide level1 center">
<h1>Data provenance</h1>
<ul>
<li><em>Entity</em>
<ul>
<li>Physical/conceptual things</li>
</ul></li>
<li><em>Activity</em>
<ul>
<li>Dynamic aspects of the world, such as actions</li>
<li>How entities come into existence, often making use of previously existing entities</li>
</ul></li>
<li><em>Agent</em>
<ul>
<li>A person, a piece of software</li>
<li>Takes a role in an activity such that the agent can be assigned some degree of responsibility for the activity taking place</li>
</ul></li>
</ul>

<img data-src="imgs/slides17.png" class="r-stretch"><p><a href="https://www.w3.org/TR/2013/NOTE-prov-primer-20130430/">https://www.w3.org/TR/2013/NOTE-prov-primer-20130430/</a></p>
</section>

<section id="data-provenance-6" class="title-slide slide level1 center">
<h1>Data provenance</h1>
<ul>
<li>Use cases for data provenance</li>
<li>Accountability and auditing</li>
<li>Data quality
<ul>
<li>Monitoring of the quality (e.g., accuracy) of the objects produced</li>
<li>Notify when a transformation pipeline is not behaving as expected</li>
</ul></li>
<li>Debugging
<ul>
<li>Inferring the cause of pipeline failures is challenging</li>
<li>Store inputs of each operation with versions and environmental settings (RAM, CPUs, etc.)</li>
</ul></li>
<li>And so on…</li>
</ul>
</section>

<section id="compression" class="title-slide slide level1 center">
<h1>Compression</h1>
<ul>
<li>Summarization / compression
<ul>
<li>Present a concise representation of a dataset in a comprehensible and informative manner</li>
</ul></li>
</ul>

<img data-src="imgs/slides18.png" class="r-stretch"><p>Ahmed, Mohiuddin. “Data summarization: a survey.” <em>Knowledge and Information Systems</em> 58.2 (2019): 249-273.</p>
</section>

<section id="data-profiling" class="title-slide slide level1 center">
<h1>Data profiling</h1>
<ul>
<li>Data profiling <span class="citation" data-cites="naumann2014data">(<a href="" role="doc-biblioref" onclick="return false;"><strong>naumann2014data?</strong></a>)</span>
<ul>
<li>A broad range of methods to efficiently analyze a given data set</li>
<li>E.g., in a <em>relational</em> scenario, <em>tables</em> of a relational database are <em>scanned</em> to derive <em>metadata</em>, such as <em>data types</em>, <em>completeness</em> and <em>uniqueness</em> of columns, <em>keys</em> and <em>foreign keys</em>, and occasionally <em>functional dependencies</em> and <em>association rules</em></li>
</ul></li>
</ul>

<img data-src="imgs/slides19.png" class="r-stretch"></section>

<section id="data-profiling-1" class="title-slide slide level1 center">
<h1>Data profiling</h1>
<ul>
<li>Use cases
<ul>
<li><em>Query optimization</em>
<ul>
<li>Performed by DBMS to support query optimization with statistics about tables and columns</li>
<li>Profiling results can be used to estimate the selectivity of operators and the cost of a query plan</li>
</ul></li>
<li><em>Data cleansing </em> (typical use case is profiling data)
<ul>
<li>Prepare a cleansing process by revealing errors (e.g., in formatting), missing values or outliers</li>
</ul></li>
<li><em>Data integration and analytics</em></li>
</ul></li>
<li>Challenges?</li>
</ul>
</section>

<section id="data-profiling-2" class="title-slide slide level1 center">
<h1>Data profiling</h1>
<div class="columns">
<div class="column" style="width:50%;">
<ul>
<li>Challenges
<ul>
<li>The results of data profiling are <em>computationally complex</em> to discover
<ul>
<li>E.g., discovering keys/dependencies usually involves some sorting step for each considered column</li>
</ul></li>
<li>Verification of <em>complex constraints on column combinations </em> in a database
<ul>
<li>What is the complexity of this task?</li>
</ul></li>
</ul></li>
</ul>
</div><div class="column" style="width:50%;">
<table>
<thead>
<tr class="header">
<th style="text-align: center;">a</th>
<th style="text-align: center;">b</th>
<th style="text-align: center;">c</th>
<th style="text-align: center;">d</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">2</td>
</tr>
<tr class="even">
<td style="text-align: center;">1</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">4</td>
</tr>
</tbody>
</table>
<p>Given a table with columns <span class="math inline">\(C = { a, b, c, d }\)</span></p>
<ul>
<li>To extract the (distinct) cardinality of each column, I will consider <span class="math inline">\(|C|\)</span> columns <span class="math inline">\(\{(a), (b), (c), (d)\}\)</span></li>
<li>To extract the correlations between pairs of columns, I will consider (<span class="math inline">\(\binom{|C|}{n}\)</span>) groups <span class="math inline">\(\{(a, b), (a, c), (a, d), (b, c), ...\}\)</span></li>
<li>Extracting the relationships among all possible groups of columns generalizes to <span class="math inline">\(\sum_{n=1}^{|C|}\binom{|C|}{n}=2^{|C|}−1\)</span> groups</li>
</ul>
</div>
</div>
</section>

<section id="entity-resolution" class="title-slide slide level1 center">
<h1>Entity resolution</h1>
<ul>
<li>Entity resolution
<ul>
<li>(also known as entity matching, linking)</li>
<li>Find records that refer to the same entity across different data sources (e.g., data files, books, websites, and databases)</li>
</ul></li>
</ul>

<img data-src="imgs/slides20.png" class="r-stretch"><p>Papadakis, George, et al.&nbsp;“Blocking and filtering techniques for entity resolution: A survey.” <em>ACM Computing Surveys (CSUR)</em> 53.2 (2020): 1-42.</p>
</section>

<section id="data-versioning" class="title-slide slide level1 center">
<h1>Data versioning</h1>
<ul>
<li>Version control
<ul>
<li>A class of systems responsible for managing changes to computer programs, documents, or data collections</li>
<li>Changes are identified by a number/letter code, termed the revision/version number</li>
</ul></li>
<li>However, data pipelines are not only about code bult also about
<ul>
<li>Model Version control</li>
<li>Data Version Control</li>
<li>Model Parameter Tracking</li>
<li>Model Performance Comparison</li>
</ul></li>
</ul>
<p><img data-src="imgs/slides21.png"></p>
<p>Support CRUD (Create, Read, Update, Delete) operations with versions</p>
<p>E.g., on AWS (PUT, GET, DELETE), what about update?</p>
<p><img data-src="imgs/slides22.png"></p>
<p><img data-src="imgs/slides23.png"></p>
<p><img data-src="imgs/slides24.png"></p>
<p><a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/versioning-workflows.html">https://docs.aws.amazon.com/AmazonS3/latest/userguide/versioning-workflows.html</a> (accessed 2022-08-01)</p>
</section>

<section id="in-action" class="title-slide slide level1 center">
<h1>In action</h1>

<img data-src="imgs/slides25.png" class="r-stretch"><p>Lab: California housing prices</p>
</section>

<section id="data-platform-9" class="title-slide slide level1 center">
<h1>Data platform</h1>
<ul>
<li>Are we done? No!
<ul>
<li>Metadata can become bigger than data themselves</li>
</ul></li>
<li>We need meta meta-data (or models)…
<ul>
<li>… chasing our own tails</li>
</ul></li>
<li>Data management is still a (research) issue in data platforms</li>
</ul>
</section>

<section id="data-lakehouse" class="title-slide slide level1 center">
<h1>Data lakehouse</h1>
<ul>
<li><strong>Data </strong> <strong>lakehouse</strong>
<ul>
<li>Data management architecture that combines the flexibility, cost-efficiency, and scale of data lakes with the data management and ACID transactions of data warehouses, enabling business intelligence (BI) and machine learning (ML) on all data</li>
<li>Vendor lock in</li>
</ul></li>
</ul>
<p><img data-src="imgs/slides26.png"></p>
<p><a href="https://www.databricks.com/glossary/data-lakehouse">https://www.databricks.com/glossary/data-lakehouse</a></p>
<p><img data-src="imgs/slides27.png"></p>
<table>
<colgroup>
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 25%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;"></th>
<th style="text-align: center;">Data warehouse</th>
<th style="text-align: center;">Data lake</th>
<th style="text-align: center;">Data lakehouse</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Data format</td>
<td style="text-align: center;">Closed, proprietary format</td>
<td style="text-align: center;">Open format (e.g., Parquet)</td>
<td style="text-align: center;">Open format</td>
</tr>
<tr class="even">
<td style="text-align: center;">Types of data</td>
<td style="text-align: center;">Structured data, with limited support for semi-structured data</td>
<td style="text-align: center;">All types: Structured data, semi-structured data, textual data, unstructured (raw) data</td>
<td style="text-align: center;">All types: Structured data, semi-structured data, textual data, unstructured (raw) data</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Data access</td>
<td style="text-align: center;">SQL-only, no direct access to file</td>
<td style="text-align: center;">Open APIs for direct access to files with SQL, R, Python and other languages</td>
<td style="text-align: center;">Open APIs for direct access to files with SQL, R, Python and other languages</td>
</tr>
<tr class="even">
<td style="text-align: center;">Reliability</td>
<td style="text-align: center;">High quality, reliable data with ACID transactions</td>
<td style="text-align: center;">Low quality, data swamp</td>
<td style="text-align: center;">High quality, reliable data with ACID transactions</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Governance and security</td>
<td style="text-align: center;">Fine-grained security and governance for row/columnar level for tables</td>
<td style="text-align: center;">Poor governance as security needs to be applied to files</td>
<td style="text-align: center;">Fine-grained security and governance for row/columnar level for tables</td>
</tr>
<tr class="even">
<td style="text-align: center;">Performance</td>
<td style="text-align: center;">High</td>
<td style="text-align: center;">Low</td>
<td style="text-align: center;">High</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Scalability</td>
<td style="text-align: center;">Scaling becomes exponentially more expensive</td>
<td style="text-align: center;">Scales to hold any amount of data at low cost, regardless of type</td>
<td style="text-align: center;">Scales to hold any amount of data at low cost, regardless of type</td>
</tr>
<tr class="even">
<td style="text-align: center;">Use case support</td>
<td style="text-align: center;">Limited to BI, SQL applications and decision support</td>
<td style="text-align: center;">Limited to machine learning</td>
<td style="text-align: center;">One data architecture for BI, SQL and machine learning</td>
</tr>
</tbody>
</table>
<ul>
<li>Key technologies used to implement open source Data Lakehouses
<ul>
<li>Databricks’ Delta Lake</li>
<li>Apache Hudi</li>
<li>Apache Iceberg</li>
</ul></li>
</ul>
<p><a href="https://databricks.com/blog/2021/05/19/evolution-to-the-data-lakehouse.html">https://databricks.com/blog/2021/05/19/evolution-to-the-data-lakehouse.html</a></p>
</section>

<section id="data-platform-10" class="title-slide slide level1 center">
<h1>Data platform</h1>
<p><strong>Is it a Lakehouse with another name?</strong></p>
<ul>
<li>A Lakehouse is a part of data platform, a layer that enables to query multiple data sources (with SQL/Spark) transparently by using some metadata (JSON) log</li>
<li>Still, you could get a data platform where such transparence is not mandatory or could be achieved by different techniques (e.g., multistore [1])</li>
</ul>
<p>[1] Forresi, C., Gallinucci, E., Golfarelli, M., &amp; Hamadou, H. B. (2021). A dataspace-based framework for OLAP analyses in a high-variety multistore. The VLDB Journal, 30(6), 1017-1040.</p>
<p><strong>Is it a new&nbsp;name for BI?</strong></p>
<p>No, in a data platform you also need to manage (streams of) operational data and OLTP workloads</p>

<img data-src="imgs/slides28.png" class="r-stretch"></section>

<section id="data-platform-related-job-positions" class="title-slide slide level1 center">
<h1>Data platform: related job positions</h1>
<ul>
<li><em>Data platform engineer</em>
<ul>
<li>Orchestrate the successful implementation of cloud technologies within the data infrastructure of their business</li>
<li>Solid understanding of impact database types and implementation</li>
<li>Responsible for purchasing decisions for cloud services and approval of data architectures</li>
</ul></li>
<li><em>Data architect</em>
<ul>
<li>Team members who understand all aspects of a data platform’s architecture</li>
<li>Work closely with the data platform engineers to create data workflows</li>
<li>Responsible for designing and testing new database architectures and planning both data and architecture migrations</li>
</ul></li>
<li><em>Data pipeline engineer</em>
<ul>
<li>Responsible for planning, architecting, and building large-scale data processing systems</li>
</ul></li>
<li><em>Data analyst</em>
<ul>
<li>Analyze data systems, creating automated systems for retrieving data from the data platform</li>
<li>Cloud data analysts are more commonly members of the business user population</li>
</ul></li>
<li><em>Data scientist</em>
<ul>
<li>Analyze and interpret complex digital data</li>
<li>Work with new technologies (e.g., machine learning) to deepen the business’ understanding and gain new insights</li>
</ul></li>
</ul>
</section>

<section id="from-devops" class="title-slide slide level1 center">
<h1>From DevOps…</h1>
<p><strong>DevOps</strong> combines development and operations to increase the efficiency, speed, and security of software development and delivery compared to traditional processes.</p>
<p>DevOps practices enable software development (dev) and operations (ops) teams to accelerate delivery through automation, collaboration, fast feedback, and iterative improvement</p>
<p><img data-src="imgs/slides29.png"></p>
<p><a href="https://about.gitlab.com/topics/devops/">https://about.gitlab.com/topics/devops/</a> (accessed 2023-06-03)</p>
<p><img data-src="imgs/slides30.png"></p>
</section>

<section id="to-dataops" class="title-slide slide level1 center">
<h1>… to DataOps</h1>
<p><strong>DataOps</strong> refers to a general process aimed to shorten the end-to-end data analytic life-cycle time by introducing automation in the data collection, validation, and verification process</p>

<img data-src="imgs/slides31.png" class="r-stretch"><p>Munappy, A. R., Mattos, D. I., Bosch, J., Olsson, H. H., &amp; Dakkak, A. (2020, June). From ad-hoc data analytics to dataops. In <em>Proceedings of the International Conference on Software and System Processes</em> (pp.&nbsp;165-174).</p>
</section>

<section id="dataops" class="title-slide slide level1 center">
<h1>DataOps</h1>
<p><img data-src="imgs/slides32.png"></p>
<ul>
<li>From DevOps to DataOps
<ul>
<li><em>“A collaborative data management practice focused on improving the </em> <em>communication, integration and automation of data flows between </em> <em>data managers and data consumers across an organization”</em></li>
<li>Data analytics improved in terms of velocity, quality, predictability and scale of software engineering and deployment</li>
</ul></li>
<li>Some key rules
<ul>
<li>Establish progress and performance measurements at every stage</li>
<li>Automate as many stages of the data flow as possible</li>
<li>Establish governance discipline (<em>governance-as-code</em>)</li>
<li>Design process for growth and extensibility</li>
</ul></li>
</ul>
<p><img data-src="imgs/slides33.png"></p>
<p>Gartner, 2020 <a href="https://www.gartner.com/smarterwithgartner/how-dataops-amplifies-data-and-analytics-business-value">https://www.gartner.com/smarterwithgartner/how-dataops-amplifies-data-and-analytics-business-value</a>Andy Palmer, 2015 <a href="https://www.tamr.com/blog/from-devops-to-dataops-by-andy-palmer/">https://www.tamr.com/blog/from-devops-to-dataops-by-andy-palmer/</a> William Vorhies, 2017 <a href="https://www.datasciencecentral.com/profiles/blogs/dataops-it-s-a-secret">https://www.datasciencecentral.com/profiles/blogs/dataops-it-s-a-secret</a></p>
</section>

<section>
<section id="data-fabric" class="title-slide slide level1 center">
<h1>Data fabric</h1>
<ul>
<li>“vision for data management […] that seamlessly connects different clouds, whether they are private, public, or hybrid environments.” (2016)</li>
<li>Frictionless access and sharing of data in a distributed data environment
<ul>
<li>Enables a <strong>single and consistent data management framework</strong> , which allows seamless data access and processing by design across otherwise siloed storage</li>
<li>Leverages <strong>human and machine capabilities to access data </strong> in place or support its consolidation where appropriate</li>
<li><strong>Continuously identifies and connects data </strong> from disparate applications to discover unique, business-relevant relationships between the available data points</li>
</ul></li>
<li>It is a unified architecture with an integrated set of technologies and services
<ul>
<li>Designed to deliver integrated and enriched data – at the right time, in the right method, and to the right data consumer – in support of both operational and analytical workloads</li>
<li>Combines key data management technologies – such as <strong>data catalog</strong> , <strong>data governance</strong> , <strong>data integration</strong> , <strong>data pipelining</strong> , and <strong>data orchestration</strong></li>
</ul></li>
</ul>
<p><a href="https://cloud.netapp.com/hubfs/Data-Fabric/Data%20Fabric%20WP%20April%202017.pdf">https://cloud.netapp.com/hubfs/Data-Fabric/Data%20Fabric%20WP%20April%202017.pdf</a> (accessed 2023-06-23)Gartner, 2019 <a href="https://www.gartner.com/en/newsroom/press-releases/2019-02-18-gartner-identifies-top-10-data-and-analytics-technolo">https://www.gartner.com/en/newsroom/press-releases/2019-02-18-gartner-identifies-top-10-data-and-analytics-technolo</a> Gartner, 2021 <a href="https://www.gartner.com/smarterwithgartner/data-fabric-architecture-is-key-to-modernizing-data-management-and-integration">https://www.gartner.com/smarterwithgartner/data-fabric-architecture-is-key-to-modernizing-data-management-and-integration</a> K2View Whitepaper: What is a Data Fabric? The Complete Guide, 2021</p>
<ul>
<li><strong>Catalog all your data</strong>: including business glossary and design-time and runtime metadata</li>
<li><strong>Enable self-service capabilities</strong>: data discovery, profiling, exploration, quality assessment, consumption of data-as-a-product</li>
<li><strong>Provide a knowledge graph</strong>: Visualizing how data, people, processes, systems, etc. are interconnected, deriving additional actionable insight</li>
<li><strong>Provide intelligent (smart) information integration</strong>: Supporting IT staff and business users alike in their data integration and transformation, data virtualization, and federation tasks</li>
<li><strong>Derive insight from metadata</strong>: Orchestrating and automating tasks and jobs for data integration, data engineering, and data governance end to end</li>
<li><strong>Enforce local and global data rules/policies</strong>: Including AI/ML-based automated generation, adjustments, and enforcement of rules and policies</li>
<li><strong>Manage an end-to-end unified lifecycle</strong>: Implementing a coherent and consistent lifecycle end to end of all Data Fabric tasks across various platforms, personas, and organizations</li>
<li><strong>Enforce data and AI governance</strong>: Broadening the scope of traditional data governance to include AI artefacts, for example, AI models, pipelines</li>
</ul>
<p>Is this brand new?</p>
<ul>
<li><strong>It is a design concept</strong>
<ul>
<li>It optimizes data management by automating repetitive tasks</li>
<li>According to Gartner estimates, 25% of data management vendors will provide a complete framework for data fabric by 2024 – up from 5% today</li>
</ul></li>
</ul>
<p><img data-src="imgs/slides34.png"></p>
<p><img data-src="imgs/slides35.png"></p>
<p>Gartner, 2021 <a href="https://www.gartner.com/smarterwithgartner/data-fabric-architecture-is-key-to-modernizing-data-management-and-integration">https://www.gartner.com/smarterwithgartner/data-fabric-architecture-is-key-to-modernizing-data-management-and-integration</a></p>
<p>K2View, 2021 <a href="https://www.k2view.com/top-data-fabric-vendors">https://www.k2view.com/top-data-fabric-vendors</a></p>
</section>
<section class="slide level2">

<p>Top Players https://solutionsreview.com/data-management/the-best-data-fabric-tools-and-software/ https://em360tech.com/top-10/data-modelling-fabric Predictions https://live-datastaxd8.pantheonsite.io/sites/default/files/2021-02/Predicts_2021_Data__735776_ndx.pdf</p>
<p><img data-src="imgs/slides36.png"></p>
<p><a href="https://www.irion-edm.com/data-management-insights/gartner-data-summit-irion-representative-vendor-for-data-fabric-technology/">https://www.irion-edm.com/data-management-insights/gartner-data-summit-irion-representative-vendor-for-data-fabric-technology/</a></p>
<p><img data-src="imgs/slides37.png"></p>
<p>Gartner, 2021 <a href="https://www.gartner.com/smarterwithgartner/data-fabric-architecture-is-key-to-modernizing-data-management-and-integration">https://www.gartner.com/smarterwithgartner/data-fabric-architecture-is-key-to-modernizing-data-management-and-integration</a></p>
</section></section>
<section>
<section id="data-mesh" class="title-slide slide level1 center">
<h1>Data mesh</h1>
<ul>
<li>Distributed data architecture, under centralized governance and standardization for interoperability, enabled by a shared and harmonized self-serve data infrastructure
<ul>
<li>Domain-oriented decentralized data ownership
<ul>
<li>Decentralization and distribution of responsibility to people who are closest to the data, in order to support continuous change and scalability</li>
<li>Each domain exposes its own op/analytical APIs</li>
</ul></li>
<li><strong>Data as a product </strong> (<em>quantum</em>)
<ul>
<li>Products must be discoverable, addressable, trustworthy, self-describing, secure</li>
</ul></li>
<li>Self-serve data infrastructure as a platform
<ul>
<li>High-level abstraction of infrastructure to provision and manage the lifecycle of data products</li>
</ul></li>
<li>Federated computational governance
<ul>
<li>A governance model that embraces decentralization and domain self-sovereignty, interoperability through global standardization, a dynamic topology, automated execution of decisions by the platform</li>
</ul></li>
</ul></li>
</ul>
<p>Zhamak Dehghani, 2019 <a href="https://martinfowler.com/articles/data-monolith-to-mesh.html">https://martinfowler.com/articles/data-monolith-to-mesh.html</a>Zhamak Dehghani, 2020 <a href="https://martinfowler.com/articles/data-mesh-principles.html">https://martinfowler.com/articles/data-mesh-principles.html</a></p>
</section>
<section class="slide level2">

<p>https://www.youtube.com/watch?v=_bmYXWCxF_Q</p>
<ul>
<li>Data Mesh organizes data around <strong>business domain owners </strong> and transforms relevant data assets (data sources) to <strong>data products</strong> that can be consumed by distributed business users from various business domains or functions
<ul>
<li>Data products are created, governed, and used in an <strong>autonomous, decentralized</strong> , and self-service manner</li>
<li><strong>Self-service capabilities</strong> , which we have already referenced as a Data Fabric capability, enable business organizations to entertain a data marketplace with shopping-for-data characteristics</li>
</ul></li>
</ul>

<img data-src="imgs/slides38.png" class="r-stretch"></section></section>
<section id="what-makes-data-a-product" class="title-slide slide level1 center">
<h1>What makes data a product?</h1>
<ul>
<li>A <strong>data product </strong> is raw data transformed into a business context
<ul>
<li>Data products are registered in <strong>knowledge catalog </strong> through specifications (XML, JSON, etc.)</li>
<li>Main features
<ul>
<li><strong>Data product description</strong>: The data product needs to be well described</li>
<li><strong>Access methods</strong>: for example, REST APIs, SQL, NoSQL, etc., and where to find the data asset</li>
<li><strong>Policies and rules</strong>: who is allowed to consume the data product for what purpose</li>
<li><strong>SLAs</strong>: agreements regarding the data product availability, performance characteristics, functions, cost of data product usage</li>
<li><strong>Defined format</strong>: A data product needs to be described using a defined format</li>
<li><strong>Cataloged</strong>: All data products need to be registered in the knowledge catalog. Data products need to be searchable and discoverable by potential data product consumers and business user</li>
</ul></li>
<li>Data products themselves are not stored in the knowledge catalog</li>
</ul></li>
</ul>
</section>

<section id="data-mesh-vs-data-fabric" class="title-slide slide level1 center">
<h1>Data mesh vs data fabric</h1>
<ul>
<li>They are design concepts, not things
<ul>
<li>They are not mutually exclusive</li>
<li>They are architectural frameworks, not architectures
<ul>
<li>The frameworks must be adapted and customized to your needs, data, processes, and terminology</li>
<li>Gartner estimates 25% of data management vendors will provide a complete data fabric solution by 2024 – up from 5% today</li>
</ul></li>
</ul></li>
</ul>
<p>Alex Woodie, 2021 <a href="https://www.datanami.com/2021/10/25/data-mesh-vs-data-fabric-understanding-the-differences/">https://www.datanami.com/2021/10/25/data-mesh-vs-data-fabric-understanding-the-differences/</a> Dave Wells, 2021 <a href="https://www.eckerson.com/articles/data-architecture-complex-vs-complicated">https://www.eckerson.com/articles/data-architecture-complex-vs-complicated</a></p>
<ul>
<li>Both provide an architectural framework to access data across multiple technologies and platforms
<ul>
<li><strong>Data fabric</strong>
<ul>
<li>Attempts to centralize and coordinate data management</li>
<li>Tackles the complexity of data and metadata in a smart way that works well together</li>
<li>Focus on the architectural, technical capabilities, and intelligent analysis to produce active metadata supporting a smarter, AI-infused system to orchestrate various data integration styles</li>
</ul></li>
<li><strong>Data mesh</strong>
<ul>
<li>Emphasis on decentralization and data domain autonomy</li>
<li>Focuses on organizational change; it is more about people and process</li>
<li>Data are primarily organized around domain owners who create business-focused data products, which can be aggregated and consumed across distributed consumers</li>
</ul></li>
</ul></li>
</ul>
<p>Alex Woodie, 2021 <a href="https://www.datanami.com/2021/10/25/data-mesh-vs-data-fabric-understanding-the-differences/">https://www.datanami.com/2021/10/25/data-mesh-vs-data-fabric-understanding-the-differences/</a> Dave Wells, 2021 <a href="https://www.eckerson.com/articles/data-architecture-complex-vs-complicated">https://www.eckerson.com/articles/data-architecture-complex-vs-complicated</a></p>

<img data-src="imgs/slides39.png" class="r-stretch"><ul>
<li>Data Fabric and Mesh are the results from the data architecture evolution
<ul>
<li><strong>Many capabilities were in existence already long before</strong> the terms were coined</li>
</ul></li>
<li>Take away:
<ul>
<li>Abstract the “building blocks” of such platforms</li>
<li>Let them evolve according to scalability and flexibility requirements</li>
</ul></li>
</ul>
</section>

<section id="some-references" class="title-slide slide level1 center">
<h1>(Some) References</h1>
<p><img data-src="imgs/slides40.jpg"></p>
<p><img data-src="imgs/slides41.png"></p>
<p><img data-src="imgs/slides42.png"></p>
</section>

<section id="example-of-architecture" class="title-slide slide level1 center">
<h1>«Example» of architecture</h1>

<img data-src="imgs/slides43.jpg" class="r-stretch"><p>[1] <a href="https://xkcd.com/2347/">https://xkcd.com/2347/</a> (<em>)(</em>) «Ormai sta xkcd é una base troppo usata» Alessandro Tappi</p>
</section>

<section id="example-of-data-platform-hadoop-based" class="title-slide slide level1 center">
<h1>Example of data platform: Hadoop-based</h1>
<ul>
<li>A data platform on the Hadoop stack requires several tools</li>
<li>How many levels of complexity are hidden here?</li>
<li>How do you provision it?
<ul>
<li>Manual provisioning on-premises</li>
<li>Semi-automatic provisioning on-premises</li>
<li>Automatic provisioning in the cloud</li>
</ul></li>
</ul>
<p>Storage .</p>
<p>Resources .</p>
<p>Application .</p>
<p>GUI .</p>
<p>Messaging .</p>
<p>Orchestration .</p>
<p>Map Reduce</p>
<p>Batch</p>
<p>Flink</p>
<p>real-time</p>
</section>

<section id="on-premises-manual-provisioning" class="title-slide slide level1 center">
<h1>On-premises manual provisioning</h1>
<ul>
<li>Hardly advisable, if not for small and local tests
<ul>
<li><strong>Technical challenges</strong>
<ul>
<li>Installation: how do I set up a new machine?</li>
<li>Networking: how do I cable dozens of machines?</li>
<li>Management: how do I replace a broken disk?</li>
<li>Upgrade: how do I extend the cluster with new services/machines?</li>
<li>(energy and cooling, software licenses, insurance…)</li>
</ul></li>
<li><strong>Technological challenges</strong>
<ul>
<li>How do we configure a distributed environment?</li>
<li>How do we set up/integrate/control independent services?</li>
<li>How do we orchestrate data flows?</li>
</ul></li>
<li><strong>Business challenges</strong>
<ul>
<li>Can we afford to spend resources on tasks that are not mission oriented?</li>
<li>No free lunch, each choice has cost/benefit</li>
<li>How much time does it take to master a technology?</li>
<li>How many people do I need?</li>
</ul></li>
</ul></li>
</ul>
</section>

<section id="example-of-data-platform-moses" class="title-slide slide level1 center">
<h1>Example of data platform: MOSES</h1>
<p><img data-src="imgs/slides44.png"></p>
<ul>
<li>Example of a data platform (MOSES)</li>
<li>Functional architecture
<ul>
<li>Components of MOSES are in orange</li>
<li>Others are standard components in charge of producing/consuming, processing, storing, and visualizing data</li>
<li>The orchestrator (e.g., Oozie) manages (e.g., schedules) the data transformation processes</li>
</ul></li>
</ul>
<p>Metadata Extractor</p>
<p><img data-src="imgs/slides45.png"></p>
<p><img data-src="imgs/slides46.png"></p>
<p>Metadata Search</p>
<p>Engine</p>
<p><img data-src="imgs/slides47.png"></p>
<p><img data-src="imgs/slides48.png"></p>
<p><img data-src="imgs/slides49.png"></p>
<p><img data-src="imgs/slides50.png"></p>
<p>Provenance Manager</p>
<p><img data-src="imgs/slides51.png"></p>
<p><img data-src="imgs/slides52.png"></p>
<p><img data-src="imgs/slides53.png"></p>
<p><img data-src="imgs/slides54.png"></p>
<p>Custom components</p>
<p><img data-src="imgs/slides55.png"></p>
<p><img data-src="imgs/slides56.png"></p>
<p><img data-src="imgs/slides57.png"></p>
<p><img data-src="imgs/slides58.png"></p>
<p><img data-src="imgs/slides59.png"></p>
<p><img data-src="imgs/slides60.png"></p>
<p><img data-src="imgs/slides61.png"></p>
<p>Process Interfaces</p>
<p>MOSES Interfaces</p>
<p>Other Interfaces</p>
<p>Workflow Administration</p>
<p>Francia, M., Gallinucci, E., Golfarelli, M., Rizzi, S. et al.&nbsp;(2021). Making data platforms smarter with MOSES. Future Generation Computer Systems, 125, 299-313.</p>
</section>

<section id="summing-up" class="title-slide slide level1 center">
<h1>Summing up</h1>
<ul>
<li>Storage should be flexible enough to support heterogenous data models and raw data
<ul>
<li>From operational databases to DWHs <strong>(why?)</strong></li>
<li>From relational data models to NoSQL <strong>(why?)</strong></li>
<li>Data lake to (directly) ingest raw data</li>
</ul></li>
<li>Storage, <em>per se</em> , is insufficient to get value from the data <strong>(examples?)</strong>
<ul>
<li>We also need data processing and fruition</li>
<li>Data lakes are blurring into data platforms</li>
</ul></li>
<li>Data platforms support end-to-end data needs <strong>(which ones?)</strong>
<ul>
<li>Building data platforms is hard <strong>(why?)</strong></li>
<li>Managing data platforms is hard, exploit meta-data to ease this task
<ul>
<li>Data lineage, compression, profiling, resolution, etc.</li>
</ul></li>
</ul></li>
<li><strong>Open question</strong>: how do we deploy working data platforms?</li>
</ul>
</section>

<section id="newsection-1" class="title-slide slide level1 center">
<h1>– newsection –</h1>

</section>

<section>
<section id="building-data-pipelines" class="title-slide slide level1 center">
<h1>Building data pipelines</h1>

</section>
<section class="slide level2">

<p>https://catalog.us-east-1.prod.workshops.aws/workshops/ea7ddf16-5e0a-4ec7-b54e-5cadf3028b78/en-US</p>
</section></section>
<section id="a-necessary-introduction" class="title-slide slide level1 center">
<h1>A necessary introduction</h1>
<ul>
<li>Computational thinking: solving problems using concepts and ideas from computer science.
<ul>
<li>Take a complex problem</li>
<li>Understand better what the problem involves</li>
<li>Develop possible solutions</li>
<li>Present these solutions in a way that a computer, human or both can understand</li>
</ul></li>
<li>Pillars to computational thinking:
<ul>
<li>Decomposition</li>
<li>Pattern recognition</li>
<li>Data representation</li>
<li>Abstraction</li>
</ul></li>
</ul>

<img data-src="imgs/slides62.png" class="r-stretch"></section>

<section id="computational-thinking" class="title-slide slide level1 center">
<h1>Computational thinking</h1>
<ul>
<li><strong>Decomposition</strong>
<ul>
<li>Taking a complex problem and breaking it into more manageable sub-problems.</li>
<li>The solution to each sub-problem may be much simpler by putting together the solutions to the sub-problems (any example?)</li>
</ul></li>
<li><strong>Pattern recognition</strong>
<ul>
<li>Find patterns among the sub-problems</li>
<li>Identify problems sharing similarities or characteristics</li>
<li>Discovering these patterns make the complex problem easier to solve since we can use the same solution for each occurrence of the pattern (any example?)</li>
</ul></li>
<li>Data <strong>representation</strong> and <strong>abstraction</strong>
<ul>
<li>Determining the important characteristics of the problem and filtering out those that are not</li>
<li>Can create a representation of what we’re trying to solve</li>
</ul></li>
<li><strong>Algorithm</strong>
<ul>
<li>A set of step-by-step instructions of how to solve a problem.</li>
<li>It identifies what is to be done (the instructions), and the order in which they should be done</li>
</ul></li>
<li>… there is no magic in programming computers</li>
</ul>
</section>

<section id="integrated-analytics-lab" class="title-slide slide level1 center">
<h1>Integrated analytics lab</h1>
<ul>
<li><p>Requirements:</p>
<ul>
<li>Knowledge of programming, data structures, and algorithms</li>
<li>Acquaintance with Python programming and notebooks</li>
</ul></li>
<li><p>The labs will be mainly guided…</p>
<ul>
<li>… but the notebooks contain all the details</li>
<li>… no time for a complete (coding) discussion during the lectures</li>
</ul></li>
<li><p>Focus on the problem <strong>understanding</strong> , <strong>definition</strong> , and <strong>solution</strong> !</p></li>
<li><p>Building data pipelines</p>
<ul>
<li>Frame the problem and look at the big picture</li>
<li>Get the data</li>
<li>Explore the data to gain insights</li>
<li>Prepare the data</li>
<li>Explore different models and find the best ones</li>
<li>Fine-tune your models</li>
<li>Present your solution</li>
<li>Launch, monitor, and maintain your system</li>
</ul></li>
</ul>
<p><img data-src="imgs/slides63.png"></p>
<ul>
<li>Building data pipelines
<ul>
<li><em>Frame the problem</em> and look at the big picture</li>
<li><em>“We’ll use the California Housing Prices. Our task is to use California census data to forecast housing prices given the population, median income, and median housing price for each block group in California. Block groups are the smallest geographical unit for which the US Census Bureau publishes sample data (a block group typically has a population of 600 to 3,000 people)”</em></li>
</ul></li>
</ul>
<p><img data-src="imgs/slides64.png"></p>
<p><img data-src="imgs/slides65.png"></p>
<p><img data-src="imgs/slides66.png"></p>
<ul>
<li>Building data pipelines
<ul>
<li>Frame the problem and look at the big picture
<ul>
<li><em>Knowing the objective</em> is important because it will determine how you frame the problem, which algorithms you will select, which performance measure you will use to evaluate your model, and how much effort you will spend tweaking it.</li>
<li><em>“Your boss answers that your model’s output (a prediction of a district’s median housing price) will be fed to another Machine Learning system, along with many other signals. This downstream system will determine whether it is worth investing in a given area or not. Getting this right is critical, as it directly affects revenue.”</em></li>
</ul></li>
</ul></li>
</ul>
<p><img data-src="imgs/slides67.png"></p>
<ul>
<li>Building data pipelines
<ul>
<li>Frame the problem and look at the big picture
<ul>
<li>✔Define the objective in business terms</li>
<li>✖How should performance be measured? (postponed for later)</li>
</ul></li>
<li>Get the data
<ul>
<li>✔ List the data you need and how much you need
<ul>
<li>Data could be available in a relational database and/or spread across multiple tables/documents/files</li>
<li>In this project, however, things are much simpler</li>
</ul></li>
</ul></li>
<li>Explore the data to gain insights
<ul>
<li>✔ Create an environment to keep track of your data exploration
<ul>
<li>You have been provided with notebook environments</li>
</ul></li>
<li><em>✔ Study each attribute and its characteristics</em>
<ul>
<li><em>Let’s do this!</em></li>
</ul></li>
</ul></li>
</ul></li>
</ul>
</section>

<section id="in-action-1" class="title-slide slide level1 center">
<h1>In action</h1>

<img data-src="imgs/slides68.png" class="r-stretch"></section>

<section id="storage-nosql-dbmss" class="title-slide slide level1 center">
<h1>STORAGE: NoSQL DBMSs</h1>

</section>

<section id="not-only-sql" class="title-slide slide level1 center">
<h1>Not only SQL</h1>

</section>

<section id="introduction" class="title-slide slide level1 center">
<h1>Introduction</h1>
<p>What is NoSQL</p>
<p>Where does it come from, and why</p>
</section>

<section id="strengths-of-rdbmss" class="title-slide slide level1 center">
<h1>Strengths of RDBMSs</h1>
<ul>
<li><em>ACID properties</em>
<ul>
<li>Provides guarantees in terms of consistency and concurrent accesses</li>
</ul></li>
<li><em>Data integration and normalization of schemas</em>
<ul>
<li>Several application can share and reuse the same information</li>
</ul></li>
<li><em>Standard model and query language</em>
<ul>
<li>The relational model and SQL are very well-known standards</li>
<li>The same theoretical background is shared by the different implementations</li>
</ul></li>
<li><em>Robustness</em>
<ul>
<li>Have been used for over 40 years</li>
</ul></li>
</ul>
</section>

<section id="weaknesses-of-rdbms" class="title-slide slide level1 center">
<h1>Weaknesses of RDBMS</h1>
<ul>
<li>Impedance mismatch
<ul>
<li>Data are stored according to the relational model, but applications to modify them typically rely on the object-oriented model</li>
<li>Many solutions, no standard
<ul>
<li>E.g.: Object Oriented DBMS (OODBMS), Object-Relational DBMS (ORDBMS), Object-Relational Mapping (ORM) frameworks</li>
</ul></li>
</ul></li>
<li><em>Painful scaling-out</em>
<ul>
<li>Not suited for a cluster architecture</li>
<li>Distributing an RDBMS is neither easy nor cheap (e.g., Oracle RAC)</li>
</ul></li>
<li><em>Consistency vs latency</em>
<ul>
<li>Consistency is a must – even at the expense of latency</li>
<li>Today’s applications require high reading/writing throughput with low latency</li>
</ul></li>
<li><em>Schema rigidity</em>
<ul>
<li>Schema evolution is often expensive</li>
</ul></li>
</ul>
</section>

<section id="what-nosql-means" class="title-slide slide level1 center">
<h1>What NoSQL means</h1>
<ul>
<li>The term has been first used in ’98 by Carlo Strozzi
<ul>
<li>It referred to an open-source RDBMS&nbsp;that used a query language different from SQL</li>
</ul></li>
<li>In 2009 it was adopted by a meetup in San Francisco
<ul>
<li>Goal: discuss open-source projects related to the newest databases from Google and Amazon</li>
<li>Participants: Voldemort, Cassandra, Dynomite, HBase, Hypertable, CouchDB, MongoDB</li>
</ul></li>
<li>Today, <em>NoSQL</em> indicates <em>DBMSs</em> adopting a <em>different data model from the relational one</em>
<ul>
<li>NoSQL = Not Only SQL</li>
<li>According to Strozzi himself, NoREL would have been a more proper noun</li>
</ul></li>
</ul>
</section>

<section>
<section id="the-first-nosql-systems" class="title-slide slide level1 center">
<h1>The first NoSQL systems</h1>
<ul>
<li><em>LiveJournal, 2003</em>
<ul>
<li>Goal: reduce the number of queries on a DB from a pool of web servers</li>
<li>Solution: <em>Memcached</em> , designed to keep queries and results in RAM</li>
</ul></li>
<li><em>Google, 2005</em>
<ul>
<li>Goal: handle Big Data (web indexing, Maps, Gmail, etc.)</li>
<li>Solution: <em>BigTable</em> , designed for scalability and high performance on Petabytes of data</li>
</ul></li>
<li><em>Amazon, 2007</em>
<ul>
<li>Goal: ensure availability and reliability of its e-commerce service 24/7</li>
<li>Solution: <em>DynamoDB</em> , characterized by strong simplicity for data storage and manipulation</li>
</ul></li>
</ul>
</section>
<section class="slide level2">

<p>https://en.wikipedia.org/wiki/LiveJournal LiveJournal è una sorta di MSN russo</p>
</section></section>
<section id="nosql-common-features" class="title-slide slide level1 center">
<h1>NoSQL common features</h1>
<ul>
<li>Not just rows and tables
<ul>
<li>Several data model adopted to store and manipulate data</li>
</ul></li>
<li>Freedom from joins
<ul>
<li>Joins are either not supported or discouraged</li>
</ul></li>
<li>Freedom from rigid schemas
<ul>
<li>Data can be stored or queried without pre-defining a schema (<em>schemaless</em> _ or <em>soft-schema</em>)</li>
</ul></li>
<li>Distributed, shared-nothing architecture
<ul>
<li>Trivial scalability in a distributed environment with no performance decay</li>
<li>Each workstation uses its own disks and RAM</li>
</ul></li>
<li>SQL is dead, long live SQL!
<ul>
<li>Some systems do adopt SQL (or a SQL-like language)</li>
</ul></li>
</ul>
</section>

<section>
<section id="nosql-in-the-big-data-world" class="title-slide slide level1 center">
<h1>NoSQL in the Big Data world</h1>
<ul>
<li><em>NoSQL</em> systems are mainly used for operational workloads (<em>OLTP</em>)
<ul>
<li>Optimized for high read and write throughput on small amounts of data</li>
</ul></li>
<li><em>Big Data </em> technologies are mainly used for analytical workloads (<em>OLAP</em>)
<ul>
<li>Optimized for high read throughput on large amounts of data</li>
</ul></li>
<li>Can NoSQL systems be used for OLAP?
<ul>
<li>Possibly, but through Big Data analytical tools (e.g., Spark)</li>
</ul></li>
</ul>
</section>
<section class="slide level2">

<p>https://aws.amazon.com/it/nosql/</p>
</section></section>
<section id="data-models" class="title-slide slide level1 center">
<h1>Data models</h1>

</section>

<section id="nosql-several-data-models" class="title-slide slide level1 center">
<h1>NoSQL: several data models</h1>
<p>One of the key challenges is to understand which one fits best with the required application</p>
<table>
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">Model</th>
<th style="text-align: center;">Description</th>
<th style="text-align: center;">Use cases</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Key-value</td>
<td style="text-align: center;">Associates any kind of value to a string</td>
<td style="text-align: center;">Dictionary, lookup table, cache, file and images storage</td>
</tr>
<tr class="even">
<td style="text-align: center;">Document</td>
<td style="text-align: center;">Stores hierarchical data in a tree-like structure</td>
<td style="text-align: center;">Documents, anything that fits into a hierarchical structure</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Wide-column</td>
<td style="text-align: center;">Stores sparse matrixes where a cell is identified by the row and column keys</td>
<td style="text-align: center;">Crawling, high-variability systems, sparse matrixes</td>
</tr>
<tr class="even">
<td style="text-align: center;">Graph</td>
<td style="text-align: center;">Stores vertices and arches</td>
<td style="text-align: center;">Social network queries, inference, pattern matching</td>
</tr>
</tbody>
</table>
</section>

<section id="running-example" class="title-slide slide level1 center">
<h1>Running example</h1>
<p>Typical use case: customers, orders and products</p>

<img data-src="imgs/slides69.png" class="r-stretch"></section>

<section id="relational-data-model" class="title-slide slide level1 center">
<h1>Relational: data model</h1>
<p>Based on tables and rows</p>

<img data-src="imgs/slides70.png" class="r-stretch"></section>

<section id="data-modeling-example-relational-model" class="title-slide slide level1 center">
<h1>Data modeling example: relational model</h1>

<img data-src="imgs/slides71.png" class="r-stretch"></section>

<section>
<section id="graph-data-model" class="title-slide slide level1 center">
<h1>Graph: data model</h1>
<ul>
<li>Each DB contains one or more <em>graphs</em></li>
<li>Each graph contains <em>vertices </em> and <em>arcs</em>
<ul>
<li>Vertices: usually represent real-world entities
<ul>
<li>E.g.: people, organizations, web pages, workstations, cells, books, etc.</li>
</ul></li>
<li>Arcs: represent directed relationships between the vertices
<ul>
<li>E.g.: friendship, work relationship, hyperlink, ethernet links, copyright, etc.</li>
</ul></li>
<li>Vertices and arcs are described by <em>properties</em></li>
<li>Arcs are stored as physical pointers</li>
</ul></li>
<li>Most known specializations:
<ul>
<li>Reticular data model
<ul>
<li>Parent-child or owner-member relationships</li>
</ul></li>
<li>Triplestore
<ul>
<li>Subject-predicate-object relationships (e.g., RDF)</li>
</ul></li>
</ul></li>
</ul>

<img data-src="imgs/slides72.png" class="r-stretch"></section>
<section class="slide level2">

<p>https://stackoverflow.com/questions/5040617/what-is-the-difference-between-a-graph-database-and-a-network-database</p>
</section></section>
<section id="graph-querying" class="title-slide slide level1 center">
<h1>Graph: querying</h1>
<ul>
<li>Graph databases usually model relationships-rich scenarios</li>
<li>The query language simplifies the navigation of these relationships
<ul>
<li>Support for transactions</li>
<li>Support for indexes, selections and projections</li>
<li><strong>Query language based on detecting patterns</strong></li>
</ul></li>
</ul>
<table>
<colgroup>
<col style="width: 50%">
<col style="width: 50%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">Query</th>
<th style="text-align: center;">Pattern</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Find friends of friends</td>
<td style="text-align: center;">(user)-[:KNOWS]-(friend)-[:KNOWS]-(foaf)</td>
</tr>
<tr class="even">
<td style="text-align: center;">Find shortest path from A to B</td>
<td style="text-align: center;">shortestPath((userA)-[:KNOWS*..5]-(userB))</td>
</tr>
<tr class="odd">
<td style="text-align: center;">What has been bought by those who bought my same products?</td>
<td style="text-align: center;">(user)-[:PURCHASED]-&gt;(product)&lt;-[:PURCHASED]-()-[:PURCHASED]-&gt;(otherProduct)</td>
</tr>
</tbody>
</table>
</section>

<section id="data-modeling-example-graph-model" class="title-slide slide level1 center">
<h1>Data modeling example: graph model</h1>
<p>IDs are implicitly handled; different edge colors imply different edge types</p>

<img data-src="imgs/slides73.png" class="r-stretch"><p>CardN: 457</p>
<p>txnId:….</p>
<p>CardN: 477</p>
<p>txnId:….</p>
<p>street:Adamcity:Chicago</p>
<p>state:illinois</p>
<p>code:60007</p>
<p>street:9thcity:NewYork</p>
<p>state:NewYork</p>
<p>code:10001</p>
</section>

<section>
<section id="graph-vs-aggregate-modeling" class="title-slide slide level1 center">
<h1>Graph vs Aggregate modeling</h1>
<ul>
<li>The graph data model is intrinsically different from the others
<ul>
<li>Focused on the relationships rather than on the entities per-se</li>
<li><strong>Limited scalability</strong>: it is often impossible to shard a graph on several machines without “cutting” several arcs (i.e.&nbsp;having several cross-machine links)
<ul>
<li>Batch cross-machine queries: don’t follow relationships one by one, but “group them” to make less requests</li>
<li>Limit the depth of cross-machine node searches</li>
</ul></li>
<li><em>Data-driven modeling</em></li>
</ul></li>
<li>Key-value, document and wide-column are called <em>aggregate-oriented</em>
<ul>
<li>Aggregate = key-value pair, document, row (respectively)</li>
<li>The aggregate is the atomic block (no guarantees for multi-aggregate operations)</li>
</ul></li>
<li>Based on the concept of encapsulation
<ul>
<li>Avoid joins as much as possible  achieve <strong>high scalability</strong>
<ul>
<li>Con: data denormalization  <strong>potential inconsistencies in the data</strong></li>
</ul></li>
<li><em>Query-driven modeling</em></li>
</ul></li>
</ul>
</section>
<section class="slide level2">

<p>https://stackoverflow.com/questions/21558589/neo4j-sharding-aspect https://ayende.com/blog/4490/that-no-sql-thing-scaling-graph-databases</p>
</section></section>
<section id="document-data-model" class="title-slide slide level1 center">
<h1>Document: data model</h1>
<ul>
<li>Each DB contains one or more <em>collections</em> (corresponding to tables)</li>
<li>Each collection contains a list of <em>documents</em> (usually JSON)
<ul>
<li>Documents are hierarchically structured</li>
</ul></li>
<li>Each document contains a set of <em>fields</em>
<ul>
<li>The <em>ID</em> is mandatory</li>
</ul></li>
<li>Each field corresponds to a <em>key-value pair</em>
<ul>
<li>Key: unique string in the document</li>
<li>Value: either simple (string, number, boolean) or complex (object, array, BLOB)
<ul>
<li>A complex field can contain other field</li>
</ul></li>
</ul></li>
</ul>
<p>{</p>
<p>“_id”: 1234,</p>
<p>“name”: “Enrico”,</p>
<p>“address”: {</p>
<p>“city”: “Cesena”, “postalCode”: 47522</p>
<p>},</p>
<p>“contacts”: [ {</p>
<p>“type”: “office”, “contact”: “0547-338835”</p>
<p>}, {</p>
<p>“type”: “skype”, “contact”: “egallinucci”</p>
<p>} ]</p>
<p>}</p>
</section>

<section id="document-querying" class="title-slide slide level1 center">
<h1>Document: querying</h1>
<ul>
<li>The query language is quite expressive
<ul>
<li>Can create indexes on fields</li>
<li>Can filter on the fields</li>
<li>Can return more documents with one query</li>
<li>Can select which fields to project</li>
<li>Can update specific fields</li>
</ul></li>
<li>Different implementations, different functionalities
<ul>
<li>Some enable (possibly materialized) views</li>
<li>Some enable MapReduce queries</li>
<li>Some provide connectors to Big Data tools (e.g., Spark, Hive)</li>
<li>Some provide <em>full-text search </em> capabilities</li>
</ul></li>
</ul>
</section>

<section id="data-modeling-example-aggregate-model-2" class="title-slide slide level1 center">
<h1>Data modeling example: aggregate model (2)</h1>
<p><img data-src="imgs/slides74.png"></p>
<p><img data-src="imgs/slides75.png"></p>
</section>

<section id="data-modeling-example-document-model-1" class="title-slide slide level1 center">
<h1>Data modeling example: document model (1)</h1>
<p>Product collection</p>
<p>Customer collection</p>
<p>{</p>
<p>“_id”: 1,</p>
<p>“name”: “Martin”,</p>
<p>“adrs”: [</p>
<p>{“street”:“Adam”, “city”:“Chicago”, “state”:“illinois”, “code”:60007}, {“street”:“9th”, “city”:“NewYork”, “state”:“NewYork”, “code”:10001}</p>
<p>],</p>
<p>“orders”: [ {</p>
<p>“orderpayments”:[</p>
<p>{“card”:477, “billadrs”: {“street”:“Adam”, “city”:“Chicago”, “state”:“illinois”, “code”:60007}},</p>
<p>{“card”:457, “billadrs”: {“street”:“9th”, “city”:“NewYork”, “state”:“NewYork”, “code”:10001}}</p>
<p>],</p>
<p>“products”:[</p>
<p>{“id”:1, “name”:“Cola”, “price”:12.4},</p>
<p>{“id”:2, “name”:“Fanta”, “price”:14.4}</p>
<p>],</p>
<p>“shipAdrs”: {“street”:“9th”, “city”:“NewYork”, “state”:“NewYork”, “code”:10001}</p>
<p>}]</p>
<p>}</p>
<ul>
<li><p>{</p></li>
<li><p>“_id”:1,</p></li>
<li><p>“name”:“Cola”,</p></li>
<li><p>“price”:12.4</p></li>
<li><p>},</p></li>
<li><p>{</p></li>
<li><p>“_id”:2,</p></li>
<li><p>“name”:“Fanta”,</p></li>
<li><p>“price”:14.4</p></li>
<li><p>}</p></li>
<li><p>{</p></li>
<li><p>“_id”:1,</p></li>
<li><p>“name”:“Cola”,</p></li>
<li><p>“price”:12.4</p></li>
<li><p>},</p></li>
<li><p>{</p></li>
<li><p>“_id”:2,</p></li>
<li><p>“name”:“Fanta”,</p></li>
<li><p>“price”:14.4</p></li>
<li><p>}</p></li>
</ul>
<p>{</p>
<p>“_id”: 1,</p>
<p>“name”: “Martin”,</p>
<p>“adrs”: [</p>
<p>{“street”:“Adam”, “city”:“Chicago”, “state”:“illinois”, “code”:60007}, {“street”:“9th”, “city”:“NewYork”, “state”:“NewYork”, “code”:10001}</p>
<p>]</p>
<p>}</p>
<p>Customer</p>
<p>collection</p>
<ul>
<li>{</li>
<li>“_id”: 1,</li>
<li>“customer”:1,</li>
<li>“orderpayments”:[</li>
<li>{“card”:477, “billadrs”:{“street”:“Adam”, “city”:“Chicago”, “state”:“illinois”, “code”:60007}},
<ul>
<li>{“card”:457, “billadrs”:{“street”:“9th”, “city”:“NewYork”, “state”:“NewYork”, “code”:10001}}</li>
<li>],</li>
<li>“products”: [</li>
<li>{“id”:1, “name”:“Cola”, “price”:12.4},</li>
<li>{“id”:2, “name”:“Fanta”, “price”:14.4}</li>
<li>],</li>
<li>“shipAdrs”: {“street”:“9th”, “city”:“NewYork”, “state”:“NewYork”, “code”:10001}</li>
</ul></li>
<li>}</li>
</ul>
<p>Product</p>
<p>collection</p>
<p>Order</p>
<p>collection</p>
</section>

<section id="key-value-data-model" class="title-slide slide level1 center">
<h1>Key-value: data model</h1>
<ul>
<li>Each DB contains one or more <em>collections</em> (corresponding to tables)</li>
<li>Each collection contains a list of <em>key-value pairs</em>
<ul>
<li>Key: a unique string
<ul>
<li>E.g.: ids, hashes, paths, queries, REST calls</li>
</ul></li>
<li>Value: a BLOB (binary large object)
<ul>
<li>E.g.: text, documents, web pages, multimedia files</li>
</ul></li>
</ul></li>
<li>Looks like a simple dictionary
<ul>
<li><em>The collection is indexed by key</em></li>
<li><em>The value may contain several information</em>
<ul>
<li>Definitions, synonyms and antonyms, images, etc.</li>
</ul></li>
</ul></li>
</ul>

<img data-src="imgs/slides76.png" class="r-stretch"></section>

<section id="key-value-querying" class="title-slide slide level1 center">
<h1>Key-value: querying</h1>
<ul>
<li>Three simple kinds of query:
<ul>
<li><em>put($key as </em> <em>xs:string</em> <em>, $value as item())</em>
<ul>
<li>Adds a key-value pair to the collection</li>
<li>If the key already exists, the value is replaced</li>
</ul></li>
<li><em>get($key as </em> <em>xs:string</em> <em>) as item()</em>
<ul>
<li>Returns the value corresponding to the key (if it exists)</li>
</ul></li>
<li><em>delete($key as </em> <em>xs:string</em> <em>)</em>
<ul>
<li>Deletes the key-value pair</li>
</ul></li>
</ul></li>
<li>The value is a _ <em>black box</em> _: it cannot be queried!
<ul>
<li>No “where” clauses</li>
<li>No indexes on the values</li>
<li>Schema information is often indicated in the key</li>
</ul></li>
</ul>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">Key</th>
<th style="text-align: center;">Value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">user:1234:name</td>
<td style="text-align: center;">Enrico</td>
</tr>
<tr class="even">
<td style="text-align: center;">user:1234:city</td>
<td style="text-align: center;">Cesena</td>
</tr>
<tr class="odd">
<td style="text-align: center;">post:9876:written-by</td>
<td style="text-align: center;">user:1234</td>
</tr>
<tr class="even">
<td style="text-align: center;">post:9876:title</td>
<td style="text-align: center;">NoSQL Databases</td>
</tr>
<tr class="odd">
<td style="text-align: center;">comment:5050:reply-to</td>
<td style="text-align: center;">post:9876</td>
</tr>
</tbody>
</table>
</section>

<section id="data-modeling-example-key-value-model" class="title-slide slide level1 center">
<h1>Data modeling example: key-value model</h1>
<p>Product collection</p>
<p>Customer collection</p>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">key</th>
<th style="text-align: center;">value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">p-1:name</td>
<td style="text-align: center;">Cola</td>
</tr>
<tr class="even">
<td style="text-align: center;">p-2:name</td>
<td style="text-align: center;">Fanta</td>
</tr>
</tbody>
</table>
<table>
<colgroup>
<col style="width: 50%">
<col style="width: 50%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">key</th>
<th style="text-align: center;">value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">cust-1:name</td>
<td style="text-align: center;">Martin</td>
</tr>
<tr class="even">
<td style="text-align: center;">cust-1:adrs</td>
<td style="text-align: center;">[ <br> {“street”:“Adam”, “city”:“Chicago”, “state”:“Illinois”, “code”:60007}, {“street”:“9th”, “city”:“NewYork”, “state”:“NewYork”, “code”:10001}<br>]</td>
</tr>
<tr class="odd">
<td style="text-align: center;">cust-1:ord-99</td>
<td style="text-align: center;">{ <br> “orderpayments”: [ <br> {“card”:477, “billadrs”: <br> {“street”:“Adam”, “city”:“Chicago”, “state”:“illinois”, “code”:60007} }, <br> {“card”:457, “billadrs”:<br> {“street”:“9th”, “city”:“NewYork”, “state”:“NewYork”, “code”:10001} <br> ],<br> “products”: [ <br> {“id”:1, “name”:“Cola”, “price”:12.4}, <br> {“id”:2, “name”:“Fanta”, “price”:14.4} <br> ],<br> “shipAdrs”: {“street”:“9th”, “city”:“NewYork”, “state”:“NewYork”, code”:10001}<br>}</td>
</tr>
</tbody>
</table>
</section>

<section id="wide-column-data-model" class="title-slide slide level1 center">
<h1>Wide column: data model</h1>
<ul>
<li>Each DB contains one or more <em>column families </em> (corresponding to tables)</li>
<li>Each column family contains a list of <em>row</em> in the form of a key-value pair
<ul>
<li>Key: unique string in the column family</li>
<li>Value: a set of <em>columns</em></li>
</ul></li>
<li>Each column is a key-value pair itself
<ul>
<li>Key: unique string in the row</li>
<li>Value: simple or complex (<em>supercolumn</em>)</li>
</ul></li>
<li>Essentially a 2-dimensional key-value store</li>
<li><em>Rows specify only the columns </em> <em>for which a value exists</em>
<ul>
<li>Particularly suited for sparse matrixes and many-to-many relationships</li>
</ul></li>
</ul>

<img data-src="imgs/slides77.png" class="r-stretch"></section>

<section id="wide-column-querying" class="title-slide slide level1 center">
<h1>Wide column: querying</h1>
<ul>
<li>The query language expressiveness is in between key-value and document data models
<ul>
<li>Column indexes are discouraged</li>
<li>Can filter on column values (not always)</li>
<li>Can return more rows with one query</li>
<li>Can select which columns to project</li>
<li>Can update specific columns (not always)</li>
</ul></li>
<li>Given the similarity with the relational model, a <em>SQL-like </em> language is often used</li>
</ul>
</section>

<section id="wide-column-columnar" class="title-slide slide level1 center">
<h1>Wide column: ≠ columnar</h1>
<ul>
<li>Do not mistake the wide column data model with the columnar storage used for OLAP applications</li>
<li>Row-oriented
<ul>
<li>Pro: inserting a record is easy</li>
<li>Con: several unnecessary data may be accessed when reading a record</li>
</ul></li>
<li>Column-oriented
<ul>
<li>Pro: only the required values are accessed</li>
<li>Con: writing a record requires multiple accesses</li>
</ul></li>
</ul>
<p><img data-src="imgs/slides78.png"></p>
<p><img data-src="imgs/slides79.png"></p>
<p><img data-src="imgs/slides80.png"></p>
</section>

<section id="data-modeling-example-wide-column-model" class="title-slide slide level1 center">
<h1>Data modeling example: wide-column model</h1>
<p>Order details column family</p>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">Ord</th>
<th style="text-align: center;">CustName</th>
<th style="text-align: center;">Pepsi</th>
<th style="text-align: center;">Cola</th>
<th style="text-align: center;">Fanta</th>
<th style="text-align: center;">…</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">1</td>
<td style="text-align: center;">Martin</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">12.4</td>
<td style="text-align: center;">14.4</td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;">2</td>
<td style="text-align: center;">…</td>
<td style="text-align: center;">…</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">…</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">Ord</th>
<th style="text-align: center;">OrderPayments</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">1</td>
<td style="text-align: center;"><br><br><br></td>
</tr>
<tr class="even">
<td style="text-align: center;">2</td>
<td style="text-align: center;">…</td>
</tr>
</tbody>
</table>
<p>Order payments column family</p>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">Card</th>
<th style="text-align: center;">Steet</th>
<th style="text-align: center;">City</th>
<th style="text-align: center;">State</th>
<th style="text-align: center;">Code</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">477</td>
<td style="text-align: center;">9th</td>
<td style="text-align: center;">NewYork</td>
<td style="text-align: center;">NewYork</td>
<td style="text-align: center;">10001</td>
</tr>
<tr class="even">
<td style="text-align: center;">457</td>
<td style="text-align: center;">Adam</td>
<td style="text-align: center;">Chicago</td>
<td style="text-align: center;">Illinois</td>
<td style="text-align: center;">60007</td>
</tr>
</tbody>
</table>
</section>

<section id="aggregate-modeling-strategy" class="title-slide slide level1 center">
<h1>Aggregate modeling strategy</h1>
<ul>
<li>The <em>aggregate </em> term comes from Domain-Driven Design
<ul>
<li>An aggregate is a group of tightly coupled objects to be handled as a block</li>
<li>Aggregates are the basic unit for data manipulation and consistency management</li>
</ul></li>
<li>Advantages
<ul>
<li><em>Can be distributed trivially</em>
<ul>
<li>Data that should be used together (e.g., orders and details) are stored together</li>
</ul></li>
<li><em>Facilitate the developer’s job</em>
<ul>
<li>By surpassing the impedance mismatch problem</li>
</ul></li>
</ul></li>
<li>Disadvantages
<ul>
<li><strong>No design strategy exists for aggregates</strong>
<ul>
<li><em>It only depends on how they are meant to be used</em></li>
</ul></li>
<li>Can optimize only a limited set of queries</li>
<li>Data denormalization  possible inconsistencies</li>
</ul></li>
<li>RDBMSs are agnostic from this point of view</li>
</ul>
</section>

<section>
<section id="sharding-data" class="title-slide slide level1 center">
<h1>Sharding data</h1>
<p>A look behind the curtain</p>
<ul>
<li>One of the strengths of NoSQL systems is their <em>scale-out capability</em>
<ul>
<li>_ <em>Aggregate data modeling</em> <em>: </em> well suited for being distributed within a cluster</li>
<li>NoSQL systems can be used in a <em>single server environment </em> too
<ul>
<li>Graph databases do not scale as well as the others</li>
</ul></li>
</ul></li>
<li>Two aspects must be considered when deploying on a cluster
<ul>
<li><strong>Sharding</strong>: <em>distributing the data across different nodes</em></li>
<li><strong>Replication</strong>: <em>creating copies of the data on several nodes</em></li>
</ul></li>
</ul>
</section>
<section class="slide level2">

<p>As data volumes increase, it becomes more difficult and expensive to scale up—buy a bigger server to run the database on. A more appealing option is to scale out—run the database on a cluster of servers. Aggregate orientation fits well with scaling out because the aggregate is a natural unit to use for distribution.</p>
<p>Quando ha senso l’approccio single-server? Mole di dati non è enorme Si vogliono sfruttare le caratteristiche dei database NoSQL (e.g., schemaless, modello dati) Un sistema distribuito è inevitabilmente più complesso; non è detto che ne valga sempre la pena</p>
</section></section>
<section>
<section id="sharding" class="title-slide slide level1 center">
<h1>Sharding</h1>
<ul>
<li><strong>Sharding</strong>: <em>subdividing the data in </em> <em>shards</em> _ that are stored in different machines_
<ul>
<li>Intrinsic in a distributed DB</li>
<li>Improves the efficiency of the system
<ul>
<li>Read/write operations are distributed</li>
</ul></li>
</ul></li>
<li>A good <em>sharding</em> _ strategy _ is <strong>fundamental </strong> to optimize performances
<ul>
<li>Usually based on one or more fields composing the sharding key</li>
</ul></li>
</ul>

<img data-src="imgs/slides81.png" class="r-stretch"></section>
<section class="slide level2">

<p>Rimosso: Non dimenticarsi che, nei cluster,si usano macchine meno affidabili – diminuisce la resistenza ai guasti</p>
</section></section>
<section>
<section id="sharding-strategy" class="title-slide slide level1 center">
<h1>Sharding strategy</h1>
<ul>
<li>Thumbs-up rules for a sharding strategy:</li>
<li>_ Data-locality: stores the data close to those that need to access them_
<ul>
<li>E.g., store orders of Italian customers in the European data center</li>
</ul></li>
<li>_ Keep a balanced distribution_
<ul>
<li>Each node should have the same percentage of data (more or less)</li>
</ul></li>
<li>_ Keep together the data that must be accessed together_
<ul>
<li>E.g., store each client’s orders in the same node</li>
</ul></li>
<li>Hash strategy: a hash function is used to allocate data to partitions
<ul>
<li>Adopted by DynamoDB and Cassandra</li>
<li>Pro: ensures even data distribution across nodes  massive scalability</li>
<li>Pro: new nodes can be added without heavy data redistribution</li>
<li>Con: range queries become inefficient</li>
</ul></li>
</ul>

<img data-src="imgs/slides82.png" class="r-stretch"></section>
<section class="slide level2">

<p>https://blog.yugabyte.com/four-data-sharding-strategies-we-analyzed-in-building-a-distributed-sql-database/</p>
<ul>
<li>Range strategy: each partition contains a range of sorted data
<ul>
<li>Adopted by HBase</li>
<li>Pro: efficiently run range queries that work on the sharding key values</li>
<li>Con: global ordering often generates hot spots  risk of bottlenecks</li>
<li>Con: ranges are defined a priori and this can determine heavy data redistribution</li>
</ul></li>
</ul>

<img data-src="imgs/slides83.png" class="r-stretch"></section>
<section class="slide level2">

<p>https://blog.yugabyte.com/four-data-sharding-strategies-we-analyzed-in-building-a-distributed-sql-database/</p>
<p>Auto-sharding: the database distributes the data according to the workload</p>
<p>Beware: redefining (or choosing later) the sharding strategy can be quite expensive</p>

<img data-src="imgs/slides84.png" class="r-stretch"></section></section>
<section>
<section id="replication" class="title-slide slide level1 center">
<h1>Replication</h1>
<ul>
<li><strong>Replication</strong>: the data is <em>copied </em> on several nodes
<ul>
<li>Improves the robustness of the system
<ul>
<li>In case of node failure, replicas prevent data loss</li>
</ul></li>
<li>Improves the efficiency of the system
<ul>
<li>More users read the same data from different copies, in parallel</li>
<li>Higher chance of enforcing data-locality</li>
</ul></li>
</ul></li>
<li>How to distribute the replicas?
<ul>
<li>Random (possibly <em>topology-aware</em>) distribution of each record
<ul>
<li>Similarly to HDFS blocks</li>
</ul></li>
<li>Replication of entire instances</li>
</ul></li>
<li>Main issue: each update must be pushed to every replica
<ul>
<li>Two techniques to handle updates: master-slave, peer to peer</li>
</ul></li>
</ul>
</section>
<section class="slide level2">

<p>Parliamo di replica completa, per ora</p>
</section></section>
<section>
<section id="master-slave-replication" class="title-slide slide level1 center">
<h1>Master-Slave Replication</h1>
<ul>
<li><em>Master</em>
<ul>
<li>It’s the manager of the data</li>
<li><em>Handles each and every write operation</em></li>
<li>Can be chosen or drawn</li>
</ul></li>
<li><em>Slaves </em>
<ul>
<li>Enable read operations</li>
<li>In sync with the master</li>
<li>Can become masterif the latter fails</li>
</ul></li>
</ul>

<img data-src="imgs/slides85.png" class="r-stretch"></section>
<section class="slide level2">

<p>Parliamo di replica completa, per ora</p>
<ul>
<li><strong>Pros</strong>
<ul>
<li>Easily handles many read requests
<ul>
<li>Slaves do not need the master to perform reads</li>
</ul></li>
<li>Useful when the workload mainly consists of reads</li>
<li>Useful to avoid write conflicts</li>
</ul></li>
<li><strong>Cons</strong>
<ul>
<li><em>The master is a bottleneck</em>
<ul>
<li><strong>Only the master can handle writes</strong></li>
<li>In case of failure, a new master must be drawn</li>
</ul></li>
<li>Delay in write propagation can be a source of inconsistency
<ul>
<li>Two users may read different values at the same time</li>
<li><em>Read inconsistency can be problematic, but are relatively limited in time</em></li>
</ul></li>
<li>Not ideal when the workload mainly consists of writes</li>
</ul></li>
</ul>
</section></section>
<section>
<section id="peer-to-peer-replication" class="title-slide slide level1 center">
<h1>Peer-to-Peer Replication</h1>
<p>Each node has the same importance</p>
<p><em>Each node can handle write operations</em></p>
<p>The loss of a node does not compromise reads nor writes</p>

<img data-src="imgs/slides86.png" class="r-stretch"><ul>
<li><strong>Pro</strong>
<ul>
<li>The failure of a node does not interrupt read nor write requests</li>
<li>Write performances easily scale by adding new nodes</li>
</ul></li>
<li><strong>Cons</strong>
<ul>
<li><em>Conflicts! </em></li>
<li>Delay in write propagation can be a source of inconsistency
<ul>
<li>Same as with master-slave replication</li>
</ul></li>
<li>Two users may update the same value from different replicas
<ul>
<li><em>Write inconsistencies are way worse</em></li>
</ul></li>
</ul></li>
</ul>
</section>
<section class="slide level2">

<p>TODO: come gestire conflitti in scrittura? Quorum, l‘ultimo vince o segnalazione.</p>
</section></section>
<section>
<section id="handling-conflicts" class="title-slide slide level1 center">
<h1>Handling conflicts</h1>
<ul>
<li>Read conflicts
<ul>
<li><em>Tolerate conflicts</em>: _ _ the <em>inconsistency window </em> is usually limited</li>
<li><em>Read-your-writes</em>: read consistency is guaranteed for the data written by the same user
<ul>
<li>Applies only to reads that immediately follow a write operation</li>
<li>One way is to associate a user to a node (risk: unbalanced workloads)</li>
<li>Typically, versioning fields are used to ensure that the up-to-date version is read</li>
</ul></li>
</ul></li>
<li>Write conflicts (P2P model)
<ul>
<li><em>Last write wins: </em> in case of conflict, the latest update overrides the others</li>
<li><em>Conflict prevention</em>: enforce writes on the most recent version by verifying that the value hasn’t changed since the last read</li>
<li><em>Conflict detection</em>: preserve history, merge results, and let the user decide</li>
</ul></li>
</ul>
</section>
<section class="slide level2">

<p>Read-your-writes: https://jepsen.io/consistency/models/read-your-writes https://highlyscalable.wordpress.com/2012/09/18/distributed-algorithms-in-nosql-databases/ Prevention: verify that the value hasn’tchanges since the last read</p>
</section></section>
<section id="the-quorum-mechanism" class="title-slide slide level1 center">
<h1>The quorum mechanism</h1>
<ul>
<li>The <em>quorum mechanism </em> ensures consistent IO under replication
<ul>
<li>Based on contacting a majority of the nodes responsible for certain data</li>
<li>The quorum is the minimum number of nodes that a distributed operation has to obtain in order to be allowed to perform an operation on a replicated data item</li>
</ul></li>
<li>Each data item has N replicas
<ul>
<li>Writing quorum: W &gt; N/2
<ul>
<li>The write operation is allowed only if W replicas can be updated</li>
<li>Ensures that two write operations cannot occur concurrently</li>
</ul></li>
<li>Reading quorum: R &gt; N-W
<ul>
<li>The read operation is allowed only if R replicas can be read</li>
<li>Ensures that (at least) one copy with the up-to-date value is read</li>
</ul></li>
</ul></li>
</ul>
<p>writes <em>w</em> <em>1</em> , <em>w</em> <em>2</em> , w 3</p>
<table>
<tbody>
<tr class="odd">
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
</tr>
</tbody>
</table>
<table>
<tbody>
<tr class="odd">
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
</tr>
</tbody>
</table>
<table>
<tbody>
<tr class="odd">
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
</tr>
</tbody>
</table>
<table>
<tbody>
<tr class="odd">
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
</tr>
</tbody>
</table>
</section>

<section id="managing-consistency" class="title-slide slide level1 center">
<h1>Managing consistency</h1>
<p>A look behind the curtain</p>
</section>

<section id="rdbms-vs-nosql-different-philosophies" class="title-slide slide level1 center">
<h1>RDBMS vs NoSQL: different philosophies</h1>
<ul>
<li>RDBMS come from decades of widespread usage
<ul>
<li>Strong focus on data consistency</li>
<li>Years of research activities to optimize performances</li>
<li>Highly complex systems (triggers, caching, security, etc.)</li>
</ul></li>
<li>NoSQL systems are designed to succeed where RDBMSs fail
<ul>
<li>Strong focus on data sharding and high availability</li>
<li>Quite simple systems (for now)</li>
<li>Speed and manageability rather than consistency at all costs</li>
</ul></li>
</ul>

<img data-src="imgs/slides87.png" class="r-stretch"></section>

<section id="consistency-an-example" class="title-slide slide level1 center">
<h1>Consistency: an example</h1>
<ul>
<li>Consider 1000€ to be transferred from bank account A to B; the transfer is made by:
<ul>
<li>Removing 1000€ from A</li>
<li>Adding 1000€ to B</li>
</ul></li>
<li>What should never happen
<ul>
<li>The money is removed from A but not added to B</li>
<li>The money is added twice to B</li>
<li>A query on the database shows an intermediate state
<ul>
<li>E.g., A+B = 0€</li>
</ul></li>
</ul></li>
<li>RDBMS adopt <em>transactions </em> to avoid this kind of issue</li>
</ul>
</section>

<section id="consistency-in-rdbmss-acid" class="title-slide slide level1 center">
<h1>Consistency in RDBMSs: ACID</h1>
<ul>
<li>Transactions guarantee four fundamental properties: ACID</li>
<li><em>A</em> <em>tomicity</em>
<ul>
<li>The transaction is indivisible: either it fully completes, or it fails</li>
<li>It cannot be completed partially</li>
</ul></li>
<li><em>C</em> <em>onsistency</em>
<ul>
<li>The transaction leaves the DB in a consistent state</li>
<li>Integrity constraints can never be violated</li>
</ul></li>
<li><em>I</em> <em>solation</em>
<ul>
<li>The transaction is independent from the others</li>
<li>In case of concurrent transactions, the effect is the same of their sequential execution</li>
</ul></li>
<li><em>D</em> <em>urability</em>
<ul>
<li>The DBMS protects the DB from failures</li>
</ul></li>
<li>Implementation of ACID properties relies on <em>locking mechanisms and logs</em>
<ul>
<li>Resources are locked, updates are logged</li>
<li>In case of problems, rollback to the original state</li>
<li>If no error occurs, unlock the resources</li>
</ul></li>
<li>Consistency is guaranteed to the detriment of speed and availability
<ul>
<li>User may have to wait</li>
<li>Hard to replicate this mechanism in a distributed environment</li>
</ul></li>
<li>But, sometimes, consistency is not that important
<ul>
<li>E.g.: e-commerce application</li>
<li>Shopping cart management requires speed and availability</li>
<li>Order emission requires consistency</li>
</ul></li>
</ul>
</section>

<section id="consistency-in-nosql" class="title-slide slide level1 center">
<h1>Consistency in NoSQL</h1>
<ul>
<li>Several attempts have been made to describe NoSQL properties with respect to ACID properties
<ul>
<li>CAP theorem</li>
<li>PACELC theorem</li>
<li>BASE philosophy</li>
</ul></li>
<li>They are not properties on which NoSQL systems rely
<ul>
<li>Rather, they simply <em>try </em> to describe their behavior</li>
</ul></li>
</ul>
</section>

<section>
<section id="consistency-in-nosql-cap" class="title-slide slide level1 center">
<h1>Consistency in NoSQL: CAP</h1>
<ul>
<li>“Theorem”: only two of the following three properties can be guaranteed</li>
<li><em>C</em> <em>onsistency: </em> the system is always consistent
<ul>
<li>Every node returns the same, most recent, successful write</li>
<li>Every client has the same view of the data</li>
</ul></li>
<li><em>A</em> <em>vailability: </em> the system is always available
<ul>
<li>Every non-failing node returns a response for all read and write requests in a reasonable amount of time</li>
</ul></li>
<li><em>P</em> <em>artition tolerance: </em> the system continues to function and upholds its consistency guarantees in spite of network partitions
<ul>
<li><em>In distributed systems, network partitioning</em> <em>is inevitably a possibility</em></li>
</ul></li>
</ul>

<img data-src="imgs/slides88.png" class="r-stretch"></section>
<section class="slide level2">

<p>CAP demonstration: https://dl.acm.org/doi/pdf/10.1145/564585.564601?casa_token=m69maazxkqIAAAAA:cBn5y1eKnJUh7Tl4GVsw9Hqv984qwQ3_b8XvSM_wM3U2zp_-363uPINWJADEmMt-8ZjPzA1yaoE</p>
<ul>
<li>Three situations
<ul>
<li>CA: the system cannot suffer from network partitioning (single server)</li>
<li>AP: in case of partitioning, the system sacrifices consistency (overbooking)</li>
<li>CP: in case of partitioning, the system sacrifices availability (bookings prevented)</li>
</ul></li>
<li>Theorem interpretation is not trivial
<ul>
<li>Asymmetric properties: consistency is sacrificed to favor speed at all times, not just when partitioning happens</li>
<li>Different application requirements  different algorithms handle these properties more strictly/loosely</li>
</ul></li>
</ul>
</section></section>
<section>
<section id="consistency-in-nosql-relaxing-cap" class="title-slide slide level1 center">
<h1>Consistency in NoSQL: relaxing CAP</h1>
<ul>
<li>Consider two users that want to book the same room when a network partition happens</li>
<li><strong>CP</strong>: no one can book (<em>A is sacrificed</em>)
<ul>
<li>Not the best solution</li>
</ul></li>
<li><strong>AP</strong>: both can book (<em>C is sacrificed</em>)
<ul>
<li>Possible overbooking: writing conflict to handle</li>
</ul></li>
<li>_ <strong>caP</strong> _: only one can book
<ul>
<li>The other will se the room available but cannot book it</li>
</ul></li>
<li><em>This is admissible only in certain scenarios</em>
<ul>
<li>Finance? Blogs? E-commerce?</li>
</ul></li>
<li>It’s important to understand:
<ul>
<li><em>What is the tolerance to obsolete reads</em></li>
<li><em>How large can the inconsistency window be</em></li>
</ul></li>
</ul>
</section>
<section class="slide level2">

<p>Gestione del conflitto in scrittura: Last one wins (vince l’ultimo che arriva) Segnalazione all’utente del conflitto Quorum</p>
</section></section>
<section>
<section id="consistency-in-nosql-pacelc" class="title-slide slide level1 center">
<h1>Consistency in NoSQL: PACELC</h1>
<ul>
<li>Evolution of the CAP theorem (less known, but more precise)
<ul>
<li>if (<em>P</em> <em>artition</em>) then { <em>A</em> <em>vaialbility</em> _ or <em>C</em> <em>onsistency</em>? }</li>
<li><em>E</em> <em>lse</em> { <em>L</em> <em>atency </em> or <em>C</em> <em>onsistency</em>? }</li>
</ul></li>
<li>Different behavior in case or in absence of partitioning
<ul>
<li>PA: in case of partitioning, the system sacrifices consistency (overbooking)</li>
<li>PC: in case of partitioning, the system sacrifices availability (bookings prevented)</li>
<li>EL: otherwise, the system sacrifices consistency in favor of speed</li>
<li>EC: otherwise, the system sacrifices speed in favor of consistency</li>
</ul></li>
<li>Four situations:
<ul>
<li>PA EL: system focused on speed and availability (main NoSQL philosophy)</li>
<li>PA EC: consistency sacrificed only when partitioning happens</li>
<li>PC EL: consistency enforced only when partitioning happens (e.g., Yahoo Sherpa)</li>
<li>PC EC: system focused on consistency (RDBMS)</li>
</ul></li>
</ul>
</section>
<section class="slide level2">

<p>http://dbmsmusings.blogspot.com/2010/04/problems-with-cap-and-yahoos-little.html</p>
</section></section>
<section id="consistency-in-nosql-base" class="title-slide slide level1 center">
<h1>Consistency in NoSQL: BASE</h1>
<ul>
<li>The CAP theorem is often cited as a justification for the use of weaker consistency models, for example _ <strong>BASE</strong> _
<ul>
<li><em>Basically Available Soft-state services with Eventual consistency</em></li>
</ul></li>
<li><em>B</em> <em>asic </em> <em>A</em> <em>vailability: </em> the system should always be available</li>
<li><em>S</em> <em>oft-state: </em> it is acceptable for the system to be temporarily inconsistent</li>
<li><em>E</em> <em>ventual consistency: </em> eventually, the system becomes consistent</li>
<li>ACID
<ul>
<li>Pessimistic approach (better safe than sorry)</li>
</ul></li>
<li>BASE
<ul>
<li>Optimistic approach (everything is going to be ok)</li>
<li>Higher throughput is better than enforcing consistency</li>
</ul></li>
</ul>
</section>

<section id="consistency-in-nosql-summary" class="title-slide slide level1 center">
<h1>Consistency in NoSQL: summary</h1>
<table>
<colgroup>
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 25%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">Source</th>
<th style="text-align: center;">Cause</th>
<th style="text-align: center;">Effect</th>
<th style="text-align: center;">Solution</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Replication(MS and P2P)</td>
<td style="text-align: center;">Write propagation delay between replicas is slow</td>
<td style="text-align: center;">Read conflicts</td>
<td style="text-align: center;">- Tolerate<br>- Read-your-writes<br>- Quorum</td>
</tr>
<tr class="even">
<td style="text-align: center;">Replication (P2P)</td>
<td style="text-align: center;">Two write operations can be issued on different replicas</td>
<td style="text-align: center;">Write conflicts</td>
<td style="text-align: center;">- Last write wins<br>- Conflict prevention<br>- Conflict detection<br>- Quorum</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Network partitioning</td>
<td style="text-align: center;">Inability to communicate with all replicas of a certain data</td>
<td style="text-align: center;">- Read conflicts<br>- Possibly write conflicts</td>
<td style="text-align: center;">- Relax CAP<br>- Prevent write conflicts<br>- Handle read conflict as above</td>
</tr>
<tr class="even">
<td style="text-align: center;">No ACID transactions</td>
<td style="text-align: center;">- An update over multiple records fails mid-query<br>- Two updates over multiple records are interleaved</td>
<td style="text-align: center;">Unrecoverable inconsistency</td>
<td style="text-align: center;">- Each system provides its own mechanism to offer limited ACID-like transactions</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Data de-normalization</td>
<td style="text-align: center;">The same data is repeated in different instances with different values</td>
<td style="text-align: center;">Inability to find the correct values</td>
<td style="text-align: center;">- Avoid denormalization if strong consistency is needed<br>- Data cleaning before analysis</td>
</tr>
</tbody>
</table>
</section>

<section id="one-size-does-not-fit-all" class="title-slide slide level1 center">
<h1>One size does not fit all</h1>
<p>To each application its own data model</p>
</section>

<section id="key-value-popular-dbs" class="title-slide slide level1 center">
<h1>Key-Value: popular DBs</h1>
<ul>
<li><strong>Redis</strong> (Data Structure server): <a href="http://redis.io/">http://redis.io/</a>
<ul>
<li>Supports complex fields (list, set, …) and operations on values (range, diff, …)</li>
</ul></li>
<li><strong>Memcached DB: </strong> <a href="http://memcached.org/">http://memcached.org/</a></li>
<li><strong>Riak</strong>: <a href="http://basho.com/riak/">http://basho.com/riak/</a></li>
</ul>
</section>

<section>
<section id="key-value-when-to-use" class="title-slide slide level1 center">
<h1>Key-Value: when to use</h1>
<ul>
<li>Very simple use cases
<ul>
<li>Independent data (no need to model relationships)</li>
<li>The typical query is a simple lookup</li>
<li>Need super-fast performance</li>
</ul></li>
<li>Examples
<ul>
<li><strong>Session information</strong>
<ul>
<li>Each web session is identified by its own sessionId: All related data can be stored with a PUT request and returned with a GET request</li>
</ul></li>
<li><strong>User profiles, preferences</strong>
<ul>
<li>Each user is uniquely identified (userId, username) and has her own preferences in terms of language, colors, timezone, products, etc. – <em>data that fits well within an aggregate</em></li>
</ul></li>
<li><strong>Shopping cart, chat services</strong>
<ul>
<li>Each e-commerce websites associates a shopping cart to a user; it can be stored as <em>an aggregate identified by the user ID</em></li>
</ul></li>
</ul></li>
</ul>
</section>
<section class="slide level2">

<p>1 RDBMS would be overkill</p>
</section></section>
<section>
<section id="key-value-real-use-cases" class="title-slide slide level1 center">
<h1>Key-Value: real use cases</h1>
<ul>
<li><strong>Crawling of web pages</strong>
<ul>
<li>The URL is the key, the whole page content (HTML, CSS, JS, images, ..)is the value</li>
</ul></li>
<li><strong>Twitter timeline</strong>
<ul>
<li>The user ID is the key, the list of mostrecent tweets to be shown is the value</li>
</ul></li>
<li><strong>Amazon S3 (Simple Storage Service)</strong>
<ul>
<li>A cloud-based file system service</li>
<li>Useful for personal backups, file sharing, website or apps publication</li>
<li>The more you store, the more you pay
<ul>
<li>Storage: approx. $0.03 per GB per month</li>
<li>Uploading files: approx. $0.005 per 1000 items</li>
<li>Downloading files: approx. $0.004 per 10,000 files* PLUS $0.09 per GB (first GB free)</li>
</ul></li>
</ul></li>
</ul>

<img data-src="imgs/slides89.png" class="r-stretch"></section>
<section class="slide level2">

<p>1 RDBMS would be overkill https://www.infoq.com/presentations/Real-Time-Delivery-Twitter http://highscalability.com/blog/2014/9/8/how-twitter-uses-redis-to-scale-105tb-ram-39mm-qps-10000-ins.html https://www.quora.com/Why-is-Twitter-not-using-NoSQL</p>
</section></section>
<section id="key-value-when-to-avoid" class="title-slide slide level1 center">
<h1>Key-Value: when to avoid</h1>
<ul>
<li><strong>Data with many relationships</strong>
<ul>
<li>When relationships between data (in the same or in different collections) must be followed</li>
<li>Some systems offer limited link-walking mechanisms</li>
</ul></li>
<li><strong>Multi-record operations</strong>
<ul>
<li>Because operations (mostly) involve one record at a time</li>
</ul></li>
<li><strong>Querying the data</strong>
<ul>
<li>If it is necessary to query the values, not just the key</li>
<li>Few systems offer limited functionalities (e.g., Riak Search)</li>
</ul></li>
</ul>
</section>

<section id="document-popular-dbs" class="title-slide slide level1 center">
<h1>Document: popular DBs</h1>
<p><strong>MongoDB</strong>: <a href="http://www.mongodb.org/">http://www.mongodb.org</a></p>
<p><strong>Couchbase: </strong> <a href="http://www.couchbase.com/">http://www.couchbase.com</a></p>
<p><strong>CouchDB</strong>: <a href="http://couchdb.apache.org/">http://couchdb.apache.org</a></p>
</section>

<section id="document-when-to-use" class="title-slide slide level1 center">
<h1>Document: when to use</h1>
<ul>
<li>Higher expressiveness
<ul>
<li>Store data according to a highly nested data model</li>
<li>Need to formulate complex queries on many fields</li>
</ul></li>
<li>Examples
<ul>
<li><strong>Event logs</strong>
<ul>
<li><em>Central repo to store event logs from many applications; </em> shard on app name or event type</li>
</ul></li>
<li><strong>CMS, blogging platforms</strong>
<ul>
<li><em>The absence of a predefined schema </em> <em>fits well</em> _ within content management systems (CMS) or website management applications, to handle comments, registrations and user profiles</li>
</ul></li>
<li><strong>Web Analytics or Real-Time Analytics</strong>
<ul>
<li><em>The ability to update only specific fields </em> enables fast update of analytical metrics</li>
<li><em>Text indexing</em> enables real-time sentiment analysis and social media monitoring</li>
</ul></li>
<li><strong>E-commerce applications</strong>
<ul>
<li><em>Schema flexibility is often required </em> to store products and orders, as well as to enable schema evolution without incurring into refactoring or migration costs</li>
</ul></li>
</ul></li>
</ul>
</section>

<section id="document-real-use-cases" class="title-slide slide level1 center">
<h1>Document: real use cases</h1>
<ul>
<li><strong>Adversting</strong> __ services__
<ul>
<li>MongoDB was born as a system for banner ads
<ul>
<li>24/7 availability and high performance</li>
<li>Complex rules to find the right banner based on user’s interests</li>
<li>Handle several kinds of ads and show detailed analytics</li>
</ul></li>
</ul></li>
<li><strong>Internet of Things</strong>
<ul>
<li>Real-time management of sensor-based data</li>
<li>Bosch uses MongoDB to capture data from cars (breaks, ABS, windscreen wiper, etc.) and aircrafts maintenance tools
<ul>
<li>Business rules are applied to warn the pilot when the breaking system pressure falls under a critical threshold, or the maintenance operator when the tool is used improperly</li>
</ul></li>
<li>Technogym uses MongoDB to capture data from gym equipment</li>
</ul></li>
</ul>
</section>

<section id="document-when-to-avoid" class="title-slide slide level1 center">
<h1>Document: when to avoid</h1>
<ul>
<li><strong>ACID transactions requirement</strong>
<ul>
<li>If not for a few exceptions (e.g., RavenDB), document databases are not suited for cross-document atomicity</li>
</ul></li>
<li><strong>Queries on high-variety data</strong>
<ul>
<li><em>If the aggregate structure continuously evolves, queries must be constantly updated </em> (and normalization clashes with the concept of aggregate)</li>
</ul></li>
</ul>
</section>

<section id="wide-column-popular-dbs" class="title-slide slide level1 center">
<h1>Wide column: popular DBs</h1>
<p><strong>Cassandra</strong>: <a href="http://cassandra.apache.org/">http://cassandra.apache.org</a></p>
<p><strong>HBase</strong>: <a href="https://hbase.apache.org/">https://hbase.apache.org</a></p>
<p><strong>Google </strong> <strong>BigTable</strong>: <a href="https://cloud.google.com/bigtable/">https://cloud.google.com/bigtable</a></p>
</section>

<section id="wide-column-when-to-use" class="title-slide slide level1 center">
<h1>Wide column: when to use</h1>
<ul>
<li>Compromise between expressiveness and simplicity
<ul>
<li>Limited (but some) requirements in terms of data model</li>
<li>Limited (but some) requirements in terms of querying records</li>
</ul></li>
<li>Examples
<ul>
<li><strong>Event logs; CMS, blogging platforms</strong>
<ul>
<li>Similarly to document databases, <em>different applications may use different columns</em></li>
</ul></li>
<li><strong>Sparse matrixes</strong>
<ul>
<li>While an RDBMS would store <em>null </em> values, a wide column <em>stores only the columns for which a value is specified</em></li>
</ul></li>
<li><strong>GIS applications</strong>
<ul>
<li>Pieces of a map (tiles) can be stored as <em>couples of latitude and longitude</em></li>
</ul></li>
</ul></li>
</ul>
</section>

<section>
<section id="wide-column-real-use-cases" class="title-slide slide level1 center">
<h1>Wide column: real use cases</h1>
<ul>
<li><strong>Google applications</strong>
<ul>
<li>BigTable is the DB used by Google for most of its applications, including Search, Analytics, Maps and Gmail</li>
</ul></li>
<li><strong>User profiles and preferences</strong>
<ul>
<li>Spotify uses Cassandra to store metadata about users, artists, songs, playlists, etc.</li>
</ul></li>
<li><strong>Manhattan</strong>
<ul>
<li>After using Cassandra, Twitter ha developed its own proprietary NoSQL system to support most of its services</li>
</ul></li>
</ul>
</section>
<section class="slide level2">

<p>Netflix: 12M trans/sec.&nbsp;Ebay, &gt;100TB. IoT</p>
<p>https://labs.spotify.com/2015/01/09/personalization-at-spotify-using-cassandra/</p>
<p>https://academy.datastax.com/resources/ds220-data-modeling?unit=use-cases-use-case-introduction</p>
</section></section>
<section>
<section id="wide-column-when-to-avoid" class="title-slide slide level1 center">
<h1>Wide column: when to avoid</h1>
<ul>
<li><strong>Same as for document model</strong>
<ul>
<li>ACID transactions requirement</li>
<li>Queries on high-variety data</li>
</ul></li>
<li><strong>Need for full query expressiveness</strong>
<ul>
<li>Joins are highly discouraged</li>
<li>Limited support for filters and group bys</li>
</ul></li>
</ul>
</section>
<section class="slide level2">

<p>Prototipazioni: nelle prima fasi di progetto, i pattern delle query possono cambiare frequentemente, con la conseguenza di dover riprogettare le famiglie di colonne. In Cassandra, the cost may be higher for query change as compared to schema change.</p>
</section></section>
<section id="graph-popular-dbs" class="title-slide slide level1 center">
<h1>Graph: popular DBs</h1>
<p><strong>Neo4J</strong>: <a href="http://neo4j.com/">http://neo4j.com</a></p>
<p><strong>TigerGraph</strong>: <a href="https://www.tigergraph.com/">https://www.tigergraph.com/</a></p>
</section>

<section id="graph-when-to-use" class="title-slide slide level1 center">
<h1>Graph: when to use</h1>
<ul>
<li><strong>Interlinked data</strong>
<ul>
<li><em>Social networks</em> are one of the most typical use case of graph databases (e.g., to store friendships or work relationships); <em>every relationship-centric domain is a good one</em></li>
</ul></li>
<li><strong>Routing and location-based services</strong>
<ul>
<li>Applications working on the <em>TSP (Travelling Salesman Problem)</em> problem</li>
<li>Location-based application that, for instance, recommend the best restaurant nearby; in this case, <em>relationships model the distance between node</em></li>
</ul></li>
<li><strong>Recommendation applications, fraud-detection</strong>
<ul>
<li>Systems recommending «the products bought by your friends», or «the products bought by those who bought your same products»</li>
<li>When relationships model behaviors, outlier detection may be useful to identify frauds</li>
</ul></li>
</ul>
</section>

<section>
<section id="graph-real-use-cases" class="title-slide slide level1 center">
<h1>Graph: real use cases</h1>
<ul>
<li><strong>Relationships analysis</strong>
<ul>
<li>Finding common friends (e.g., friend-of-a-friend) in a social network</li>
<li>Identifying clusters of phone calls that identify a criminal network</li>
<li>Analyzing flows of money to identifying money recycling patterns or credit card theft</li>
<li>Main users: law firms, police, intelligence agencies
<ul>
<li><a href="https://neo4j.com/use-cases/fraud-detection/">https://neo4j.com/use-cases/fraud-detection/</a></li>
</ul></li>
<li>Useful for text analysis as well (Natural Language Processing)</li>
</ul></li>
<li><strong>Inference</strong>
<ul>
<li>Creating rules that define new knowledge based on existing patterns (e.g., transitive relationships, trust mechanisms)</li>
</ul></li>
</ul>
</section>
<section class="slide level2">

<p>https://developer.ibm.com/dwblog/2017/detecting-complex-fraud-real-time-graph-databases/</p>
</section></section>
<section id="graph-when-to-avoid" class="title-slide slide level1 center">
<h1>Graph: when to avoid</h1>
<ul>
<li><strong>Data-intensive applications</strong>
<ul>
<li>Traversing the graph is trivial, but <em>analyzing the whole graph can be expensive</em></li>
<li>There exist framework for distributed graph analysis (e.g., Apache Giraph), but they do not rely on a graph DB</li>
</ul></li>
</ul>
</section>

<section>
<section id="polyglot-persistence" class="title-slide slide level1 center">
<h1>Polyglot persistence</h1>
<ul>
<li><em>Different databases are designed to solve </em> <em>differen</em> <em>t problems</em></li>
<li><em>Using a single DBMS to handle everything …</em>
<ul>
<li>Operational data</li>
<li>Temporary session information</li>
<li>Graph traversing</li>
<li>OLAP analyses</li>
<li>…</li>
</ul></li>
<li><em>… usually lead to inefficient solutions</em></li>
<li>Each activity has its own requirements (availability, consistency, fault tolerance, etc.)</li>
</ul>

<img data-src="imgs/slides90.jpg" class="r-stretch"></section>
<section class="slide level2">

<p>Termine derivato da “programmazione poliglotta”</p>
</section></section>
<section>
<section id="traditional-approach" class="title-slide slide level1 center">
<h1>Traditional approach</h1>
<p>The <em>one-size-fits-all</em> solution</p>

<img data-src="imgs/slides91.png" class="r-stretch"></section>
<section class="slide level2">

<p>The session, shopping cart, or order data do not need the same properties of availability, consistency, or backup requirements. Does session management storage need the same rigorous backup/recovery strategy as the e-commerce orders data? Does the session management storage need more availability of an instance of database engine to write/read session data?</p>
<p>In 2006, Neal Ford coined the term polyglot programming, to express the idea that applications should be written in a mix of languages to take advantage of the fact that different languages are suitable for tackling different problems. Complex applications combine different types of problems, so picking the right language for each job may be more productive than trying to fit all aspects into a single language.</p>
</section></section>
<section>
<section id="polyglot-data-management" class="title-slide slide level1 center">
<h1>Polyglot data management</h1>
<p>The <em>one-size-fits-all</em> solution</p>
<p>Replaced by the <em>polyglot </em> solution</p>

<img data-src="imgs/slides92.png" class="r-stretch"></section>
<section class="slide level2">

<p>A key-value data store could be used to store the shopping cart data before the order is confirmed by the customer and also store the session data so that the RDBMS is not used for this transient data. Key-value stores make sense here since the shopping cart is usually accessed by user ID and, once confirmed and paid by the customer, can be saved in the RDBMS. Similarly, session data is keyed by the session ID. If we need to recommend products to customers when they place products into their shopping carts—for example, “ your friends also bought these products” or “ your friends bought these accessories for this product”—then introducing a graph data store in the mix becomes relevant.</p>
<p>Even using specialized relational databases for different purposes, such as data warehousing appliances or analytics appliances within the same application, can be viewed as polyglot persistence</p>
</section></section>
<section id="service-oriented-polyglot-data-management" class="title-slide slide level1 center">
<h1>Service-oriented polyglot data management</h1>
<ul>
<li>Each DB should be “embedded” within services, which offer API services to enable data access and manipulation
<ul>
<li>Several NoSQL systems (e.g., Riak, Neo4J) already provide REST APIs</li>
</ul></li>
</ul>

<img data-src="imgs/slides93.png" class="r-stretch"></section>

<section>
<section id="supporting-existing-technologies" class="title-slide slide level1 center">
<h1>Supporting existing technologies</h1>
<p>If the current solution cannot be changed, NoSQL systems can still support the existing ones</p>

<img data-src="imgs/slides94.png" class="r-stretch"></section>
<section class="slide level2">

<p>While doing this, we need to update the indexed data as the data in the application database changes. The process of updating the data can be real-time or batch, as long as we ensure that the application can deal with stale data in the index/search engine. The event sourcing (“ Event Sourcing,” p.&nbsp;142) pattern can be used to update the index.</p>
</section></section>
<section id="beyond-nosql" class="title-slide slide level1 center">
<h1>Beyond NoSQL</h1>
<ul>
<li>NewSQL systems
<ul>
<li>Combine the benefits from both relational and NoSQL worlds</li>
<li>Ensure scalability without compromising consistency, but by <strong>compromising some availability</strong></li>
</ul></li>
<li>Extended RDBMSs
<ul>
<li>KV implementable as a table with two fields: a string key, and a blob value</li>
<li>Cypher query language on top of a relational implementation of a graph</li>
<li>Hstore data type in PostgreSQL for wide-column-like implementation</li>
<li><strong>Scalabilty</strong> __ issue remains__</li>
</ul></li>
<li>Multi-model NoSQL DBMSs
<ul>
<li>ArangoDB, OrientDB</li>
<li><strong>Support all NoSQL data models, but not the relational one</strong></li>
</ul></li>
<li>Database-as-a-service
<ul>
<li>All cloud providers offer storage services supporting all data models</li>
</ul></li>
</ul>
</section>

<section id="newsection-2" class="title-slide slide level1 center">
<h1>– newsection –</h1>

</section>

<section id="cloud-computing" class="title-slide slide level1 center">
<h1>Cloud computing</h1>

</section>

<section id="section" class="title-slide slide level1 center">
<h1></h1>

<img data-src="imgs/slides95.png" class="r-stretch"><p><a href="https://xkcd.com/1444/">https://xkcd.com/1444/</a></p>
</section>

<section id="reference-scenario" class="title-slide slide level1 center">
<h1>Reference scenario</h1>
<ul>
<li>The big-data cube
<ul>
<li>Volume: small to big</li>
<li>Variety: structure to unstructured</li>
<li>Velocity: pull to push</li>
</ul></li>
</ul>
<p>Meijer, Erik. “Your mouse is a database.” <em>Communications of the ACM</em> 55.5 (2012): 66-73.</p>
<ul>
<li><strong>Variety</strong>
<ul>
<li><strong>Structured</strong>
<ul>
<li>Relational tuples with FK/PK relationships</li>
</ul></li>
<li><strong>Unstructured</strong>
<ul>
<li>Key-value</li>
<li>Columnar</li>
<li>Document-based</li>
<li>Graph</li>
<li>…</li>
</ul></li>
</ul></li>
</ul>
<p><img data-src="imgs/slides96.png"></p>
<p><img data-src="imgs/slides97.png"></p>
<p><a href="https://www.datamation.com/big-data/structured-vs-unstructured-data/">https://www.datamation.com/big-data/structured-vs-unstructured-data/</a> (accessed 2022-08-01)</p>
<ul>
<li><strong>Velocity</strong> (latency)
<ul>
<li><strong>High</strong>: clients synchronously pulling data from sources</li>
<li><strong>Low</strong>: sources asynchronously pushing data to clients</li>
</ul></li>
<li><strong>Velocity</strong> (speed; dual to latency)
<ul>
<li><strong>High</strong>: processing in real-time (milliseconds) or near-real time (minutes)</li>
<li><strong>Low</strong>: processing can take hours</li>
</ul></li>
</ul>
<p><img data-src="imgs/slides98.png"></p>
<ul>
<li><strong>Acceleration</strong>
<ul>
<li>Velocity is not constant, data comes in bursts</li>
<li>Take Twitter as an example
<ul>
<li>Hashtags can become hugely popular and appear hundreds of times in just seconds</li>
<li>… or slow down to one tag an hour</li>
</ul></li>
<li>Your system must be able to efficiently handle the peak as well as the lows</li>
</ul></li>
</ul>
<p><img data-src="imgs/slides99.png"></p>
<p><img data-src="imgs/slides100.jpg"></p>
<p><img data-src="imgs/slides101.jpg"></p>
<p><img data-src="imgs/slides102.png"></p>
<p><a href="https://www.domo.com/learn/data-never-sleeps-9">https://www.domo.com/learn/data-never-sleeps-9</a></p>
<p>The Netflix scenario</p>
<p><a href="https://www.domo.com/learn/data-never-sleeps-9">https://www.domo.com/learn/data-never-sleeps-9</a></p>
<p>Collecting data</p>
<p>Processing data</p>
<ul>
<li><p>_ <strong>Scheduled Batch</strong> _</p>
<ul>
<li>Large volume of data processed on a regular scheduled basis</li>
<li>Velocity is very predictable</li>
</ul></li>
<li><p>_ <strong>Periodic</strong> _:</p>
<ul>
<li>Data processed at irregular times (e.g., after collecting a certain —large— amount of data)</li>
<li>Velocity is less predictable</li>
</ul></li>
<li><p>_ <strong>Near real-time</strong> _</p>
<ul>
<li>Streaming data processed in small individual batches collected and processed within minutes</li>
<li>Velocity is a huge concern</li>
</ul></li>
<li><p>_ <strong>Real-time</strong> _</p>
<ul>
<li>Streaming data collected and processed in very small individual batches within milliseconds</li>
<li>Velocity is the paramount concern</li>
</ul></li>
<li><p>_ <strong>Batch and periodic</strong> _</p>
<ul>
<li>Once data has been collected, processing can be done in a controlled environment</li>
<li>There is time to plan for the appropriate resources</li>
</ul></li>
<li><p>_ <strong>Near real-time and real-time</strong> _</p>
<ul>
<li>Collection of the data leads to an immediate need for processing</li>
<li>Depending on the complexity of the processing (cleansing, scrubbing, curation), this can slow down the velocity of the solution significantly</li>
<li>Plan accordingly</li>
</ul></li>
<li><p>Plus other Vs</p>
<ul>
<li><strong>Veracity</strong>: __ __ data trustworthiness/quality</li>
<li><strong>Value</strong>: ability to extract meaningful information</li>
<li>…</li>
</ul></li>
<li><p>Our focus</p>
<ul>
<li>(Un)Structured big-data batch</li>
<li>(Un)Structured big-data streams</li>
</ul></li>
<li><p><strong>Goal</strong>: keep in mind the cube to</p></li>
<li><p>categorize the services</p></li>
<li><p>Scenario 1</p>
<ul>
<li>My business has a set of 15 JSON data files that are each about 2.5 GB in size.</li>
<li>They are&nbsp;placed on a file server once an hour, and they must be ingested as soon as they arrive in this location.</li>
<li>Data must be combined with all transactions from financial dashboard for this same period, then compared to the recommendations from marketing engine</li>
<li>All&nbsp;data is fully cleansed.</li>
<li>The results from this time period must be made available to decision makers by 10 minutes after the hour in the form of financial dashboards.</li>
</ul></li>
</ul>
<p><em>Which Vs are involved?</em></p>
<ul>
<li>Scenario 1
<ul>
<li>My business has a set of 15 JSON data files that are each about 2.5 GB in size.</li>
<li>They are&nbsp;placed on a file server once an hour, and they must be ingested as soon as they arrive in this location.</li>
<li>Data must be combined with all transactions from financial dashboard for this same period, then compared to the recommendations from marketing engine</li>
<li>All&nbsp;data is fully cleansed.</li>
<li>The results from this time period must be made available to decision makers by 10 minutes after the hour in the form of financial dashboards.</li>
</ul></li>
<li>Which Vs are involved?
<ul>
<li><em>Volume</em> This scenario describes huge JSON files to be combined with transactional data and marketing data.</li>
<li><em>Velocity</em> “Wait - now hurry up!” Wait to collect data for a full hour and then produce meaningful results in 10 minutes <em>(is it batch or stream processing?)</em></li>
<li><em>Variety</em> three data source types: log files, transactional data, and recommendation information</li>
<li><em>Value</em> populate dashboards that are used by decision makers as soon as they are made available. The value is reached because it requires an understanding of what the organization is trying to accomplish</li>
</ul></li>
<li>Scenario 2
<ul>
<li>My business compiles data generated by hundreds of corporations.</li>
<li>This data is delivered to us in very large files, transactional updates, and even data streams.</li>
<li>The data must be cleansed and prepared to ensure that rogue inputs do not skew the results.</li>
<li>Knowing the data source for each record is vital to the work we do.</li>
<li>A large portion of the data gathered is irrelevant to our analysis, so this data must be eliminated.</li>
<li>The final requirement is that all data must be combined and loaded into our data warehouse, where it will be analyzed.</li>
</ul></li>
</ul>
<p><em>Which Vs are involved?</em></p>
<ul>
<li>Scenario 2
<ul>
<li>My business compiles data generated by hundreds of corporations.</li>
<li>This data is delivered to us in very large files, transactional updates, and even data streams.</li>
<li>The data must be cleansed and prepared to ensure that rogue inputs do not skew the results.</li>
<li>Knowing the data source for each record is vital to the work we do.</li>
<li>A large portion of the data gathered is irrelevant to our analysis, so this data must be eliminated.</li>
<li>The final requirement is that all data must be combined and loaded into our data warehouse, where it will be analyzed.</li>
</ul></li>
<li>Which Vs are involved?
<ul>
<li><em>Volume</em> The data is delivered in very large files, transactional updates, and even in data streams</li>
<li><em>Variety</em> The business will need to combine the data from all three sources into a single data warehouse.</li>
<li><em>Veracity</em> The data is known to be suspect. The data must be cleansed and prepared to ensure that rogue inputs do not skew the results. Knowing the data source for each record is vital to the work we do.</li>
</ul></li>
</ul>
</section>

<section id="data-driven-companies" class="title-slide slide level1 center">
<h1>Data-driven companies</h1>
<ul>
<li><em>Data-driven company </em> refers to companies where decisions and processes are supported by data
<ul>
<li>Decisions are based on quantitative rather than qualitative knowledge</li>
<li>Processes &amp; Knowledge are an asset of the company and are not lost if managers change</li>
<li>The gap between a data-driven decision and a good decision is a good manager</li>
</ul></li>
<li>Adopting a data-driven mindset goes far beyond adopting a business intelligence solution and entails:
<ul>
<li><em>Create a data culture</em></li>
<li><em>Change the mindset of managers</em></li>
<li><em>Change processes</em></li>
<li><em>Improve the quality of all the data</em></li>
</ul></li>
</ul>
</section>

<section id="why-going-cloud" class="title-slide slide level1 center">
<h1>Why going cloud?</h1>
<ul>
<li><em>Digitalization</em> is a journey that involves three main dimensions
<ul>
<li>Moving from A to B is a multi-year process made of intermediate goals</li>
<li>Each of which must be <em>feasible</em>
<ul>
<li>Solves a company pain and brings value</li>
<li>Can be accomplished in a limited time range (typically less than one year)</li>
<li>Costs must be economically related to gains</li>
</ul></li>
</ul></li>
</ul>
<p>Are processes extensively digitalized and produces reliable data?</p>
<p><em>Technological</em> <em>infrastructure</em></p>
<p>Do we have the right persons to drive the project and exploit the results?</p>
<p><em>Data quality </em></p>
<p><em>&amp; quantity</em></p>
<p>Is the technogical infrastructure appropriate to support data collection and analysis?</p>
<ul>
<li><strong>Cloud computing</strong> (National Institute of Standards and Technology)
<ul>
<li><em>“A model for enabling </em> <em>ubiquitous, convenient, on-demand </em> <em>network access to a </em> <em>shared pool</em> _ of configurable computing resources (e.g., networks, servers, storage, services) that can be rapidly provisioned and released with _ <em>minimal management effort </em> <em>or service provider interaction.”</em></li>
<li>On-demand self-service (consume services when you want)</li>
<li>Broad network access (consume services from anywhere)</li>
<li>Resource pooling (infrastructure, virtual platforms, and applications)</li>
<li>Rapid elasticity (enable horizontal scalability)</li>
<li>Measured service (pay for the service you consume as you consume)</li>
</ul></li>
<li><strong>Digital transformation </strong> involves the <strong>cloud</strong> to create/change business flows
<ul>
<li>Often involves changing the company culture to adapt to this new way of doing business</li>
<li>One of the end goal is to meet ever-changing business and market demand</li>
</ul></li>
<li>Goal: adjusts capacity to have predictable performance at the lowest cost</li>
<li><strong>Scalability</strong> that is not possible on premises
<ul>
<li>Scale from one to thousands of servers</li>
</ul></li>
<li><strong>Elasticity</strong>
<ul>
<li>Automatically scale resources in response to run-time conditions</li>
<li>Adapt to changes in workload by turning on/off resources to match the necessary capacity</li>
<li>Core justification for the cloud adoption</li>
</ul></li>
<li>Hardware scalability
<ul>
<li>No longer think about rack space, switches, and power supplies, etc.</li>
</ul></li>
<li>Grow storage from GBs to PBs
<ul>
<li>1PB: one hundred 10TB Enterprise Capacity 3.5 HDD hard drives</li>
</ul></li>
</ul>

<img data-src="imgs/slides103.jpg" class="r-stretch"><p><a href="https://blog.seagate.com/business/linus-tech-tips-want-petabyte-system/">https://blog.seagate.com/business/linus-tech-tips-want-petabyte-system/</a></p>
<ul>
<li><strong>Resource pooling</strong>
<ul>
<li>Enable <em>cost-sharing</em> , a resource to serve different consumers</li>
<li>Resources are dynamically reassigned according to demands</li>
<li>Based on <em>virtualization</em> , _ _ running multiple virtual instances on top of a physical computer system</li>
<li>Economy of scale for physical resources</li>
</ul></li>
<li><strong>Reliability</strong>
<ul>
<li>Built to handle failures</li>
<li>Fault-tolerant or highly available</li>
</ul></li>
<li>Worldwide <strong>deployment</strong>
<ul>
<li>Deploy applications as close to customers as possible
<ul>
<li>E.g., to reduce network latency</li>
</ul></li>
<li>Improve data locality</li>
<li>Compliant to privacy regulations (e.g., GDPR)</li>
</ul></li>
<li>Measured <strong>quality of service</strong>
<ul>
<li>Services leverage a quantitative qualitative metering capability making pay-as-you-go (or pay-per-use) billing and validation of the service quality available</li>
</ul></li>
<li>Service <strong>integration</strong>
<ul>
<li>Do not reinvent the wheel, eliminate repetitive tasks
<ul>
<li>Use services that solve common problems (e.g., load balancing, queuing)</li>
</ul></li>
<li>Abstract and automatically adapt the architecture to requirements
<ul>
<li>E.g., create (test) environments on demand</li>
</ul></li>
</ul></li>
<li><em>Integration</em> and <em>abstraction</em> are drivers of change
<ul>
<li>From <em>databases</em> to <em>data platforms</em></li>
<li>From <em>on-premises</em> to <em>serverless</em> architectures</li>
<li>From <em>custom</em> to <em>standardized</em> data pipelines</li>
</ul></li>
</ul>
</section>

<section>
<section id="is-cloud-a-silver-bullet" class="title-slide slide level1 center">
<h1>Is cloud a silver bullet?</h1>

<img data-src="imgs/slides104.png" class="r-stretch"><p><a href="https://www.reuters.com/article/us-france-ovh-fire-idUSKBN2B20NU">https://www.reuters.com/article/us-france-ovh-fire-idUSKBN2B20NU</a></p>
<ul>
<li>Cloud computing is the outsourcing of a company’s hardware and software architecture
<ul>
<li>Which are the risks and issues?</li>
</ul></li>
</ul>
</section>
<section class="slide level2">

<p>Google has a long track record on clean energy: in 2007, Google became the first major company to become carbon neutral. And in 2017, Google became the first company of our size to match 100% of its electricity consumption with renewable energy. Today, Google Cloud is the only major cloud provider to purchase enough renewable energy to cover our entire operations, and over the years, we’ve purchased more wind and solar power than any other corporation in history.&nbsp; But wind and solar power don’t work in all places at all times. Though we buy enough renewable energy on average to match our data centers’&nbsp;electricity consumption, that average is an annual average. Thus, for a particular data center, at any given time we may have too much renewable power, or too little. When we have too much, we feed it into the local grid so someone else can consume it. When we have too little, we draw power from the local grid, and that power may not be renewable.</p>
<p><img data-src="imgs/slides105.png"></p>
<p><img data-src="imgs/slides106.png"></p>
<p>Left: Mytton, David. “Data centre water consumption.” <em>npj</em> _ Clean Water_ 4.1 (2021): 1-6.Right: <a href="https://cloud.google.com/blog/topics/inside-google-cloud/announcing-round-the-clock-clean-energy-for-cloud">https://cloud.google.com/blog/topics/inside-google-cloud/announcing-round-the-clock-clean-energy-for-cloud</a> (accessed 2022-08-01)</p>
</section>
<section class="slide level2">

<p>Google has a long track record on clean energy: in 2007, Google became the first major company to become carbon neutral. And in 2017, Google became the first company of our size to match 100% of its electricity consumption with renewable energy. Today, Google Cloud is the only major cloud provider to purchase enough renewable energy to cover our entire operations, and over the years, we’ve purchased more wind and solar power than any other corporation in history.&nbsp; But wind and solar power don’t work in all places at all times. Though we buy enough renewable energy on average to match our data centers’&nbsp;electricity consumption, that average is an annual average. Thus, for a particular data center, at any given time we may have too much renewable power, or too little. When we have too much, we feed it into the local grid so someone else can consume it. When we have too little, we draw power from the local grid, and that power may not be renewable.</p>
</section></section>
<section id="section-1" class="title-slide slide level1 center">
<h1></h1>

<img data-src="imgs/slides107.png" class="r-stretch"><p><a href="https://xkcd.com/908/">https://xkcd.com/908/</a></p>
</section>

<section id="cloud-computing-types-of-cloud" class="title-slide slide level1 center">
<h1>Cloud computing: types of cloud</h1>
<ul>
<li>There are different types of cloud
<ul>
<li><strong>Public</strong>: accessible to anyone willing to pay (e.g., Microsoft, AWS, Google)</li>
<li><strong>Private</strong>: accessible by individuals within an institution
<ul>
<li>In public cloud, any resources that you are not using can be used by other</li>
<li>Users share the costs</li>
<li>Cost-sharing disappears in private clouds</li>
</ul></li>
<li><strong>Hybrid</strong>: a mix of the previous</li>
</ul></li>
</ul>
<p><img data-src="imgs/slides108.png"></p>
<ul>
<li>Cloud services are hosted in separate geographic areas
<ul>
<li>Locations are composed of <strong>regions</strong> and <strong>availability zones</strong></li>
</ul></li>
<li>Region (e.g., us-east-1)
<ul>
<li>Is an independent geographical area that groups data centers</li>
<li>Has availability zones</li>
</ul></li>
<li>Availability zones in a region
<ul>
<li>A data center</li>
<li>Connected through low-latency links</li>
<li>Resources are usually replicated across zones but not regions</li>
</ul></li>
</ul>
<p><img data-src="imgs/slides109.png"></p>
<p><a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-zones.html">https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-zones.html</a></p>
</section>

<section id="cloud-computing-principal-vendors" class="title-slide slide level1 center">
<h1>Cloud computing: principal vendors</h1>

<img data-src="imgs/slides110.png" class="r-stretch"><ul>
<li>Gartner Magic Quadrant
<ul>
<li>Understanding the technology providers to consider for an investment</li>
<li><strong>Leaders</strong> execute well and are well positioned for tomorrow</li>
<li><strong>Visionaries</strong> understand where the market is going but do not yet execute well</li>
<li><strong>Niche Players</strong> focus successfully on a small segment, or are unfocused and do not out-innovate or outperform others</li>
<li><strong>Challengers</strong> execute well but do not demonstrate an understanding of market direction</li>
<li>Focusing on leaders isn’t always the best
<ul>
<li>A niche player may support needs better than a market leader. It depends on how the provider aligns with business goals</li>
</ul></li>
</ul></li>
</ul>
<p><a href="https://www.gartner.com/en/research/methodologies/magic-quadrants-research">https://www.gartner.com/en/research/methodologies/magic-quadrants-research</a></p>
</section>

<section id="cloud-computing-deployment-models" class="title-slide slide level1 center">
<h1>Cloud computing: deployment models</h1>
<ul>
<li>On a cloud architecture, you can rely on <em>serverless</em> or <em>managed </em> services</li>
<li><em>Serverless</em>
<ul>
<li>Standalone independent services built for a specific purpose and integrated by cloud service provider</li>
<li>No visibility into the machines
<ul>
<li>There are still servers in serverless, but they are abstracted away</li>
<li>No server management, do not have to manage any servers or scale them</li>
<li>E.g., when you run a query on <a href="https://cloud.google.com/blog/products/bigquery/separation-of-storage-and-compute-in-bigquery">BigQuery</a> you do not know how many machines were used</li>
</ul></li>
<li>Pay for what your application uses, usually per request or per usage</li>
</ul></li>
<li><em>(Fully) Managed</em>
<ul>
<li>Visibility and control of machines
<ul>
<li>You can choose the number of machines that are being used to run your application</li>
</ul></li>
<li>Do not have to set up any machines, the management and backup are taken care for you</li>
<li>Pay for machine runtime, however long you run the machines and resources that your application uses</li>
</ul></li>
</ul>
<p><a href="https://cloud.google.com/blog/topics/developers-practitioners/serverless-vs-fully-managed-whats-difference">https://cloud.google.com/blog/topics/developers-practitioners/serverless-vs-fully-managed-whats-difference</a> (accessed 2020-08-01)</p>
<ul>
<li>Understanding architectures is paramount to successful systems
<ul>
<li>Good architectures help to scale</li>
<li>Poor architectures cause issues that necessitate a costly rewrite</li>
</ul></li>
<li><strong>XaaS</strong> __ (anything as a service)__
<ul>
<li>A collective term that refers to the delivery of anything as a service</li>
<li>It encompasses the products, tools and technologies that vendors deliver to users</li>
</ul></li>
</ul>
<p><img data-src="imgs/slides111.png"></p>
<ul>
<li><strong>On-premises</strong>
<ul>
<li>Provisioning servers is time-consuming
<ul>
<li>A non-trivial environment is hard to set up</li>
</ul></li>
<li>Require dedicated operations people</li>
<li>Often a distraction from strategic tasks</li>
</ul></li>
<li><strong>Infrastructure as a service (IaaS)</strong>
<ul>
<li>A computing infrastructure provisioned and managed over the internet (e.g., AWS EC2)</li>
<li>Avoid expense/complexity of buying/managing physical servers/data-centers</li>
<li>IaaS overcomes issues on-premises</li>
<li>Possibly requires to manage many environments</li>
</ul></li>
<li><strong>Platform as a Service (PaaS)</strong>
<ul>
<li>A development and deployment environment in the cloud (e.g., AWS Elastic Beanstalk)</li>
<li>Support complete application life-cycle: building, testing, deploying, etc.</li>
<li>Avoid expense/complexity of managing licenses and application infrastructure</li>
</ul></li>
<li><strong>PaaS</strong> and <strong>containers</strong> are potential solutions to inconsistent infrastructures</li>
<li>PaaS provides a platform for users to run their software
<ul>
<li>Developers write software targeting features/capabilities of the platform</li>
</ul></li>
<li>Containerization isolates an application with its own environment
<ul>
<li>Lightweight alternative to full virtualization</li>
<li>Containers are isolated but need to be deployed to (public/private) server</li>
<li>Excellent solution when dependencies are in play</li>
<li>Housekeeping challenges and complexities</li>
</ul></li>
<li><em>Containers</em> and <em>virtual machines </em> are packaged computing environments</li>
<li><em>Containers</em>
<ul>
<li>On top of physical server and its host OS</li>
<li>Share the host OS kernel</li>
<li>Shared components are read-only</li>
<li>“Light”, take seconds to start</li>
</ul></li>
<li><em>Virtual machines</em>
<ul>
<li>Emulate a hardware/software system</li>
<li>On top of a hypervisor (VM monitor)</li>
</ul></li>
</ul>
<p><img data-src="imgs/slides112.jpg"></p>
<ul>
<li><strong>Function as a Service (</strong> <strong>FaaS</strong> <strong>)</strong>
<ul>
<li>A coding environment, cloud provider provisions platform to run the code (e.g., AWS Lambda)</li>
<li>Infrastructure provisioning and management are invisible to the developer</li>
</ul></li>
<li>Principles of FaaS architectures
<ul>
<li>FaaS is based on a serverless approach, use a compute service to execute code on demand</li>
<li>Every function could be considered as a standalone service</li>
<li>Write single-purpose stateless functions</li>
</ul></li>
<li>Functions react to events
<ul>
<li>Design push-based, event-driven pipelines</li>
<li>Create thicker, more powerful front ends</li>
<li>Embrace third-party services (e.g., security)</li>
</ul></li>
<li>FaaS is not a silver bullet
<ul>
<li>Not appropriate for latency-sensitive applications</li>
<li>Strict specific service-level agreements</li>
<li>Migration costs</li>
<li>Vendor lock-in can be an issue</li>
</ul></li>
<li><strong>Software as a service (SaaS)</strong>
<ul>
<li>An application environment</li>
<li>Access cloud-based apps over the Internet (e.g., email, Microsoft Office 365, Github)</li>
</ul></li>
</ul>
</section>

<section id="section-2" class="title-slide slide level1 center">
<h1></h1>

<img data-src="imgs/slides113.png" class="r-stretch"><p><a href="https://xkcd.com/1084/">https://xkcd.com/1084/</a></p>
</section>

<section id="newsection-3" class="title-slide slide level1 center">
<h1>– newsection –</h1>

</section>

<section>
<section id="from-data-lake-to-data-warehouse" class="title-slide slide level1 center">
<h1>From data lake to data warehouse</h1>

</section>
<section class="slide level2">

<p>https://catalog.us-east-1.prod.workshops.aws/workshops/ea7ddf16-5e0a-4ec7-b54e-5cadf3028b78/en-US</p>
</section></section>
<section id="context-soil-moisture-monitoring" class="title-slide slide level1 center">
<h1>Context: Soil moisture monitoring</h1>
<p><img data-src="imgs/slides114.jpg"></p>
<ul>
<li>Optimizing soil moisture is crucial for watering and crop performance [1]
<ul>
<li>_ <strong>GOAL</strong> _: build an expert system to save water while improving fruit quality (i.e., provide a recommendation of the optimal amount of water)</li>
<li><em>Soils </em> have different water retention</li>
<li><em>Watering systems </em> have different behaviors (e.g., drippers and sprinklers)</li>
<li><em>Plants </em> have different water demand (e.g., Kiwi [2] vs Grapes)</li>
<li><em>Sensors</em> produce different measurements with different precisions</li>
</ul></li>
</ul>
<p><img data-src="imgs/slides115.jpg"></p>
<p><img data-src="imgs/slides116.jpg"></p>
<p><img data-src="imgs/slides117.jpg"></p>
<p><img data-src="imgs/slides118.jpg"></p>
<p>[1] Turkeltaub et al., Real-time monitoring of nitrate transport in the deep vadose zone under a crop field–implications for groundwater protection, Hydrology and Earth System Sciences 20 (8) (2016) 3099–3108.[2] M. Judd, et al., Water use by sheltered kiwifruit under advective conditions, New Zealand journal of agricultural research 29 (1) (1986) 83–92.</p>
<ul>
<li>(Example) Scenarios of digital transformation in agriculture</li>
<li>Scenario #1
<ul>
<li>The farmer/technician controls the watering system based only on the experience</li>
<li>No digital data/KPIs/automation</li>
</ul></li>
<li>Scenario #2
<ul>
<li>The control of the watering system is refined by observing sensor data</li>
<li>Sensor data is digitalized, no KPIs/automatic</li>
</ul></li>
<li>Scenario #3
<ul>
<li>Sensor data feeds a decision support system that, knowing how to optimize KPIs, controls the watering system</li>
</ul></li>
</ul>
<p><img data-src="imgs/slides119.png"></p>
<ul>
<li>(Example) Scenarios of digital transformation in agriculture</li>
<li>Scenario #1
<ul>
<li>The farmer/technician controls the watering system based only on the experience</li>
<li>No digital data/KPIs/automation</li>
</ul></li>
<li>Scenario #2
<ul>
<li>The control of the watering system is refined by observing sensor data</li>
<li>Sensor data is digitalized, no KPIs/automatic</li>
</ul></li>
<li>Scenario #3
<ul>
<li>Sensor data feeds a decision support system that, knowing how to optimize KPIs, controls the watering system</li>
</ul></li>
</ul>
<p><img data-src="imgs/slides120.png"></p>
<p>Artificial intelligence (AI) is intelligence demonstrated by machines. AI research has been defined as the field of study of intelligent agents, which refers to any system that perceives its environment and takes actions that maximize its chance of achieving its goals.</p>
<ul>
<li>We need to understand how the soil behaves</li>
<li><em>Simulate</em> [1, 2] the soil behavior according to physical models [3]
<ul>
<li>However, a <em>fine tuning </em> is required</li>
<li>We need to <em>know/parametrize everything</em>
<ul>
<li>Soil (e.g., retention curve, hysteresis [4])</li>
<li>Plant (e.g., roots, LAI)</li>
<li>Weather conditions (temperature, humidity, wind, precipitations)</li>
<li>Watering system (e.g., capacity, distance between drippers)</li>
</ul></li>
</ul></li>
<li>Tuning can take months (of human interactions)!
<ul>
<li>Need to collect samples from the field… if parameters are incorrect, trace back</li>
<li>Need to implement/code all these features into the simulator [1, 2]</li>
<li>Hyper-parameter tuning with machine learning can help, but it is not a silver bullet</li>
</ul></li>
</ul>
<p>[1] Šimunek, J., et al.&nbsp;“HYDRUS: Model use, calibration, and validation.” Transactions of the ASABE 55.4 (2012): 1263-1274.[2] Bittelli, Marco, et al.&nbsp;Soil physics with Python: transport in the soil-plant-atmosphere system. OUP Oxford, 2015.[3] Van Genuchten, M. Th. “A closed‐form equation for predicting the hydraulic conductivity of unsaturated soils.” Soil science society of America journal 44.5 (1980): 892-898.[4] Pham, Hung Q., Delwyn G. Fredlund, and S. Lee Barbour. “A study of hysteresis models for soil-water characteristic curves.” Canadian Geotechnical Journal 42.6 (2005): 1548-1568.</p>
<ul>
<li>But… we have sensors! [1] [2] [3]
<ul>
<li>These settings are too coarse to monitor soil moisture with precision</li>
<li>They require many sensors</li>
</ul></li>
</ul>
<p><img data-src="imgs/slides121.png"></p>
<p><img data-src="imgs/slides122.png"></p>
<p><img data-src="imgs/slides123.png"></p>
<p>[1] Koyuncu, Hakan, et al.&nbsp;“Construction of 3D soil moisture maps in agricultural fields by using wireless sensor communication.” Gazi University Journal of Science 34.1 (2021): 84-98.[2] Zheng, Zhong, et al.&nbsp;“Spatial estimation of soil moisture and salinity with neural kriging.” International Conference on Computer and Computing Technologies in Agriculture. Springer, Boston, MA, 2008.[3] Fersch, Benjamin, et al.&nbsp;“Synergies for soil moisture retrieval across scales from airborne polarimetric SAR, cosmic ray neutron roving, and an in situ sensor network.” Water Resources Research 54.11 (2018): 9364-9383.</p>
</section>

<section id="reference-scenario-1" class="title-slide slide level1 center">
<h1>Reference scenario</h1>
<ul>
<li>We consider an orchard where
<ul>
<li><em>Kiwi plants </em> are aligned along <em>rows</em></li>
<li>Each row has many _ drippers_ (e.g., 1 every meter)</li>
<li>Drippers can water a <em>limited soil volume</em></li>
</ul></li>
</ul>
<p><img data-src="imgs/slides124.jpg"></p>
<p>Francia, Matteo, et al.&nbsp;“Multi-sensor profiling for precision soil-moisture monitoring.” Computers and Electronics in Agriculture 197 (2022): 106924.</p>
<ul>
<li>We consider an orchard where
<ul>
<li><em>Kiwi plants </em> are aligned along <em>rows</em></li>
<li>Each row has many _ drippers_ (e.g., 1 every meter)</li>
<li>Drippers can water a <em>limited soil volume</em></li>
</ul></li>
</ul>
<p><img data-src="imgs/slides125.png"></p>
<p>Francia, Matteo, et al.&nbsp;“Multi-sensor profiling for precision soil-moisture monitoring.” Computers and Electronics in Agriculture 197 (2022): 106924.</p>
</section>

<section id="sensor-layouts-and-symmetry-assumptions" class="title-slide slide level1 center">
<h1>Sensor layouts and symmetry assumptions</h1>
<ul>
<li>When the watered volume is symmetric along the row, a <em>2D grid of sensors </em> (left) is sufficient to represent the entire soil volume</li>
<li>When relevant moisture variations take place along the row too, a <em>3D grid of sensors</em> (right) is required
<ul>
<li>E.g., too sparse drippers</li>
<li>E.g., non-homogeneous suction of the roots</li>
</ul></li>
</ul>
<p><img data-src="imgs/slides126.png"></p>
<p><img data-src="imgs/slides127.png"></p>
<p>Francia, Matteo, et al.&nbsp;“Multi-sensor profiling for precision soil-moisture monitoring.” Computers and Electronics in Agriculture 197 (2022): 106924.</p>
</section>

<section id="reference-scenario-2" class="title-slide slide level1 center">
<h1>Reference scenario</h1>
<p><img data-src="imgs/slides128.png"></p>
<ul>
<li><ol type="a">
<li>Soil moisture is a continuum</li>
</ol></li>
<li><ol start="2" type="a">
<li>Sensors return a discretized representation of soil moisture</li>
</ol>
<ul>
<li>The monitoring accuracy changes</li>
<li>depending on the <em>sensor</em> <em>layout</em></li>
</ul></li>
</ul>
<p><img data-src="imgs/slides129.png"></p>
<p><img data-src="imgs/slides130.png"></p>
<p><img data-src="imgs/slides131.png"></p>
<p>Francia, Matteo, et al.&nbsp;“Multi-sensor profiling for precision soil-moisture monitoring.” Computers and Electronics in Agriculture 197 (2022): 106924.</p>
<p><img data-src="imgs/slides132.png"></p>
<p><img data-src="imgs/slides133.jpg"></p>
<p><img data-src="imgs/slides134.png"></p>
<p><img data-src="imgs/slides135.png"></p>
<p><img data-src="imgs/slides136.png"></p>
<p>Francia, Matteo, et al.&nbsp;“Multi-sensor profiling for precision soil-moisture monitoring.” Computers and Electronics in Agriculture 197 (2022): 106924.</p>
</section>

<section id="in-action-2" class="title-slide slide level1 center">
<h1>In action</h1>

<img data-src="imgs/slides137.png" class="r-stretch"><p>Log in AWS Academy <a href="https://awsacademy.instructure.com/">https://awsacademy.instructure.com</a></p>
<p>In AWS, start the lab (it takes 5-10 minutes)</p>
<p>Download the Notebook from Virtuale</p>
<p>Upload the Notebook to Sagemaker (not in COLAB!)</p>
</section>

<section id="data-lake-aws-s3" class="title-slide slide level1 center">
<h1>Data lake: AWS S3</h1>
<ul>
<li>AWS Simple Storage Service (S3)
<ul>
<li>A <em>serverless</em> object storage service offering industry-leading scalability, data availability, security, and performance.</li>
<li>Customers of all sizes and industries can store and protect any amount of data for virtually any use case, such as data lakes</li>
</ul></li>
</ul>

<img data-src="imgs/slides138.png" class="r-stretch"><p>Last access 2022-08</p>
</section>

<section id="data-exploration-aws-sagemaker" class="title-slide slide level1 center">
<h1>Data exploration: AWS SageMaker</h1>
<ul>
<li>Amazon SageMaker
<ul>
<li>Fully <em>managed</em> service that provides machine learning (ML) capabilities for data scientists and developers to prepare, build, train, and deploy high-quality ML models efficiently</li>
</ul></li>
</ul>

<img data-src="imgs/slides139.png" class="r-stretch"><p>Last access 2022-08</p>
</section>

<section id="etl-aws-glue" class="title-slide slide level1 center">
<h1>ETL: AWS Glue</h1>
<ul>
<li>AWS Glue
<ul>
<li>A serverless data integration service to discover and prepare data for analytics</li>
<li>Provide capabilities for data integration so that you can start analyzing your data and putting it to use in minutes</li>
<li>Provide both visual and code-based interfaces to make data integration easier</li>
<li>Users can easily find and access data using the AWS Glue Data Catalog</li>
</ul></li>
</ul>
<p><img data-src="imgs/slides140.png"></p>
<p><img data-src="imgs/slides141.png"></p>
<p><img data-src="imgs/slides142.png"></p>
<p>Last access 2022-08</p>
<p><img data-src="imgs/slides143.png"></p>
<p><img data-src="imgs/slides144.png"></p>
<p>Last access 2022-08</p>
<p><img data-src="imgs/slides145.png"></p>
<p><img data-src="imgs/slides146.png"></p>
<p><img data-src="imgs/slides147.png"></p>
<p><img data-src="imgs/slides148.png"></p>
<p><img data-src="imgs/slides149.png"></p>
<p>Last access 2022-08</p>
<p><img data-src="imgs/slides150.png"></p>
<p><img data-src="imgs/slides151.png"></p>
<p><img data-src="imgs/slides152.png"></p>
<p><img data-src="imgs/slides153.png"></p>
<p><img data-src="imgs/slides154.png"></p>
<p>Last access 2022-08</p>
<p><img data-src="imgs/slides155.png"></p>
<p><img data-src="imgs/slides156.png"></p>
<p><img data-src="imgs/slides157.png"></p>
<p><img data-src="imgs/slides158.png"></p>
<p><img data-src="imgs/slides159.png"></p>
<p>Last access 2022-08</p>
<p><img data-src="imgs/slides160.png"></p>
<p><img data-src="imgs/slides161.png"></p>
<p><img data-src="imgs/slides162.png"></p>
<p><img data-src="imgs/slides163.png"></p>
<p><em>select</em> date_format(timestamp, ‘yyyy-MM-dd HH’) <em>as</em> hour, date_format(timestamp, ‘yyyy’) <em>as</em> year, date_format(timestamp, ‘yyyy-MM’) <em>as</em> month, date_format(timestamp, ‘yyyy-MM-dd’) <em>as</em> date, concat(‘(’, xx, ‘,’, yy, ‘)’) <em>as</em> sensor, xx <em>as</em> dist, yy <em>as</em> depth, value, timestamp <em>from</em> ( <em>select</em> from_unixtime(<em>int</em> (timestamp / 3600) * 3600) <em>as</em> timestamp, xx, yy, <em>avg</em> (value) <em>as</em> value <em>from</em> myDataSource _ group by _ xx, yy, <em>int</em> (timestamp / 3600) * 3600)</p>
<p><img data-src="imgs/slides164.png"></p>
<p><img data-src="imgs/slides165.png"></p>
<p><img data-src="imgs/slides166.png"></p>
<p><img data-src="imgs/slides167.png"></p>
<p><img data-src="imgs/slides168.png"></p>
<p><img data-src="imgs/slides169.png"></p>
<p>Last access 2022-08</p>
<p><img data-src="imgs/slides170.png"></p>
<p><img data-src="imgs/slides171.png"></p>
<p>Last access 2022-08</p>
</section>

<section id="dwh-aws-rds" class="title-slide slide level1 center">
<h1>DWH: AWS RDS</h1>
<ul>
<li>Amazon Relational Database Service (Amazon RDS)
<ul>
<li>A collection of managed services that makes it simple to set up, operate, and scale relational databases in the cloud</li>
</ul></li>
</ul>
<p>Last access 2022-08</p>
<p><img data-src="imgs/slides172.png"></p>
<p><img data-src="imgs/slides173.png"></p>
<p>Last access 2022-08</p>
<p><img data-src="imgs/slides174.png"></p>
<p><img data-src="imgs/slides175.png"></p>
<p><img data-src="imgs/slides176.png"></p>
<p><img data-src="imgs/slides177.png"></p>
<p>Last access 2022-08</p>
<p><img data-src="imgs/slides178.png"></p>
<p><img data-src="imgs/slides179.png"></p>
<p>Last access 2022-08</p>
</section>

<section id="designing-the-dwh" class="title-slide slide level1 center">
<h1>Designing the DWH</h1>

</section>

<section id="newsection-4" class="title-slide slide level1 center">
<h1>– newsection –</h1>

</section>

<section id="data-pipelines-on-cloud-storage" class="title-slide slide level1 center">
<h1>Data pipelines on cloud (Storage)</h1>

</section>

<section id="data-pipeline" class="title-slide slide level1 center">
<h1>Data pipeline</h1>
<ul>
<li>Data pipeline
<ul>
<li><em>“A _ <em>sequence</em> _ of operations to transform and consume raw data”</em></li>
</ul></li>
</ul>

<img data-src="imgs/slides180.png" class="r-stretch"><p><a href="https://xkcd.com/2054/">https://xkcd.com/2054/</a></p>
<p>Quemy, Alexandre. “Data Pipeline Selection and Optimization.” <em>DOLAP</em> . 2019.</p>
<ul>
<li>The pyramid abstracts tons of techniques, algorithms, etc.</li>
<li>To provide them as services, architecting data pipelines on cloud requires
<ul>
<li>Standardization (of common services)</li>
<li>Integration</li>
<li>Orchestration</li>
<li>Accessibility through simple APIs</li>
</ul></li>
<li>Let us look to data pipelines on different cloud services providers</li>
</ul>
</section>

<section id="data-pipeline---aws" class="title-slide slide level1 center">
<h1>Data pipeline - AWS</h1>
<ul>
<li>Three main categories
<ul>
<li>Ingest
<ul>
<li>Gateway, DataSync (batch)</li>
<li>Kinesis, SNS, SQS (stream)</li>
</ul></li>
<li>Transform and store
<ul>
<li>S3 and Glacier (storage)</li>
<li>Glue (ETL)</li>
</ul></li>
<li>Serve and consume
<ul>
<li>EMR (Hadoop-like cluster)</li>
<li>Athena (serverless query service to analyze data in Amazon S3)</li>
<li>(Many) Machine learning services</li>
</ul></li>
</ul></li>
</ul>

<img data-src="imgs/slides181.png" class="r-stretch"><p><a href="https://console.aws.amazon.com/console">https://console.aws.amazon.com/console</a></p>
</section>

<section id="data-pipeline---google-cloud" class="title-slide slide level1 center">
<h1>Data pipeline - Google cloud</h1>
<ul>
<li>Three main categories
<ul>
<li>Ingest
<ul>
<li>Transfer service (batch)</li>
<li>Pub/Sub (stream)</li>
</ul></li>
<li>Analyze
<ul>
<li>Dataproc (batch)</li>
<li>Dataflow (stream)</li>
<li>Cloud storage (storage)</li>
<li>Machine learning services</li>
</ul></li>
<li>Serve
<ul>
<li>BigQuery (query service)</li>
</ul></li>
</ul></li>
</ul>

<img data-src="imgs/slides182.png" class="r-stretch"></section>

<section id="a-tentative-organization" class="title-slide slide level1 center">
<h1>A tentative organization</h1>
<p>Real-time processing and analytics</p>
<p>Operational metadata</p>
<p>Batch processing and analytics</p>
<p>Slow storage (data lake)</p>
<p>ETL tools overlay</p>
<ul>
<li>We have services
<ul>
<li>To transform data</li>
<li>To support the transformation</li>
</ul></li>
<li>The (DIKW) pyramid abstracts many techniques and algorithms
<ul>
<li>Standardization</li>
<li>Integration</li>
<li>Orchestration</li>
<li>Accessibility through APIs</li>
</ul></li>
</ul>
<p>Supporting services</p>
<p>Serve (deciding)</p>
<p>BI tools (e.g., Tableau)</p>
<p>Analytics (analyzing/process)</p>
<p>Networking, etc.</p>
<p>Machine learning</p>
<p>Ingestion (acquiring/collect)</p>
</section>

<section id="data-pipeline-1" class="title-slide slide level1 center">
<h1>Data pipeline</h1>
<ul>
<li>DIKW hierarchy
<ul>
<li>Layers representing structural relationships between data, information, knowledge, and wisdom</li>
</ul></li>
</ul>
<p><img data-src="imgs/slides183.png"></p>
<p><img data-src="imgs/slides184.jpg"></p>
<p>Ackoff, Russell L. “From data to wisdom.” Journal of applied systems analysis 16.1 (1989): 3-9.</p>
</section>

<section id="a-tentative-organization-1" class="title-slide slide level1 center">
<h1>A tentative organization</h1>
<ul>
<li>This is not a sharp taxonomy</li>
<li>Ingestion vs Analytics
<ul>
<li>Data streams are used for ingestion</li>
<li>… and (event) processing</li>
</ul></li>
</ul>
<p>Supporting services</p>
<p>Serve (deciding)</p>
<p>BI tools (e.g., Tableau)</p>
<p>Analytics (analyzing)</p>
<p>Networking, etc.</p>
<p>Machine learning</p>
<p>Ingestion (acquiring)</p>
<ul>
<li>This is not a sharp taxonomy</li>
<li>Storage vs Serving
<ul>
<li>Databases are storage</li>
<li>… with processing capability</li>
<li>… and with serving capability</li>
</ul></li>
</ul>
<p>Supporting services</p>
<p>Serve (deciding)</p>
<p>BI tools (e.g., Tableau)</p>
<p>Analytics (analyzing)</p>
<p>Networking, etc.</p>
<p>Machine learning</p>
<p>Ingestion (acquiring)</p>
</section>

<section id="section-3" class="title-slide slide level1 center">
<h1></h1>
<p>Supporting services</p>
<p>Serve (deciding)</p>
<p>BI tools (e.g., Tableau)</p>
<p>Analytics (analyzing)</p>
<p>Networking, etc.</p>
<p>Machine learning</p>
<p>Ingestion (acquiring)</p>
</section>

<section id="storage" class="title-slide slide level1 center">
<h1>Storage</h1>
<ul>
<li><strong>Goal</strong>: persisting data</li>
<li>Which storage do we choose?
<ul>
<li><strong>Storage model </strong> (or data model) ~= variety
<ul>
<li>How data are organized/accessed in a storage system
<ul>
<li>Structured vs unstructured</li>
<li>Data access model (key-value, column, etc.)</li>
</ul></li>
</ul></li>
<li>Access <strong>frequency</strong></li>
<li><strong>Analyses </strong> to be performed</li>
</ul></li>
</ul>
</section>

<section id="storage-models" class="title-slide slide level1 center">
<h1>Storage models</h1>

<img data-src="imgs/slides185.png" class="r-stretch"><p>Mansouri, Yaser, Adel Nadjaran Toosi, and Rajkumar Buyya. “Data storage management in cloud environments: Taxonomy, survey, and future directions.” ACM Computing Surveys (CSUR) 50.6 (2017): 1-51.</p>
</section>

<section id="storage-models-aws" class="title-slide slide level1 center">
<h1>Storage models (AWS)</h1>
<ul>
<li>Data structure: structured</li>
<li>Data abstraction: database</li>
<li>Data access model: relational</li>
<li><strong>Relational</strong>
<ul>
<li>Store data with predefined schemas and relationships between them</li>
<li>Support ACID transactions</li>
<li>Maintain referential integrity</li>
</ul></li>
</ul>
<p><img data-src="imgs/slides186.png"></p>
<p><a href="https://aws.amazon.com/products/databases/">https://aws.amazon.com/products/databases/</a></p>
<ul>
<li>Data structure: semi/unstructured</li>
<li>Data abstraction: database</li>
<li>Data access model: *
<ul>
<li><strong>Key/value: </strong> store and retrieve large volumes of data</li>
<li><strong>Document: </strong> store semi-structured data as JSON-like documents</li>
<li><strong>Wide column:</strong> use tables but unlike a relational database, columns can vary from row to row in the same table</li>
<li><strong>Graph: </strong> navigate and query relationships between highly connected datasets</li>
<li><strong>… and more</strong></li>
</ul></li>
</ul>
<p><img data-src="imgs/slides187.png"></p>
<p><a href="https://aws.amazon.com/products/databases/">https://aws.amazon.com/products/databases/</a></p>
</section>

<section id="storage-models-google-cloud" class="title-slide slide level1 center">
<h1>Storage models (Google Cloud)</h1>
<p><img data-src="imgs/slides188.png"></p>
<p><img data-src="imgs/slides189.png"></p>
<p><a href="https://cloud.google.com/products/databases">https://cloud.google.com/products/databases</a></p>
</section>

<section id="storage-models-aws-1" class="title-slide slide level1 center">
<h1>Storage models (AWS)</h1>
<ul>
<li>Data structure: unstructured</li>
<li>Data abstraction: file (or database)</li>
<li>Data access model: key-value</li>
<li><strong>File system</strong> (EFS), <strong>object storage</strong> (S3) (or <strong>DB K-V</strong> ; e.g., DynamoDB)
<ul>
<li>Handle unstructured data</li>
<li>… organized as files (or blob)</li>
<li>… accessed using a key-value</li>
</ul></li>
<li>Differ in the supported features
<ul>
<li>E.g., maximum item size (DynamoDB: 400KB, S3: 5TB)</li>
<li>E.g., indexes, querying mechanisms, latency, etc.</li>
</ul></li>
</ul>
</section>

<section id="aws-s3" class="title-slide slide level1 center">
<h1>AWS S3</h1>
<ul>
<li>Simple Storage Service (S3)
<ul>
<li>Serverless storage, save data as <strong>objects</strong> within <strong>buckets</strong></li>
<li>An <strong>object</strong> is composed of a file and any metadata that describes that file (e.g., <strong>object key</strong>)</li>
<li><strong>Buckets</strong> are logical containers for objects</li>
<li>You can have one or more buckets in your account</li>
<li>Control access for each bucket individually</li>
<li>Choose the geographical region where Amazon S3 will store the bucket and its contents</li>
</ul></li>
<li>Benefits
<ul>
<li>Unified data architecture
<ul>
<li>Build a multi-tenant environment, where many users can bring their own data</li>
<li>Improve both cost and data governance over traditional solutions</li>
</ul></li>
<li>Decoupling of storage from compute and data processing
<ul>
<li>You can cost-effectively store all data types in their native formats</li>
<li>Then, launch transformations as you need</li>
</ul></li>
</ul></li>
</ul>
</section>

<section id="storage-access-frequency-aws" class="title-slide slide level1 center">
<h1>Storage: access frequency (AWS)</h1>
<ul>
<li>24 storage (AWS S3) <strong>classes</strong>
<ul>
<li><strong>Standard</strong>: general purpose</li>
<li><strong>Infrequent</strong> (rapid) <strong>access</strong></li>
<li><strong>One Zone-IA</strong>: lower-cost option for infrequently accessed data that do not require high availability and resilience</li>
<li><strong>Glacier</strong>: low-cost storage class for data archiving, three retrieval options that range from a few minutes to hours</li>
<li><strong>Deep Glacier</strong>: long-term retention for data accessed once or twice in a year. E.g., retain data sets for 10 years or longer</li>
<li><strong>Intelligent-Tiering</strong>: move objects between access tiers when access patterns change</li>
</ul></li>
</ul>
<p><img data-src="imgs/slides190.png"></p>
<p><a href="https://aws.amazon.com/s3/storage-classes/">https://aws.amazon.com/s3/storage-classes/</a></p>
<ul>
<li><strong>Lifecycle</strong> configuration
<ul>
<li>A set of rules that define actions that Amazon S3 applies to a group of objects</li>
</ul></li>
<li>Two types of actions:
<ul>
<li><strong>Transition: </strong> when objects transition to another storage class. E.g., archive objects to the S3 Glacier storage class one year after creating them</li>
<li><strong>Expiration</strong>: when objects expire. Amazon S3 deletes expired objects on your behalf</li>
</ul></li>
</ul>
<p><img data-src="imgs/slides191.png"></p>
<p><a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/object-lifecycle-mgmt.html">https://docs.aws.amazon.com/AmazonS3/latest/userguide/object-lifecycle-mgmt.html</a></p>
</section>

<section id="storage-access-frequency-google-cloud" class="title-slide slide level1 center">
<h1>Storage: access frequency (Google Cloud)</h1>
<p><img data-src="imgs/slides192.png"></p>
<p><img data-src="imgs/slides193.png"></p>
<p><a href="https://cloud.google.com/blog/products/storage-data-transfer/archive-storage-class-for-coldest-data-now-available">https://cloud.google.com/blog/products/storage-data-transfer/archive-storage-class-for-coldest-data-now-available</a></p>
</section>

<section id="organizing-the-data-lake" class="title-slide slide level1 center">
<h1>Organizing the data lake</h1>
<ul>
<li>Having consistent principles on how to organize your data is important
<ul>
<li>To build standardized pipelines with the same design with regard to where read/write data</li>
<li>Standardization makes it easier to manage your pipelines at scale</li>
<li>Helps data users search for data in the storage and understand exactly to find what they need</li>
<li>Decoupling storage from processing</li>
</ul></li>
<li>Landing area (LA)
<ul>
<li>Save <em>raw data</em> from ingestion</li>
<li>Transient, data is not stored for long term</li>
</ul></li>
<li>Staging area (SA)
<ul>
<li>Raw data goes through a set of common transformations: ensuring <em>basic quality</em> and making sure it <em>conforms to existing schemas</em> for this data source and then data is saved into SA</li>
</ul></li>
<li>Archive area (A)
<ul>
<li>After saving into SA, raw data from LA should be <em>copied into the archive</em> to reprocess any given batch of data by simply copying it from AA into LA</li>
<li>Useful for debugging and testing</li>
</ul></li>
<li>Production area (PA)
<ul>
<li>Apply the business logic to data from SA</li>
</ul></li>
<li>Pass-through job
<ul>
<li>Copy data from SA to PA and then into DWH without applying any business logic</li>
<li>Optional, but having a data set in the data warehouse and PA that is an exact replica can be helpful when debugging any issues with the business logic</li>
</ul></li>
<li>Cloud data warehouse (DWH)</li>
<li>Failed area (FA)
<ul>
<li>You need to be able to deal with all kinds of errors and failures</li>
<li>There might be bugs in the pipeline code, cloud resources may fail</li>
</ul></li>
</ul>
<table>
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">Area</th>
<th style="text-align: center;">Permissions</th>
<th style="text-align: center;">Tier</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Landing</td>
<td style="text-align: center;">Ingestion applications can write<br>Scheduled pipelines can readData consumers can’t access</td>
<td style="text-align: center;">Hot</td>
</tr>
<tr class="even">
<td style="text-align: center;">Staging</td>
<td style="text-align: center;">Scheduled pipelines can read/write<br>Selected data consumers can read</td>
<td style="text-align: center;">Hot</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Production</td>
<td style="text-align: center;">Scheduled pipelines can read/writeSelected data consumers can read</td>
<td style="text-align: center;">Hot</td>
</tr>
<tr class="even">
<td style="text-align: center;">Archive</td>
<td style="text-align: center;">Scheduled pipelines can writeDedicated data reprocessing pipelines can read</td>
<td style="text-align: center;">Cold or archive</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Failed</td>
<td style="text-align: center;">Scheduled pipelines can writeDedicated data reprocessing pipelines can readData consumers don’t have access</td>
<td style="text-align: center;">Hot</td>
</tr>
</tbody>
</table>
<ul>
<li>Use folders to organize data inside areas into a logical structure
<ul>
<li><em>Namespace</em>
<ul>
<li>Logically group multiple pipelines together.</li>
</ul></li>
<li><em>Pipeline name</em>
<ul>
<li>Each data pipeline should have a name that reflects its purpose. For example
<ul>
<li>A pipeline that takes data from the LA, applies common processing steps, and saves data into SA</li>
<li>You will also have one for archiving data into AA</li>
</ul></li>
</ul></li>
<li><em>Data source name</em>
<ul>
<li>Ingestion layer will assign a name to each data source you bring into the platform</li>
</ul></li>
<li><em>BatchId</em>
<ul>
<li>Unique identifier for any batch of data that is saved into LA</li>
<li>E.g., Since only ingestion can write to LA, it is its responsibility to generate this identifier</li>
<li>A common choice for this type of an identifier is a Universally Unique Identifier (UUID)</li>
</ul></li>
</ul></li>
<li>Different areas will have slightly different folder structures
<ul>
<li>/landing/ETL/sales_oracle_ingest/customers/01DFTFX89YDFAXREPJTR94</li>
</ul></li>
</ul>
<p>However, alternative organizations are available</p>
<blockquote>
<p>“A data lake is a central repository system for storage, processing, and analysis of raw data, in which the data is <strong>kept in its original format </strong> and is processed to be queried only when needed. It can store a <strong>varied amount of formats </strong> in big data ecosystems, from unstructured, semi-structured, to structured data sources.”</p>
<p>Couto et al., 2019 ​</p>
</blockquote>
</section>

<section id="data-lakehouse-1" class="title-slide slide level1 center">
<h1>Data Lakehouse</h1>
<ul>
<li>Combine the key benefits of data lakes and data warehouses
<ul>
<li>Low-cost storage in an open format accessible by a variety of systems from the former</li>
<li>Powerful management and optimization features from the latter
<ul>
<li>ACID transactions, data versioning, auditing, indexing, caching, and query optimization.</li>
</ul></li>
</ul></li>
<li>Key question: can we combine these benefits in an effective way?
<ul>
<li>Direct access means that they <strong>give up some aspects of data independence</strong> , which has been a cornerstone of relational DBMS design</li>
<li><strong>Lakehouses</strong> __ are an especially good fit for cloud environments with separate compute and storage__: different computing applications can run on-demand on separate computing nodes (e.g., a GPU cluster for ML) while directly accessing the same storage data</li>
</ul></li>
</ul>
</section>

<section id="data-independence" class="title-slide slide level1 center">
<h1>Data Independence</h1>
<ul>
<li>Data independence can be explained using the three-schema architecture</li>
<li>Data independence: modify the schema at one level of the database system without altering the schema at the next higher level</li>
</ul>

<img data-src="imgs/slides194.png" class="r-stretch"></section>

<section>
<section id="data-lakehouse-2" class="title-slide slide level1 center">
<h1>Data Lakehouse</h1>
<ul>
<li><strong>1</strong> <strong>st</strong> <strong>generation systems</strong>: data warehousing started with helping business leaders get analytical insights
<ul>
<li>Data in these warehouses would be written with <em>schema-on-write</em> , which ensured that the data model was optimized for downstream BI consumption</li>
<li>Several challenges
<ul>
<li>They typically coupled compute and storage into an on-premises appliance
<ul>
<li>This forced enterprises to provision and pay for the peak of user load and data under management, very costly</li>
</ul></li>
<li>More and more datasets were completely unstructured, which DWHs could not store and query at all</li>
</ul></li>
</ul></li>
</ul>
<p>Armbrust, Michael, et al.&nbsp;“Lakehouse: a new generation of open platforms that unify data warehousing and advanced analytics.” <em>CIDR</em> . 2021.</p>
</section>
<section class="slide level2">

<p>https://dl.acm.org/doi/fullHtml/10.1145/3524284</p>
<ul>
<li><strong>2</strong> <strong>nd</strong> <strong>generation</strong>: offloading all the raw data into data lakes
<ul>
<li>The data lake is <em>schema-on-read</em> and stores any data at low cost, but on the other hand, punted the problem of data quality and governance</li>
<li>In this architecture, a small subset of data in the lake would later be ETLed to a downstream data warehouse</li>
<li>The use of open formats also made data lake data directly accessible to a wide range of other analytics engines, such as machine learning systems</li>
<li>From 2015 onwards, cloud data lakes, such as S3, ADLS and GCS, started replacing HDFS
<ul>
<li>Superior durability (often &gt;10 nines), geo-replication, and most importantly, extremely low cost</li>
</ul></li>
</ul></li>
</ul>

<img data-src="imgs/slides195.png" class="r-stretch"><ul>
<li>While the cloud data lake and warehouse architecture is ostensibly cheap, a two-tier architecture is highly complex for users
<ul>
<li>Data is first ETLed into lakes, and then again ELTed into warehouses</li>
<li>Enterprise use cases now include advanced analytics such as machine learning, for which neither data lakes nor warehouses are ideal</li>
<li>(Some) main problems:
<ul>
<li><strong>Reliability</strong> . Keeping the data lake and warehouse consistent is difficult and costly</li>
<li>Data <strong>staleness</strong> . The data in the warehouse is stale compared to that of the data lake, with new data frequently taking days to load</li>
<li><strong>Limited support for advanced analytics</strong> . Businesses want to ask predictive questions using their warehousing data, e.g., “which customers should I offer discounts to?” None of the leading machine learning systems directly work well on top of warehouses
<ul>
<li>Process large datasets using complex non-SQL code</li>
</ul></li>
</ul></li>
</ul></li>
</ul>
</section></section>
<section id="dataset-search-for-data-discovery-augmentation-and-explanation" class="title-slide slide level1 center">
<h1>Dataset Search for Data Discovery, Augmentation, and Explanation</h1>
<ul>
<li>Is there a real need for many unstructured and integrated dataset?
<ul>
<li>Recent years have seen an explosion in our ability to collect and catalog immense amounts of data about our environment, society, and populace</li>
<li>Governments, and organizations are increasingly making structured data available on the Web and in various repositories and data lakes</li>
<li><strong>This opportunity is often missed due to a central technical barrier</strong>: it is currently nearly impossible for domain experts to weed through the vast amount of available information to discover datasets that are needed for their specific application</li>
</ul></li>
</ul>
<p>Juliana Freire, keynote @ EDBT 2023</p>
</section>

<section id="data-lakehouse-3" class="title-slide slide level1 center">
<h1>Data Lakehouse</h1>
<ul>
<li>Main features
<ul>
<li><strong>Store data in a low-cost object store</strong> using a standard file format such as Apache Parquet</li>
<li><strong>Implement a transactional metadata layer</strong> on top of the object store that defines which objects are part of a table version</li>
<li><strong>Implement management features </strong> within the metadata layer</li>
</ul></li>
<li>Challenges:
<ul>
<li>The metadata layer is insufficient to achieve good SQL performance
<ul>
<li><strong>Data warehouses use several techniques to get state-of-the-art performance</strong>
<ul>
<li>Storing hot data on fast devices such as SSDs, maintaining statistics, building efficient indexes, etc.</li>
</ul></li>
<li><strong>In a Lakehouse it is not possible to change the format</strong> , but it is possible to implement other optimizations that leave the data files unchanged</li>
</ul></li>
</ul></li>
</ul>
</section>

<section id="delta-lake" class="title-slide slide level1 center">
<h1>Delta Lake</h1>
<ul>
<li><strong>Challenges</strong>:
<ul>
<li>Most <strong>cloud object stores are merely key-value stores</strong> , with no cross-key consistency</li>
<li><strong>Multi-object updates are not atomic</strong> , there is no isolation between queries
<ul>
<li>If a query needs to update multiple objects in the table readers will see partial updates as the query updates each object individually</li>
</ul></li>
<li>For large tables with millions of objects, <strong>metadata operations are expensive</strong>
<ul>
<li>The latency of cloud object stores is so much higher that these data skipping checks can take longer than the actual query</li>
</ul></li>
</ul></li>
</ul>
<p>Armbrust, Michael, et al.&nbsp;“Delta lake: high-performance ACID table storage over cloud object stores.” Proceedings of the VLDB Endowment 13.12 (2020): 3411-3424.</p>
<ul>
<li>Delta Lake uses a <strong>transaction log </strong> that is compacted <strong>into Apache Parquet </strong> for significantly faster metadata operations for large tabular datasets
<ul>
<li>E.g., quickly search billions of table partitions for those relevant to a query</li>
<li>The log is stored in the <strong>delta_log</strong> subdirectory within the table</li>
<li>It contains
<ul>
<li>Sequence of JSON objects with increasing, zero-padded numerical IDs to store the log records</li>
<li>Occasional checkpoints for specific log objects that summarize the log up to that point</li>
</ul></li>
</ul></li>
</ul>

<img data-src="imgs/slides196.png" class="r-stretch"><ul>
<li>Each log record object (e.g., 000003.json) contains an array of actions to apply to the previous version of the table to generate the next one</li>
<li>Examples of actions are:
<ul>
<li>Change Metadata</li>
<li>Add or Remove Files</li>
</ul></li>
<li>It is necessary to compress the log periodically into checkpoints
<ul>
<li>Checkpoints store all the non-redundant actions in the table’s log up to a certain log record ID, in Parquet format</li>
<li>Some sets of actions are redundant and can be removed</li>
<li>Read the _last_checkpoint object in the table’s log directory, if it exists, to obtain a recent checkpoint ID</li>
</ul></li>
<li>Example of a write transaction
<ul>
<li>Transaction will read the data at table version r (if needed) and attempt to write log record r+1</li>
<li>Read data at table version r, if required combine previous checkpoint and further log records</li>
<li>Write any new data objects that the transaction aims to add to the table into new files in the correct data directories, generating the object names using GUIDs.
<ul>
<li>This step can happen in parallel</li>
<li>At the end, these objects are ready to be referenced in a new log record.</li>
</ul></li>
<li>Attempt to write the transaction’s log record into the r+1 .json log object, if no other client has written this object</li>
<li><strong>This step needs to be atomic</strong> . If the step fails, the transaction can be retried; depending on the query’s semantics (optimistic concurrency)</li>
<li>Optionally, write a new .parquet checkpoint for log record r+1</li>
</ul></li>
<li>Creating the r+1 .json record, needs to be atomic: only 1 client should succeed. Not all large-scale storage systems have an atomic put operation
<ul>
<li>Google Cloud Storage and Azure Blob Store support atomic put-if-absent operations</li>
<li>HDFS, we use atomic renames to rename a temporary file to the target name</li>
<li>Amazon S3 need ad-hoc protocols</li>
</ul></li>
</ul>
</section>

<section id="lakehouse" class="title-slide slide level1 center">
<h1>Lakehouse</h1>
<ul>
<li>(SQL) Format-independent optimizations are
<ul>
<li><strong>Caching</strong>: When using a transactional metadata layer such as Delta Lake, it is safe for a Lakehouse system to cache files from the cloud object store on faster storage devices such as SSDs and RAM on the processing nodes</li>
<li><strong>Auxiliary data</strong>: maintain column min-max statistics for each data file in the table within the same Parquet file used to store the transaction log, which enables data skipping optimizations when the base data is clustered by particular columns</li>
<li><strong>Data layout</strong>:
<ul>
<li>Record ordering: which records are clustered together and hence easiest to read together, e.g.&nbsp;ordering records using individual dimensions or space-filling curves such as Z-order</li>
<li>Compression strategies differently for various groups of records, or other strategies</li>
</ul></li>
</ul></li>
<li>Offer a declarative version of the DataFrame APIs which maps data preparation computations into Spark SQL query plans and can benefit from logical optimizations</li>
</ul>
</section>

<section id="newsection-5" class="title-slide slide level1 center">
<h1>– newsection –</h1>

</section>

<section id="data-pipelines-on-cloud-computing" class="title-slide slide level1 center">
<h1>Data pipelines on cloud (Computing)</h1>

</section>

<section id="section-4" class="title-slide slide level1 center">
<h1></h1>
<p>Supporting services</p>
<p>Serve (deciding)</p>
<p>BI tools (e.g., Tableau)</p>
<p>Analytics (analyzing)</p>
<p>Networking, etc.</p>
<p>Machine learning</p>
<p>Ingestion (acquiring)</p>
</section>

<section id="supporting-data-pipelines" class="title-slide slide level1 center">
<h1>Supporting data pipelines</h1>
<ul>
<li>We can choose the XaaS configuration to build our pipelines</li>
<li>IaaS
<ul>
<li>Outsource virtual machines to the cloud (AWS EC2)</li>
<li>(You) Manage technological and business challenges</li>
</ul></li>
<li>PaaS
<ul>
<li>Outsource the data ecosystem to the cloud (e.g., AWS EMR)</li>
<li>(You) Manage business challenges</li>
</ul></li>
</ul>
<p><img data-src="imgs/slides197.png"></p>
<p><img data-src="imgs/slides198.png"></p>
<p><a href="https://aws.amazon.com/emr">https://aws.amazon.com/ec2</a><a href="https://aws.amazon.com/emr">https://aws.amazon.com/emr</a> (2022-11-15)</p>
</section>

<section id="single-instance-aws-ec2" class="title-slide slide level1 center">
<h1>Single instance: AWS EC2</h1>
<ul>
<li>Amazon Elastic Compute Cloud
<ul>
<li>A web service that provides resizable compute capacity</li>
<li>Complete control of computing resources
<ul>
<li>Processor, storage, networking, OS, and purchase model</li>
</ul></li>
</ul></li>
<li>The _ <strong>instance type </strong> _ determines the hardware
<ul>
<li>Different compute and memory capabilities</li>
</ul></li>
<li>_ <strong>Amazon Machine Image </strong> _ is a software template
<ul>
<li>The EC2 instance is used for creating the virtual server instance</li>
<li>The AMI is the EC2 virtual machines image</li>
</ul></li>
<li>Interact with EC2 instance as with any computer
<ul>
<li>You have complete control of your instances</li>
</ul></li>
</ul>
<p><img data-src="imgs/slides199.png"></p>
<p><a href="https://aws.amazon.com/ec2/instance-types">https://aws.amazon.com/ec2/instance-types</a> <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instances-and-amis.html">https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instances-and-amis.html</a> <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/compute-optimized-instances.html">https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/compute-optimized-instances.html</a></p>
<p><img data-src="imgs/slides200.png"></p>
<p><img data-src="imgs/slides201.png"></p>
<p><a href="https://aws.amazon.com/ec2/instance-types/">https://aws.amazon.com/ec2/instance-types/</a></p>
<ul>
<li>AWS uses public-key cryptography to secure the login</li>
<li>You can create one using the Amazon EC2 console
<ul>
<li>Open the Amazon EC2 console at <a href="https://console.aws.amazon.com/ec2/">https://console.aws.amazon.com/ec2/</a></li>
<li>In the navigation pane, choose <code>Key Pairs</code></li>
<li>Choose <code>Create key pair</code></li>
<li>For <code>Name</code>, enter a descriptive name for the key pair</li>
<li>For <code>File format</code>, choose the format in which to save the private key
<ul>
<li>OpenSSH, choose <code>pem</code> (<code>chmod 400 _ _my-key-_ _ _pair_ _ .pe m</code>)</li>
<li>PuTTY, choose <code>ppk</code></li>
</ul></li>
<li>Choose <code>Create key pair</code></li>
<li>The private key file is automatically downloaded by your browser</li>
</ul></li>
</ul>
</section>

<section id="cluster-aws-emr" class="title-slide slide level1 center">
<h1>Cluster: AWS EMR</h1>
<ul>
<li>Amazon EMR is a data platform based on the Hadoop stack
<ul>
<li>Apache Spark, Apache Hive, Apache HBase, etc.</li>
<li>You can run workloads on
<ul>
<li>Amazon EC2 instances</li>
<li>Amazon Elastic Kubernetes Service (EKS)&nbsp;clusters</li>
</ul></li>
</ul></li>
<li>Example of workload
<ul>
<li>Upload input data into Amazon S3</li>
<li>EMR launches EC2 instances that you specified</li>
<li>EMR begins the execution while pulling the input data from S3 into the launched instances</li>
<li>Once the cluster is finished, EMR transfers output data to Amazon S3</li>
</ul></li>
</ul>
</section>

<section id="motivation" class="title-slide slide level1 center">
<h1>Motivation</h1>
<ul>
<li>Amazon EMR (Elastic Map Reduce)
<ul>
<li>Provides a managed Hadoop framework</li>
</ul></li>
<li>Some features
<ul>
<li>Service integration
<ul>
<li>Automatically control EC2 instances</li>
<li>Transparently use S3 storage</li>
</ul></li>
<li>Pricing:
<ul>
<li>Low Hourly Pricing</li>
<li>Amazon EC2 Spot Integration</li>
</ul></li>
</ul></li>
</ul>
<p><a href="https://aws.amazon.com/emr">https://aws.amazon.com/emr</a></p>
</section>

<section>
<section id="aws-emr" class="title-slide slide level1 center">
<h1>AWS EMR</h1>
<p>Deploy Multiple Clusters</p>
<p>Provision as much capacity as you need</p>
<p>Add or remove capacity at any time</p>
<p><img data-src="imgs/slides202.png"></p>
<p><img data-src="imgs/slides203.png"></p>
<p><img data-src="imgs/slides204.png"></p>
<p><img data-src="imgs/slides205.png"></p>
<p><img data-src="imgs/slides206.png"></p>
<p><img data-src="imgs/slides207.png"></p>
<p><img data-src="imgs/slides208.png"></p>
<p><img data-src="imgs/slides209.png"></p>
<p><img data-src="imgs/slides210.png"></p>
<p><img data-src="imgs/slides211.png"></p>
<p><img data-src="imgs/slides212.png"></p>
<p><img data-src="imgs/slides213.png"></p>
<p><img data-src="imgs/slides214.png"></p>
<p><img data-src="imgs/slides215.png"></p>
<p><img data-src="imgs/slides216.png"></p>
<p><img data-src="imgs/slides217.png"></p>
<p><img data-src="imgs/slides218.png"></p>
<p><img data-src="imgs/slides219.png"></p>
<p><img data-src="imgs/slides220.png"></p>
<p><img data-src="imgs/slides221.png"></p>
<p><img data-src="imgs/slides222.png"></p>
<p><img data-src="imgs/slides223.png"></p>
<p><img data-src="imgs/slides224.png"></p>
<p><img data-src="imgs/slides225.png"></p>
<p><img data-src="imgs/slides226.png"></p>
<p><img data-src="imgs/slides227.png"></p>
<p><img data-src="imgs/slides228.png"></p>
<p><img data-src="imgs/slides229.png"></p>
<p><img data-src="imgs/slides230.png"></p>
<p>Resize a Running Cluster</p>
<p><img data-src="imgs/slides231.png"></p>
<p><img data-src="imgs/slides232.png"></p>
<p><img data-src="imgs/slides233.png"></p>
<p><img data-src="imgs/slides234.png"></p>
<p><img data-src="imgs/slides235.png"></p>
<p><img data-src="imgs/slides236.png"></p>
<p><img data-src="imgs/slides237.png"></p>
<p><img data-src="imgs/slides238.png"></p>
<p><img data-src="imgs/slides239.png"></p>
<p><img data-src="imgs/slides240.png"></p>
<p><img data-src="imgs/slides241.png"></p>
<p><img data-src="imgs/slides242.png"></p>
<p><img data-src="imgs/slides243.png"></p>
<p><img data-src="imgs/slides244.png"></p>
<p><img data-src="imgs/slides245.png"></p>
<p><img data-src="imgs/slides246.png"></p>
<p><img data-src="imgs/slides247.png"></p>
<p><img data-src="imgs/slides248.png"></p>
<p><img data-src="imgs/slides249.png"></p>
<p><img data-src="imgs/slides250.png"></p>
<p><img data-src="imgs/slides251.png"></p>
<p><img data-src="imgs/slides252.png"></p>
<p><img data-src="imgs/slides253.png"></p>
<p><img data-src="imgs/slides254.png"></p>
<p><img data-src="imgs/slides255.png"></p>
<p><img data-src="imgs/slides256.png"></p>
<p><img data-src="imgs/slides257.png"></p>
<p><img data-src="imgs/slides258.png"></p>
<p><img data-src="imgs/slides259.png"></p>
<p><img data-src="imgs/slides260.png"></p>
<p><img data-src="imgs/slides261.png"></p>
<p><img data-src="imgs/slides262.png"></p>
<p><img data-src="imgs/slides263.png"></p>
<p><img data-src="imgs/slides264.png"></p>
<p><img data-src="imgs/slides265.png"></p>
<ul>
<li>EMR cluster</li>
<li>Master group controls the cluster
<ul>
<li>Coordinate the work distribution</li>
<li>Manage the cluster state</li>
</ul></li>
<li>Core groups
<ul>
<li>Core instances run Data Node daemons</li>
</ul></li>
<li>(Optional) Task instances</li>
</ul>
<p><img data-src="imgs/slides266.png"></p>
<p><img data-src="imgs/slides267.png"></p>
<p><img data-src="imgs/slides268.png"></p>
<p><img data-src="imgs/slides269.png"></p>
<p>Amazon EMR Cluster</p>
<p>Master Instance Group</p>
<p><img data-src="imgs/slides270.png"></p>
<p><img data-src="imgs/slides271.png"></p>
<p><img data-src="imgs/slides272.png"></p>
<p><img data-src="imgs/slides273.png"></p>
<p><img data-src="imgs/slides274.png"></p>
<p><img data-src="imgs/slides275.png"></p>
<p><img data-src="imgs/slides276.png"></p>
<p><img data-src="imgs/slides277.png"></p>
<p><img data-src="imgs/slides278.png"></p>
<p><img data-src="imgs/slides279.png"></p>
<p>Task Instance Group</p>
<p>Core Instance Group</p>
<p><img data-src="imgs/slides280.png"></p>
<p><img data-src="imgs/slides281.png"></p>
<p><img data-src="imgs/slides282.png"></p>
<p><img data-src="imgs/slides283.png"></p>
<p><img data-src="imgs/slides284.png"></p>
<p><img data-src="imgs/slides285.png"></p>
<p><img data-src="imgs/slides286.png"></p>
<p><img data-src="imgs/slides287.png"></p>
<ul>
<li>The central component of Amazon EMR is the <strong>cluster</strong>
<ul>
<li>A collection of <strong>Amazon Elastic Compute Cloud (Amazon EC2)</strong> instances</li>
<li>Each instance is called a <strong>node</strong></li>
</ul></li>
<li>The <strong>node type </strong> identifies the role within the cluster
<ul>
<li><strong>Master</strong> node coordinates the distribution of data and tasks among other nodes
<ul>
<li>Every cluster has (at least) a master node</li>
<li>Always active</li>
</ul></li>
<li><strong>Core</strong> node runs tasks and store data in the Hadoop Distributed File System (HDFS)
<ul>
<li>Multi-node clusters have at least one core node</li>
<li>Always active, contains the data node daemon</li>
</ul></li>
<li><strong>Task</strong> node only runs tasks
<ul>
<li>Task nodes are optional</li>
<li>Decoupling processing and storage, we lose data locality</li>
</ul></li>
</ul></li>
<li>On-Demand Instance
<ul>
<li>Pay for compute capacity by the hour (minimum of 60 seconds)</li>
<li>No long-term commitments</li>
</ul></li>
<li>Spot Instance
<ul>
<li>Unused EC2 instance that is available for less than the on-demand price</li>
<li>Hourly price is called <em>spot price</em>
<ul>
<li>Adjusted based on long-term supply and demand for spot instances</li>
</ul></li>
<li>Run the instance when capacity is available and price is below threshold
<ul>
<li>When data-center resources are low, spot instances are dropped</li>
<li>Mainly suitable for batch workloads</li>
</ul></li>
</ul></li>
</ul>
<p><a href="https://aws.amazon.com/ec2/pricing/">https://aws.amazon.com/ec2/pricing/</a></p>
</section>
<section class="slide level2">

<p>https://us-east-1.console.aws.amazon.com/ec2/v2/home?region=us-east-1#SpotInstances:</p>
<ul>
<li>Spot Instance cost strategies</li>
<li><em>Capacity-optimized strategy</em>
<ul>
<li>Allocated instances into the most available pools</li>
<li>Look at real-time capacity data, predict which are the most available</li>
<li>Works well for workloads such as big data and analytics</li>
<li>Works well when we have high cost of interruption</li>
</ul></li>
<li><em>Lowest-price strategy</em>
<ul>
<li>Allocates instances in pools with lowest price at time of fulfillment</li>
</ul></li>
</ul>
</section></section>
<section id="creating-the-cluster" class="title-slide slide level1 center">
<h1>Creating the cluster</h1>
<p><img data-src="imgs/slides288.png"></p>
<p><img data-src="imgs/slides289.png"></p>
<ul>
<li>Choose to launch <strong>master</strong> , <strong>core</strong> , or <strong>task</strong> on Spot Instances
<ul>
<li>The <strong>master</strong> node controls the cluster
<ul>
<li>When terminated, the cluster ends</li>
<li>Use <em>spot instances</em> if you are running a cluster where sudden termination is acceptable</li>
</ul></li>
<li><strong>Core </strong> nodes process data and store information using HDFS
<ul>
<li>When terminated, data is lost</li>
<li>Use <em>spot instances</em> when partial HDFS data loss is tolerable</li>
</ul></li>
<li><strong>Task </strong> nodes process data but do not hold persistent data in HDFS
<ul>
<li>When terminated, computational capacity is lost</li>
<li>The effect of spot instances on the cluster is “minimal”</li>
</ul></li>
</ul></li>
</ul>
<p><a href="https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-plan-instances-guidelines.html">https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-plan-instances-guidelines.html</a></p>
<p><img data-src="imgs/slides290.png"></p>
<ul>
<li>Amazon EMR provides two main file systems
<ul>
<li><strong>HDFS</strong> and <strong>EMRFS</strong> , specify which file system to use by the prefix</li>
<li>hdfs://path (or just <code>path</code>)
<ul>
<li>HDFS is used by the master and core nodes</li>
<li><em>AWS EBS volume storage is used for HDFS data</em></li>
<li>Is fast, best used for caching the results produced by intermediate job-flow steps, <em>why?</em></li>
<li>It’s ephemeral storage which is reclaimed when the cluster ends</li>
</ul></li>
<li>s3://DOC-EXAMPLE-BUCKET1/path (EMRFS)
<ul>
<li>An implementation of the Hadoop file system atop Amazon S3</li>
<li>We can avoid EBS storage</li>
</ul></li>
</ul></li>
</ul>
<p><a href="https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-plan-storage.html">https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-plan-storage.html</a></p>
<ul>
<li>Choose the frameworks and applications to install</li>
<li>Data process
<ul>
<li>Submit jobs or queries directly to installed applications</li>
<li>Run steps in the cluster</li>
</ul></li>
<li>Submitting jobs
<ul>
<li>Connect to the master node over a secure connection</li>
<li>Access the interfaces and tools that are available on your cluster</li>
</ul></li>
</ul>
<p><img data-src="imgs/slides291.png"></p>
<p><img data-src="imgs/slides292.png"></p>
<p><img data-src="imgs/slides293.png"></p>
<p><img data-src="imgs/slides294.png"></p>
<p>Allows EMR to call other AWS Services such as EC2 on your behalf.</p>
<p>Provides access to other AWS services such as S3, DynamoDB from EC2 instances that are launched by EMR.</p>
<ul>
<li>Using CLI (command line interface)</li>
<li>This is more pragmatic, but there are many options to explore
<ul>
<li>Let’s stick to AWS Console</li>
<li><a href="https://console.aws.amazon.com/elasticmapreduce/">https://console.aws.amazon.com/elasticmapreduce/</a></li>
</ul></li>
<li>aws emr create-cluster \
<ul>
<li>–name _ <em>“My First EMR Cluster” </em> _ \</li>
<li>–release-label _ <em>emr-5.32.0 </em> _ \</li>
<li>–applications Name=Spark \</li>
<li>–ec2-attributes KeyName= _ <em>myEMRKeyPairName </em> _ \</li>
<li>–instance-type m5.xlarge \</li>
<li>–instance-count 3 \</li>
<li>–use-default-roles</li>
</ul></li>
</ul>
<p>Using CLI (command line interface)</p>
<p>aws emr create-cluster –auto-scaling-role EMR_AutoScaling_DefaultRole –termination-protected –applications Name=Hadoop Name=Hive Name=Hue Name=JupyterEnterpriseGateway Name=Spark –ebs-root-volume-size 10 –ec2-attributes ‘{“KeyName”:“bigdata”,“InstanceProfile”:“EMR_EC2_DefaultRole”,“SubnetId”:“subnet-5fa2f912”,“EmrManagedSlaveSecurityGroup”:“sg-07818b5690a50b3f1”,“EmrManagedMasterSecurityGroup”:“sg-0e2f5550a2cb98f79”}’ –service-role EMR_DefaultRole –enable-debugging –release-label emr-6.2.0 –log-uri ‘s3n://aws-logs-604905954159-us-east-1/elasticmapreduce/’ –name ‘BigData’ –instance-groups ‘[{“InstanceCount”:1,“BidPrice”:“OnDemandPrice”,“EbsConfiguration”:{“EbsBlockDeviceConfigs”:[{“VolumeSpecification”:{“SizeInGB”:32,“VolumeType”:“gp2”},“VolumesPerInstance”:2}]},“InstanceGroupType”:“MASTER”,“InstanceType”:“m4.xlarge”,“Name”:“Master - 1”},{“InstanceCount”:1,“BidPrice”:“OnDemandPrice”,“EbsConfiguration”:{“EbsBlockDeviceConfigs”:[{“VolumeSpecification”:{“SizeInGB”:32,“VolumeType”:“gp2”},“VolumesPerInstance”:2}]},“InstanceGroupType”:“CORE”,“InstanceType”:“m4.xlarge”,“Name”:“Core - 2”}]’ –scale-down-behavior TERMINATE_AT_TASK_COMPLETION –region us-east-1</p>
</section>

<section id="cluster-lifecycle" class="title-slide slide level1 center">
<h1>Cluster lifecycle</h1>
<ul>
<li>Creating a cluster (it takes ~10 minutes)
<ul>
<li>A cluster cannot be stopped</li>
<li>It can only be terminated</li>
</ul></li>
</ul>

<img data-src="imgs/slides295.png" class="r-stretch"><ul>
<li>STARTING: EMR provisions EC2 instances for each required instance</li>
<li>BOOTSTRAPPING: EMR runs actions that you specify on each instance
<ul>
<li>E.g., install custom applications and perform customizations</li>
</ul></li>
<li>Amazon EMR installs the native applications
<ul>
<li>E.g., Hive, Hadoop, Spark, and so on</li>
</ul></li>
<li>RUNNING: a step for the cluster is currently being run
<ul>
<li>Cluster sequentially runs any steps that you specified when you created the cluster</li>
</ul></li>
<li>WAITING: after steps run successfully</li>
<li>TERMINATING: after manual shut down
<ul>
<li><em>Any data stored on the cluster is deleted</em></li>
</ul></li>
<li>A <strong>step</strong> is a user-defined unit of processing
<ul>
<li>E.g., one algorithm that manipulates the data</li>
</ul></li>
<li>Step states
<ul>
<li>PENDING: The step is waiting to be run</li>
<li>RUNNING: The step is currently running</li>
<li>COMPLETED: The step completed successfully</li>
<li>CANCELLED: The step was cancelled before running because an earlier step failed</li>
<li>FAILED: The step failed while running</li>
</ul></li>
</ul>
</section>

<section id="running-the-cluster" class="title-slide slide level1 center">
<h1>Running the cluster</h1>
<p><img data-src="imgs/slides296.png"></p>
<p><img data-src="imgs/slides297.png"></p>
</section>

<section id="running-a-notebook" class="title-slide slide level1 center">
<h1>Running a notebook</h1>
<p><img data-src="imgs/slides298.png"></p>
<p><img data-src="imgs/slides299.png"></p>
<p><img data-src="imgs/slides300.png"></p>
</section>

<section id="running-a-spark-job" class="title-slide slide level1 center">
<h1>Running a Spark Job</h1>
<p>Connect using SSH</p>
<p>Install git</p>
<p>Clone &amp; build the project</p>
<p>ssh -i ~/bigdata.pem <a href="mailto:hadoop@ec2-54-242-176-32.compute-1.amazonaws.com">hadoop@ec2-54-242-176-32.compute-1.amazonaws.com</a></p>
<p>sudo yum install git -y</p>
<p>git clone <a href="https://github.com/w4bo/spark-word-count.git">https://github.com/w4bo/spark-word-count.git</a></p>
<p>cd spark-word-count</p>
<p>./gradlew</p>
<p>spark-submit –class it.unibo.big.WordCount build/libs/WordCount-all.jar s3://aws-bucket-bigdata2021/inferno.txt</p>
</section>

<section id="other-services-hue" class="title-slide slide level1 center">
<h1>Other services: HUE</h1>
<ul>
<li>Connecting to Hue
<ul>
<li>I.e., connecting to any HTTP interface hosted on the master node of a cluster</li>
</ul></li>
<li>To view the Hue web user interface
<ul>
<li>Set Up an SSH Tunnel to the Master Node Using Dynamic Port Forwarding</li>
<li>Type the following address in your browser to open the Hue web interface
<ul>
<li><a href="http://master-public-dns:8888/">http://master-public-DNS:8888</a></li>
<li>Where master-public-DNS is the public DNS name of the master node</li>
</ul></li>
<li>If you are the administrator logging in for the first time
<ul>
<li>Enter a username and password to create your Hue superuser account</li>
<li>Otherwise, type your username and password and select Create account</li>
</ul></li>
</ul></li>
</ul>

<img data-src="imgs/slides301.png" class="r-stretch"></section>

<section id="set-up-an-ssh-tunnel" class="title-slide slide level1 center">
<h1>Set Up an SSH Tunnel</h1>
<p><img data-src="imgs/slides302.png"></p>
<p><img data-src="imgs/slides303.png"></p>
<p><img data-src="imgs/slides304.png"></p>
</section>

<section id="connect-to-hue" class="title-slide slide level1 center">
<h1>Connect to HUE</h1>
<p><img data-src="imgs/slides305.png"></p>
<p><img data-src="imgs/slides306.png"></p>
</section>

<section id="connect-using-ssh" class="title-slide slide level1 center">
<h1>Connect using SSH</h1>
<p><img data-src="imgs/slides307.png"></p>
<p><img data-src="imgs/slides308.png"></p>
</section>

<section id="section-5" class="title-slide slide level1 center">
<h1></h1>

<img data-src="imgs/slides309.png" class="r-stretch"></section>

<section id="newsection-6" class="title-slide slide level1 center">
<h1>– newsection –</h1>

</section>

<section id="cluster-migration---based-on-a-true-story" class="title-slide slide level1 center">
<h1>Cluster migration - Based on a true story​</h1>

</section>

<section id="migration" class="title-slide slide level1 center">
<h1>Migration</h1>
<ul>
<li>Goals
<ul>
<li>Evaluating the costs for a cloud/on-premises data platform</li>
<li>Real-world case study</li>
<li>Fill in this table</li>
</ul></li>
</ul>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">Cost</th>
<th style="text-align: center;">On-premises</th>
<th style="text-align: center;">On cloud</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Hardware</td>
<td style="text-align: center;">?</td>
<td style="text-align: center;">?</td>
</tr>
<tr class="even">
<td style="text-align: center;">Software</td>
<td style="text-align: center;">?</td>
<td style="text-align: center;">?</td>
</tr>
</tbody>
</table>
</section>

<section id="case-study" class="title-slide slide level1 center">
<h1>Case study</h1>
<p>Business intelligence group</p>
</section>

<section id="migration-1" class="title-slide slide level1 center">
<h1>Migration</h1>
<p>Spatial Cube (PostGIS)</p>
<p>Reference architecture</p>
<p><img data-src="imgs/slides310.png"></p>
<p>Mobile Interface</p>
<p>ODS (Hbase+PostGIS)</p>
<p>Integration processes</p>
<p>Loading processes</p>
<p>Notebook Interface</p>
<p>Data Lake (Hadoop)</p>
<p>Enrichment processes</p>
<p>Acquisition processes</p>
<p><em>External sources</em></p>
<p><img data-src="imgs/slides311.png"></p>
<p><img data-src="imgs/slides312.png"></p>
<p><img data-src="imgs/slides313.png"></p>
<p><img data-src="imgs/slides314.png"></p>
<p><img data-src="imgs/slides315.png"></p>
<p><img data-src="imgs/slides316.png"></p>
<p>Administrative</p>
<p>borders</p>
<p>Rural Land</p>
<p>register</p>
<p>Satelliteimages</p>
<p>On-the-field sensors</p>
<p>Reference architecture</p>
<p><img data-src="imgs/slides317.png"></p>
<ul>
<li>Hardware</li>
<li>Software
<ul>
<li>“Classic” Hadoop stack</li>
</ul></li>
<li>8 CPUs (144 total)
<ul>
<li><ul>
<li>Intel(R) Core(TM) i7-8700 CPU @ 3.20GHz</li>
</ul></li>
</ul></li>
<li>32GB RAM (576GB total)
<ul>
<li><ul>
<li>2 x 16GB DIMM DDR4 2666 MHz</li>
</ul></li>
</ul></li>
<li>12TB HDD Disk (216TB total)
<ul>
<li><ul>
<li>3 x 4TB ST4000DM004-2CV1</li>
</ul></li>
</ul></li>
</ul>
<p><img data-src="imgs/slides318.png"></p>
<p><img data-src="imgs/slides319.png"></p>
<p><img data-src="imgs/slides320.png"></p>
<p><img data-src="imgs/slides321.png"></p>
<p><img data-src="imgs/slides322.png"></p>
<p><img data-src="imgs/slides323.png"></p>
<p><img data-src="imgs/slides324.png"></p>
<p><img data-src="imgs/slides325.png"></p>
<p><img data-src="imgs/slides326.png"></p>
<p><img data-src="imgs/slides327.png"></p>
<p><img data-src="imgs/slides328.png"></p>
<p><img data-src="imgs/slides329.png"></p>
<p><img data-src="imgs/slides330.png"></p>
<p><img data-src="imgs/slides331.png"></p>
<p><img data-src="imgs/slides332.png"></p>
<p><img data-src="imgs/slides333.png"></p>
<p><img data-src="imgs/slides334.png"></p>
<p><img data-src="imgs/slides335.png"></p>
<p><img data-src="imgs/slides336.png"></p>
<p><img data-src="imgs/slides337.png"></p>
<p>lshw -short -C cpu</p>
<p>lshw -short -C memory</p>
<p>lshw -short -C disk</p>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">SOLonprem</th>
<th style="text-align: center;">On-premises</th>
<th style="text-align: center;">On cloud</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Hardware</td>
<td style="text-align: center;">?</td>
<td style="text-align: center;">?</td>
</tr>
<tr class="even">
<td style="text-align: center;">Software</td>
<td style="text-align: center;">?</td>
<td style="text-align: center;">?</td>
</tr>
</tbody>
</table>
<ul>
<li><strong>Hardware cost</strong>:?
<ul>
<li>Refer to <a href="https://www.rect.coreto-europe.com/en/search.html?clearsearch=1">https://www.rect.coreto-europe.com/en/search.html?clearsearch=1</a></li>
</ul></li>
</ul>
</section>

<section id="on-premises" class="title-slide slide level1 center">
<h1>On-premises</h1>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">SOLonprem</th>
<th style="text-align: center;">On-premises</th>
<th style="text-align: center;">On cloud</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Hardware</td>
<td style="text-align: center;">10602€/year</td>
<td style="text-align: center;">?</td>
</tr>
<tr class="even">
<td style="text-align: center;">Software</td>
<td style="text-align: center;">?</td>
<td style="text-align: center;">?</td>
</tr>
</tbody>
</table>
<ul>
<li><strong>Hardware cost </strong> <em>(up to Mar 05, 2021): </em> 1767€ x 18 = 31806€
<ul>
<li>Amortization over 3 years (i.e., <em>10602€/year</em>)</li>
</ul></li>
</ul>

<img data-src="imgs/slides338.png" class="r-stretch"><p><a href="https://www.rect.coreto-europe.com/en">https://www.rect.coreto-europe.com/en</a> (Accessed 2021-08-01)</p>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">SOLonprem</th>
<th style="text-align: center;">On-premises</th>
<th style="text-align: center;">On cloud</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Hardware</td>
<td style="text-align: center;">10602€/year</td>
<td style="text-align: center;">?</td>
</tr>
<tr class="even">
<td style="text-align: center;">Software</td>
<td style="text-align: center;">?</td>
<td style="text-align: center;">?</td>
</tr>
</tbody>
</table>
<p><strong>Software cost</strong>:?</p>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">SOLonprem</th>
<th style="text-align: center;">On-premises</th>
<th style="text-align: center;">On cloud</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Hardware</td>
<td style="text-align: center;">10602€/year</td>
<td style="text-align: center;">?</td>
</tr>
<tr class="even">
<td style="text-align: center;">Software</td>
<td style="text-align: center;">0€</td>
<td style="text-align: center;">?</td>
</tr>
</tbody>
</table>
<ul>
<li><strong>Software cost</strong> <em>(up to 2020): 0€</em>
<ul>
<li>Free Cloudera Management System</li>
<li>No software licensing (for research purpose)</li>
</ul></li>
</ul>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">SOLonprem</th>
<th style="text-align: center;">On-premises</th>
<th style="text-align: center;">On cloud</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Hardware</td>
<td style="text-align: center;">10602€/year</td>
<td style="text-align: center;">?</td>
</tr>
<tr class="even">
<td style="text-align: center;">Software</td>
<td style="text-align: center;">180000€/year</td>
<td style="text-align: center;">?</td>
</tr>
</tbody>
</table>
<ul>
<li><strong>Software cost </strong> <em>(up to Mar 05, 2021): 10000€/year x 18 = 180000€/year</em>
<ul>
<li>Cloudera is no more free, 10K€ per node</li>
<li><a href="https://www.cloudera.com/products/pricing.html#private-cloud-services">https://www.cloudera.com/products/pricing.html#private-cloud-services</a></li>
<li><a href="https://www.cloudera.com/products/pricing/product-features.html">https://www.cloudera.com/products/pricing/product-features.html</a></li>
<li>No license for research purpose</li>
</ul></li>
<li><em>“Houston we’ve had a problem!”</em>
<ul>
<li>We cannot update/extend the cluster anymore</li>
<li>What about migrating to the cloud? (we only consider AWS)</li>
</ul></li>
</ul>
</section>

<section id="migration-2" class="title-slide slide level1 center">
<h1>Migration</h1>
<ul>
<li>Moving a Hadoop cluster to the cloud (we only consider AWS)
<ul>
<li>AWS price calculator <a href="https://calculator.aws/#/estimate">https://calculator.aws/#/estimate</a></li>
</ul></li>
<li>How do we start?
<ul>
<li>We have already defined the hardware and the software stack</li>
<li>Start with coarse tuning, identify the dominating costs first
<ul>
<li>Is it computing, storage, or processing?</li>
</ul></li>
<li>Identify a suitable budget, implement, refine later
<ul>
<li>Wrong refinements can do a lot of damage</li>
</ul></li>
</ul></li>
</ul>
</section>

<section id="on-cloud-v1" class="title-slide slide level1 center">
<h1>On cloud v1</h1>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">SOLcloud1</th>
<th style="text-align: center;">On-premises</th>
<th style="text-align: center;">On cloud</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Hardware</td>
<td style="text-align: center;">10602€/year</td>
<td style="text-align: center;">?</td>
</tr>
<tr class="even">
<td style="text-align: center;">Software</td>
<td style="text-align: center;">180000€/year</td>
<td style="text-align: center;">?</td>
</tr>
</tbody>
</table>
<ul>
<li>Migrating the cluster as-is:?
<ul>
<li>Hint: add 18 EC2 instances satisfying the hardware requirements</li>
</ul></li>
</ul>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">SOLcloud1</th>
<th style="text-align: center;">On-premises</th>
<th style="text-align: center;">On cloud</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Hardware</td>
<td style="text-align: center;">10602€/year</td>
<td style="text-align: center;">162000$/year</td>
</tr>
<tr class="even">
<td style="text-align: center;">Software</td>
<td style="text-align: center;">180000€/year</td>
<td style="text-align: center;">?</td>
</tr>
</tbody>
</table>
<ul>
<li>SOLcloud1 migrating the cluster as-is: <em>13500<span class="math inline">\(/month = 162000\)</span>/year</em>
<ul>
<li>18 EC2 instances (t4g.2xlarge) with 12TB EBS storage each machine</li>
<li>Still, we have no software configuration</li>
</ul></li>
<li>Prices change over the year
<ul>
<li>In 2022, 162000$/year</li>
<li>In 2023, 146000$/year</li>
</ul></li>
</ul>

<img data-src="imgs/slides339.png" class="r-stretch"><p><a href="https://calculator.aws/#/estimate?id=7757afffccc3cafdcfdeb212b74623ef02ed5a36">https://calculator.aws/#/estimate?id=7757afffccc3cafdcfdeb212b74623ef02ed5a36</a></p>
</section>

<section id="migration-3" class="title-slide slide level1 center">
<h1>Migration</h1>
<ul>
<li>Pay attention to the region
<ul>
<li>Different regions, different prices</li>
<li>Different regions, different services</li>
<li>Remember the GDPR and data locality</li>
</ul></li>
</ul>
<p><img data-src="imgs/slides340.png"></p>
<ul>
<li>It makes no sense to move the cluster as-is
<ul>
<li>More machines ensure better (on-prem) scalability but higher costs</li>
</ul></li>
<li>How do we proceed with the migration?
<ul>
<li>We need minimum software requirements</li>
<li>Try to achieve the smallest migration impact
<ul>
<li>Find the most similar cloud-based solution to a Hadoop cluster</li>
<li>Rethink applications (later) when you got the know-how</li>
</ul></li>
<li>Identify a suitable budget, implement, refine later
<ul>
<li>Wrong refinements can do a lot of damage</li>
</ul></li>
</ul></li>
<li><strong>HDFS</strong>
<ul>
<li>How much durability do we need?
<ul>
<li>HP0: three replicas (we stick to this)</li>
<li>HP1: decrease replicas for cold data</li>
<li>HP2: move cold data to glacier or delete id</li>
<li>…</li>
</ul></li>
</ul></li>
<li><strong>HBase</strong> has marginal effects on the pricing (100GB &lt;&lt; 50TB)
<ul>
<li>For simplicity, we can omit it</li>
</ul></li>
<li><strong>Overall</strong>: 50TB storage/year</li>
</ul>
<p><img data-src="imgs/slides341.png"></p>
<ul>
<li>Processing takes place each time that ESA provides a satellite image
<ul>
<li>Some days no images are available</li>
<li>Some days up to 10 images are available</li>
<li>Spark jobs are always executed with the same parameters</li>
</ul></li>
<li><strong>Image processing</strong>
<ul>
<li>4 machines, 2 cores, 10GB RAM at least</li>
</ul></li>
<li><strong>Weather processing</strong> is negligible</li>
</ul>
<p>Image processing</p>
<p>4 Executors (2 cores and 10GB RAM each)</p>
<dl>
<dt>Driver (2 cores and 20GB RAM)</dt>
<dd>
<p>15m/core (2h total)</p>
</dd>
</dl>
<p>Weather processing</p>
<p>2 Executors (1 core and 500MB RAM each)</p>
<dl>
<dt>Driver (1 core and 1GB RAM)</dt>
<dd>
<p>0.5 m/core (1m total)</p>
</dd>
</dl>
</section>

<section id="on-cloud-v2" class="title-slide slide level1 center">
<h1>On cloud v2</h1>
<table>
<thead>
<tr class="header">
<th style="text-align: center;"></th>
<th style="text-align: center;">On-premises</th>
<th style="text-align: center;">On cloud</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Hardware</td>
<td style="text-align: center;">2356€/year</td>
<td style="text-align: center;">38000$/year</td>
</tr>
<tr class="even">
<td style="text-align: center;">Software</td>
<td style="text-align: center;">100000€/year</td>
<td style="text-align: center;">?</td>
</tr>
</tbody>
</table>
<ul>
<li>Assuming 1 Executor = 1 Machine
<ul>
<li>Compare 4 machines on-premises vs on cloud</li>
</ul></li>
<li>On-premises
<ul>
<li>4 machines: 10602€/year / 18 machines x 4 machines = <em>2356€/year</em></li>
<li>Cloudera requires at least 10 nodes: <em>100000€/year</em></li>
</ul></li>
<li>AWS
<ul>
<li>4 EC2 instances: 162000<span class="math inline">\(/year / 18 machines x 4 machines = _36000\)</span>/year_
<ul>
<li>Plus the resources for master services = <em>2000$/year</em></li>
</ul></li>
<li>Problems
<ul>
<li>Still no software stack</li>
<li>A lot of storage cost</li>
<li>Machines are up-and-running even when no computation is necessary (just to persist data)</li>
</ul></li>
</ul></li>
<li>AWS
<ul>
<li>Still, we have no software stack configuration</li>
<li>Which is the major cost?</li>
</ul></li>
<li>AWS
<ul>
<li>Still, we have no software stack configuration</li>
<li>Which is the major cost?</li>
</ul></li>
</ul>
<p><img data-src="imgs/slides342.png"></p>
<p><img data-src="imgs/slides343.png"></p>
</section>

<section id="migration-4" class="title-slide slide level1 center">
<h1>Migration</h1>
<p>S3 standard</p>
<p>S3 Infrequent Access</p>
<p><img data-src="imgs/slides344.png"></p>
<p><img data-src="imgs/slides345.png"></p>
<ul>
<li><em>AWS Storage</em></li>
<li>HDFS on EC2
<ul>
<li>Heavy price</li>
<li>Machine must be always on to guarantee data persistency</li>
<li>Data locality</li>
</ul></li>
<li>S3
<ul>
<li>Much cheaper</li>
<li>Does not require machines for data storage</li>
<li>Data locality is lost</li>
</ul></li>
</ul>
<p><img data-src="imgs/slides346.png"></p>
<p><img data-src="imgs/slides347.png"></p>
<table>
<thead>
<tr class="header">
<th style="text-align: center;"></th>
<th style="text-align: center;">On-premises</th>
<th style="text-align: center;">On cloud</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Hardware</td>
<td style="text-align: center;">2356€/year</td>
<td style="text-align: center;">?</td>
</tr>
<tr class="even">
<td style="text-align: center;">Software</td>
<td style="text-align: center;">100000€/year</td>
<td style="text-align: center;">?</td>
</tr>
</tbody>
</table>
<ul>
<li>Migrating cluster to EMR: <em>?</em></li>
<li>Given the software requirements, we need
<ul>
<li>1 x Master Node (to manage the cluster)1 x Core node (with HDFS/EBS)</li>
<li>4 x Task Nodes (to compute)</li>
</ul></li>
</ul>
<p>Image processing</p>
<p>4 Executors (2 cores and 10GB RAM each)</p>
<dl>
<dt>Driver (2 cores and 20GB RAM)</dt>
<dd>
<p>15m/core (2h total)</p>
</dd>
</dl>
<p>Weather processing</p>
<dl>
<dt>2 Executors (1 core and 500MB RAM each)</dt>
<dd>
<p>0.5 m/core (1m total)</p>
</dd>
</dl>
<p>Driver (1 core and 1GB RAM)</p>
</section>

<section id="on-cloud-v3" class="title-slide slide level1 center">
<h1>On cloud v3</h1>
<table>
<thead>
<tr class="header">
<th style="text-align: center;"></th>
<th style="text-align: center;">On-premises</th>
<th style="text-align: center;">On cloud</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Hardware</td>
<td style="text-align: center;">2356€/year</td>
<td style="text-align: center;">14710€/year</td>
</tr>
<tr class="even">
<td style="text-align: center;">Software</td>
<td style="text-align: center;">100000€/year</td>
<td style="text-align: center;">?</td>
</tr>
</tbody>
</table>
<ul>
<li>Migrating cluster to EMR: <em>14710€/year</em>
<ul>
<li>S3 Infrequent Access storage (50 TB per month): 640€</li>
<li>1 x Master EMR nodes, EC2 (m4.xlarge), Utilization (75 h/month): 4.5€
<ul>
<li>75 h/month = 15min/task x 10task/day x 30day/month / 60min/hour</li>
</ul></li>
<li>1 x Core EMR nodes, EC2 (m4.xlarge), Utilization (75 h/month): 4.5€</li>
<li>4 x Task EMR nodes, EC2 (m4.4xlarge), Utilization (75 h/month): 72€</li>
<li>4 x EC2 <em>on demand (task node): 174.83€</em>
<ul>
<li>Storage amount (30 GB)</li>
<li>Workload (Daily, Duration of peak: 0 Hr 15 Min)</li>
<li>Instance type (m4.xlarge)</li>
</ul></li>
<li>2 x EC2 on demand (master and core nodes): 330€
<ul>
<li>Storage amount (30 GB)</li>
<li>Instance type (m4.xlarge)</li>
</ul></li>
</ul></li>
</ul>
<table>
<thead>
<tr class="header">
<th style="text-align: center;"></th>
<th style="text-align: center;">On-premises</th>
<th style="text-align: center;">On cloud</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Hardware</td>
<td style="text-align: center;">2356€/year</td>
<td style="text-align: center;">13445€/year</td>
</tr>
<tr class="even">
<td style="text-align: center;">Software</td>
<td style="text-align: center;">100000€/year</td>
<td style="text-align: center;">?</td>
</tr>
</tbody>
</table>
<ul>
<li>Migrating cluster to EMR: <em>13445€/year</em>
<ul>
<li>S3 Infrequent Access storage (50 TB per month): 640€</li>
<li>1 x Master EMR nodes, EC2 (m4.xlarge), Utilization (75 h/month): 4.5€
<ul>
<li>75 h/month = 15min/task x 10task/day x 30day/month / 60min/hour</li>
</ul></li>
<li>1 x Core EMR nodes, EC2 (m4.xlarge), Utilization (75 h/month): 4.5€</li>
<li>4 x Task EMR nodes, EC2 (m4.4xlarge), Utilization (75 h/month): 72€</li>
<li>4 x EC2 <em>spot (task node): 69.55€</em>
<ul>
<li>Storage amount (30 GB)</li>
<li>Workload (Daily, Duration of peak: 0 Hr 15 Min)</li>
<li>Instance type (m4.xlarge)</li>
</ul></li>
<li>2 x EC2 on demand (master and core nodes): 330€
<ul>
<li>Storage amount (30 GB)</li>
<li>Instance type (m4.xlarge)</li>
</ul></li>
</ul></li>
</ul>
<p><em><a href="https://calculator.aws/#/estimate?id=c3780b12bb43b593d05def5a1d5218d9764b8a65">https://calculator.aws/#/estimate?id=c3780b12bb43b593d05def5a1d5218d9764b8a65</a></em></p>
</section>

<section id="migration-5" class="title-slide slide level1 center">
<h1>Migration</h1>
<p>Summing up (cloud options)</p>
<table>
<colgroup>
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">Machine uptime</th>
<th style="text-align: center;">Storage</th>
<th style="text-align: center;">Software</th>
<th style="text-align: center;">Feasible?</th>
<th style="text-align: center;">Cost per year</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Constant</td>
<td style="text-align: center;">EC2</td>
<td style="text-align: center;">Manual</td>
<td style="text-align: center;">YES: but high storage cost</td>
<td style="text-align: center;">~36K€</td>
</tr>
<tr class="even">
<td style="text-align: center;">Constant</td>
<td style="text-align: center;">EC2</td>
<td style="text-align: center;">EMR</td>
<td style="text-align: center;">YES: but high storage cost</td>
<td style="text-align: center;">~37K€</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Constant</td>
<td style="text-align: center;">S3</td>
<td style="text-align: center;">Manual</td>
<td style="text-align: center;">YES: but still manual provisioning</td>
<td style="text-align: center;">~17K€</td>
</tr>
<tr class="even">
<td style="text-align: center;">Constant</td>
<td style="text-align: center;">S3</td>
<td style="text-align: center;">EMR</td>
<td style="text-align: center;">YES</td>
<td style="text-align: center;">~18K€</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Pay-per-use</td>
<td style="text-align: center;">EC2</td>
<td style="text-align: center;">Manual</td>
<td style="text-align: center;">NO: pay-per-use + EC2 = Data unpersisted</td>
<td style="text-align: center;">-</td>
</tr>
<tr class="even">
<td style="text-align: center;">Pay-per-use</td>
<td style="text-align: center;">EC2</td>
<td style="text-align: center;">EMR</td>
<td style="text-align: center;">NO: pay-per-use + EC2 = Data unpersisted</td>
<td style="text-align: center;">-</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Pay-per-use</td>
<td style="text-align: center;">S3</td>
<td style="text-align: center;">Manual</td>
<td style="text-align: center;">ISH: repetitive manual provisioning</td>
<td style="text-align: center;">-</td>
</tr>
<tr class="even">
<td style="text-align: center;">Pay-per-use</td>
<td style="text-align: center;">S3</td>
<td style="text-align: center;">EMR</td>
<td style="text-align: center;">YES</td>
<td style="text-align: center;">~14K€</td>
</tr>
</tbody>
</table>
<ul>
<li>Summing up
<ul>
<li>We estimated the cluster costs
<ul>
<li>On-premises solution with 18 machines: no go</li>
<li>Cloud solution with 18 EC2 instances: no go</li>
</ul></li>
<li>We reduced the solution based on software requirements
<ul>
<li>On-premises solution with 4 machines: no go</li>
<li>Cloud solution with 4 EC2 instances: no go, we miss the software configuration</li>
</ul></li>
<li>We moved the cluster to AWS EMR + spot instances + S3 storage</li>
</ul></li>
<li>Can we do better?
<ul>
<li>Pick ad-hoc cloud services (AWS Lambda e AWS Batch)</li>
<li>… to re-think the applications (food for thoughts)</li>
</ul></li>
</ul>
</section>

<section id="case-study-1" class="title-slide slide level1 center">
<h1>Case study</h1>
<p>WeLASER</p>
</section>

<section id="the-welaser-project" class="title-slide slide level1 center">
<h1>The WeLASER project</h1>
<ul>
<li><strong>Project description</strong>
<ul>
<li><em>The increased use of pesticides and </em> <em>fertilisers</em> _ damages the environment, destroys non-target plants and beneficial insects for the soil and harms human and animal health. Most seeds develop herbicide-resistant properties, rendering pesticides ineffective. Mechanical automatic systems that are studied as alternatives to pesticides deteriorate soil features, damage beneficial soil organisms and offer limited results for in-row weeding. The EU-funded WeLASER project will develop a non-chemical solution for weed management based on pioneering technology consisting of the application of lethal doses of energy on the weed meristems through a high-power laser source. An AI-vision system separates crops from weeds, identifying the weed meristems and pointing the laser at them. A smart controller based on IoT and cloud computing techniques coordinates the system, which is _ <em>transfered</em> _ all over the field by an autonomous vehicle._</li>
</ul></li>
</ul>
<p><img data-src="imgs/slides348.png"></p>
<p><a href="https://cordis.europa.eu/project/id/101000256">https://cordis.europa.eu/project/id/101000256</a> (accessed 2020-08-01)</p>
<ul>
<li>Which requirements do you foresee?</li>
<li>Can we define a tentative (service) architecture for the WeLASER project?</li>
<li>Assumptions
<ul>
<li>Do not consider the collection of weed/crop images &amp; training/deploying of the CV algorithm</li>
</ul></li>
</ul>
<p><img data-src="imgs/slides349.png"></p>
<p><a href="https://cordis.europa.eu/project/id/101000256">https://cordis.europa.eu/project/id/101000256</a> (accessed 2020-08-01)</p>
</section>

<section id="data-sources" class="title-slide slide level1 center">
<h1>Data sources</h1>
<p><a href="https://docs.google.com/spreadsheets/d/17zEr62CzyqeIy0vU-DcjEUoxf6bMd3ziLSSeIXvk4Lg/edit?usp=sharing">https://docs.google.com/spreadsheets/d/17zEr62CzyqeIy0vU-DcjEUoxf6bMd3ziLSSeIXvk4Lg/edit?usp=sharing</a></p>
</section>

<section id="workload" class="title-slide slide level1 center">
<h1>Workload</h1>
<ul>
<li>Nothing special
<ul>
<li>Every night compute aggregated indexes on the collected data (2h/day)</li>
</ul></li>
<li>On-premises (HDFS cluster)
<ul>
<li>How many machines do we need?</li>
<li>With which resources?</li>
</ul></li>
</ul>
</section>

<section id="on-premises-1" class="title-slide slide level1 center">
<h1>On-premises</h1>
<table>
<thead>
<tr class="header">
<th style="text-align: center;"></th>
<th style="text-align: center;">On-premises</th>
<th style="text-align: center;">On cloud</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Hardware</td>
<td style="text-align: center;">2900€/year</td>
<td style="text-align: center;">?</td>
</tr>
<tr class="even">
<td style="text-align: center;">Software</td>
<td style="text-align: center;">40000€/year</td>
<td style="text-align: center;">?</td>
</tr>
</tbody>
</table>
<ul>
<li>On-premises
<ul>
<li>How many machines do we need?
<ul>
<li><em>4</em>: <em>1 master node</em> + <em>3 HDFS data nodes</em></li>
</ul></li>
<li>With which resources?
<ul>
<li>Assuming a HDFS replication factor of 3, we need at least 1TB of disk overall (not that much)</li>
<li>Think bigger: at least 8 cores, 64GB RAM, 500GB SSD + 4TB HDD, no GPU</li>
</ul></li>
<li>8700€ / 3 years = 2900€</li>
</ul></li>
</ul>
<p><img data-src="imgs/slides350.png"></p>
<p><img data-src="imgs/slides351.png"></p>
<p><a href="https://www.rect.coreto-europe.com/en">https://www.rect.coreto-europe.com/en</a> (accessed 2022-09-01)<a href="https://www.cloudera.com/products/pricing.html">https://www.cloudera.com/products/pricing.html</a> (accessed 2022-09-01)</p>
</section>

<section id="on-cloud-v1-1" class="title-slide slide level1 center">
<h1>On cloud v1</h1>
<table>
<thead>
<tr class="header">
<th style="text-align: center;"></th>
<th style="text-align: center;">On-premises</th>
<th style="text-align: center;">On cloud</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Hardware</td>
<td style="text-align: center;">2900€/year</td>
<td style="text-align: center;">~40000$/year</td>
</tr>
<tr class="even">
<td style="text-align: center;">Software</td>
<td style="text-align: center;">40000€/year</td>
<td style="text-align: center;">?</td>
</tr>
</tbody>
</table>
<ul>
<li>Moving the Hadoop cluster as IAAS</li>
<li>EC2
<ul>
<li>Quantity (4), Pricing strategy (EC2 Instance Savings Plans 3 Year No Upfront), <em>Storage amount (4 TB), </em> Instance type (r6g.2xlarge)</li>
</ul></li>
<li>EMR
<ul>
<li>Number of master EMR nodes (1), EC2 instance (r5.2xlarge), Utilization (100 %Utilized/Month) Number of core EMR nodes (3), EC2 instance (r5d.2xlarge), <em>Utilization (100 %Utilized/Month)</em></li>
</ul></li>
<li><em>MKS (KAFKA)</em>
<ul>
<li>Storage per Broker (10 GB), Number of Kafka broker nodes (3), Compute Family (m5.2xlarge)</li>
</ul></li>
</ul>

<img data-src="imgs/slides352.png" class="r-stretch"><p><a href="https://calculator.aws/#/estimate?id=05965ca7de23fd9e7d2ab2cd0175fe8c01822c9c">https://calculator.aws/#/estimate?id=05965ca7de23fd9e7d2ab2cd0175fe8c01822c9c</a> (accessed 2022-09-01)</p>
</section>

<section id="on-cloud-v2-1" class="title-slide slide level1 center">
<h1>On cloud v2</h1>
<table>
<thead>
<tr class="header">
<th style="text-align: center;"></th>
<th style="text-align: center;">On-premises</th>
<th style="text-align: center;">On cloud</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Hardware</td>
<td style="text-align: center;">2900€/year</td>
<td style="text-align: center;">~4000$/year</td>
</tr>
<tr class="even">
<td style="text-align: center;">Software</td>
<td style="text-align: center;">40000€/year</td>
<td style="text-align: center;">?</td>
</tr>
</tbody>
</table>
<ul>
<li>Moving the Hadoop cluster as PAAS</li>
<li>EC2
<ul>
<li>Quantity (4), Pricing strategy (<em>On-Demand Instances</em>), Storage amount (30 GB), Instance type (r6g.2xlarge)</li>
</ul></li>
<li>EMR
<ul>
<li>Number of master EMR nodes (1), EC2 instance (r5.2xlarge), Utilization (2 Hours/Day) Number of core EMR nodes (3), EC2 instance (r5d.2xlarge), <em>Utilization (2 Hours/Day)</em></li>
</ul></li>
<li><em>S3</em>
<ul>
<li>Standard storage (60 GB per month)</li>
</ul></li>
<li><em>Kinesis</em>
<ul>
<li>Days for data retention (1 days), Records (100 per second), Consumer Applications (3)</li>
</ul></li>
</ul>

<img data-src="imgs/slides353.png" class="r-stretch"><p><a href="https://calculator.aws/#/estimate?id=53f60ff0412a18877dc8e1274f7d9875aa3bf665">https://calculator.aws/#/estimate?id=53f60ff0412a18877dc8e1274f7d9875aa3bf665</a> (accessed 2022-09-01)</p>
</section>

<section id="cost-vs-price" class="title-slide slide level1 center">
<h1>Cost vs price</h1>
<p>How would you evaluate the cost and the price?</p>
<ul>
<li><em>Price</em> is the amount a customer is willing to pay&nbsp;for a&nbsp;product or service</li>
<li><em>Cost</em> is the expense incurred for&nbsp;creating a product or service
<ul>
<li>Hardware</li>
<li>Development</li>
<li>Maintenance</li>
</ul></li>
<li><em>Profit</em> is the difference between price&nbsp;paid and costs&nbsp;incurred is profit
<ul>
<li>If a customer pays&nbsp;$10 for a product that costs&nbsp;$6&nbsp;to make and sell, the company earns&nbsp;$4</li>
</ul></li>
</ul>
</section>

<section id="newsection-7" class="title-slide slide level1 center">
<h1>– newsection –</h1>

</section>

<section id="data-pipelines-on-cloud-streaming" class="title-slide slide level1 center">
<h1>Data pipelines on cloud (Streaming)</h1>

</section>

<section id="section-6" class="title-slide slide level1 center">
<h1></h1>
<p>Supporting services</p>
<p>Serve (deciding)</p>
<p>BI tools (e.g., Tableau)</p>
<p>Analytics (analyzing)</p>
<p>Networking, etc.</p>
<p>Machine learning</p>
<p>Ingestion (acquiring)</p>
</section>

<section id="reference-scenario-batch-vs-stream" class="title-slide slide level1 center">
<h1>Reference scenario: batch vs stream</h1>

</section>

<section id="batch-vs.-streaming-systems" class="title-slide slide level1 center">
<h1>Batch vs.&nbsp;Streaming systems</h1>
<ul>
<li>What is a bulk processing system?
<ul>
<li>High latency</li>
<li>Exact results</li>
<li>Process massive data at once
<ul>
<li>… is this true?</li>
</ul></li>
</ul></li>
<li>What is a streaming system?
<ul>
<li>Low latency</li>
<li>Approximate result
<ul>
<li>… is this true?</li>
</ul></li>
<li>Process data item by data item
<ul>
<li>… is this true?</li>
</ul></li>
</ul></li>
<li>What is a bulk processing system?
<ul>
<li>An engine capable to handle processing on <strong>bounded</strong> datasets</li>
</ul></li>
<li>What is a streaming system?
<ul>
<li>An engine capable to handle processing on <strong>unbounded</strong> datasets</li>
<li>Streaming is a superset of batch processing</li>
</ul></li>
</ul>
<p>Akidau, Tyler, Slava Chernyak, and Reuven Lax. <em>Streaming systems: the what, where, when, and how of large-scale data processing</em> . ” O’Reilly Media, Inc.”, 2018.</p>
</section>

<section id="reference-scenario-batch-vs-stream-1" class="title-slide slide level1 center">
<h1>Reference scenario: batch vs stream</h1>
<table>
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;"></th>
<th style="text-align: center;">Batch data processing</th>
<th style="text-align: center;">Stream data processing</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Data scope</td>
<td style="text-align: center;">Queries or processing over all or most of the data in the dataset</td>
<td style="text-align: center;">Queries or processing over data within a rolling time window, or on just the most recent data record</td>
</tr>
<tr class="even">
<td style="text-align: center;">Data size</td>
<td style="text-align: center;">Large batches of data</td>
<td style="text-align: center;">Individual records or micro batches consisting of a few records</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Latency</td>
<td style="text-align: center;">Minutes to hours</td>
<td style="text-align: center;">Seconds or milliseconds</td>
</tr>
<tr class="even">
<td style="text-align: center;">Analysis</td>
<td style="text-align: center;">Complex analytics</td>
<td style="text-align: center;">Simple response functions, aggregates, and rolling metrics</td>
</tr>
</tbody>
</table>
</section>

<section id="ingestion-batch" class="title-slide slide level1 center">
<h1>Ingestion: batch</h1>
<ul>
<li><strong>Goal</strong>: moving data to the cloud</li>
<li>Moving data to the cloud
<ul>
<li><em>80TB</em> of data to move,</li>
<li><em>1Gbps</em> connection to the internet</li>
</ul></li>
<li>How many <em>days</em>?
<ul>
<li><em>80000GB</em> / (<em>1Gbps / 8</em>) / <em>60 / 60 / 24 </em> ~= a week without internet</li>
</ul></li>
<li>Batch/Bulk: move data from on-premises storage</li>
<li>Workflow
<ul>
<li>Receive shipment</li>
<li>Set up</li>
<li>Transfer data</li>
<li>Ship back (shipping carrier)</li>
</ul></li>
</ul>
</section>

<section id="ingestion-batch-aws" class="title-slide slide level1 center">
<h1>Ingestion: batch (AWS)</h1>
<ul>
<li>AWS Snowball
<ul>
<li>50TB (North America only) and 80TB versions</li>
<li>Not rack-mountable</li>
</ul></li>
<li>Throughput
<ul>
<li>1 Gbps or 10 Gbps using an RJ-45 connection</li>
<li>10 Gbps using a fiber optic connection</li>
</ul></li>
</ul>
<p><img data-src="imgs/slides354.png"></p>
<p><a href="https://aws.amazon.com/snowball/">https://aws.amazon.com/snowball/</a></p>
<p><img data-src="imgs/slides355.png"></p>
</section>

<section id="aws-snowmobile" class="title-slide slide level1 center">
<h1>AWS Snowmobile</h1>
<p>What if we have exabyte of data?</p>
<p>Value Metric</p>
<p>103 KB (kilobyte)</p>
<p>106 MB (megabyte)</p>
<p>109 GB (gigabyte)</p>
<p>1012 TB (terabyte)</p>
<p>1015 PB (petabyte)</p>
<p>1018 EB (exabyte)</p>
<p>1021 ZB (zettabyte)</p>
<p>1024 YB (yottabyte)</p>
<p><a href="https://youtu.be/8vQmTZTq7nw?t=45">https://youtu.be/8vQmTZTq7nw?t=45</a> (2022-11-14)</p>
</section>

<section id="ingestion-stream" class="title-slide slide level1 center">
<h1>Ingestion: stream</h1>
<ul>
<li>Data (often) flows in both directions, storage systems are both sources and destinations for data transformations</li>
<li>Two pipelines per application (data in/out)
<ul>
<li>Worst case (full connectivity): O(N2)</li>
</ul></li>
</ul>
<p><img data-src="imgs/slides356.png"></p>
<p>Kreps, Jay. <em>I heart logs: Event data, stream processing, and data integration</em> . ” O’Reilly Media, Inc.”, 2014.</p>
<ul>
<li><strong>Stream</strong>: real-time streaming data</li>
<li><strong>Event</strong>: anything that we can observe occurring at a particular point in time</li>
<li><strong>Continuous streaming</strong>
<ul>
<li>Illimited succession of individual events</li>
<li>Ordered by the point in time at which each event occurred</li>
</ul></li>
<li><strong>Publish/subscribe (pub/sub)</strong>: a way of communicating messages
<ul>
<li><em>Senders</em> publish messages associated with one or more <strong>topics</strong></li>
<li><em>Receivers</em> subscribe to specific topics, receive all messages with that topic</li>
<li><em>Messages</em> are events</li>
</ul></li>
</ul>
<p><img data-src="imgs/slides357.jpg"></p>
<p><a href="https://www.manning.com/books/event-streams-in-action">https://www.manning.com/books/event-streams-in-action</a></p>
<ul>
<li>Log
<ul>
<li>Append-only data structure</li>
<li>Each application only knows about the log, it ignores the details of the source
<ul>
<li>E.g., a data consumer is not concerned about whether the data came from a relational database or some application</li>
</ul></li>
</ul></li>
<li>The log acts as a messaging system with durability guarantees and ordering semantics</li>
</ul>
<p><img data-src="imgs/slides358.png"></p>
<p>Kreps, Jay. <em>I heart logs: Event data, stream processing, and data integration</em> . ” O’Reilly Media, Inc.”, 2014.</p>
<ul>
<li>General idea:
<ul>
<li>Collect events from many source systems</li>
<li>Store them in a unified log</li>
<li>Enable applications to operate on these event streams</li>
</ul></li>
<li><strong>Unified log</strong>
<ul>
<li><em>Unified</em> , <em>append-only</em> , <em>ordered</em> , <em>distributed</em> log that allows the centralization of event streams</li>
</ul></li>
</ul>
<p><img data-src="imgs/slides359.jpg"></p>
<ul>
<li><strong>Unified</strong>: a single log in a company with applications sending/reading events
<ul>
<li>Log serves as central data backbone
<ul>
<li>It can contain many distinct continuous streams of events</li>
<li>Not all events are sent to the same event stream</li>
</ul></li>
</ul></li>
<li><strong>Append-only</strong>: new events are appended to the unified log
<ul>
<li>Existing events are never updated in place
<ul>
<li>If read the event #10, never look at events 1 through 10 again</li>
</ul></li>
<li>Events are automatically deleted from the unified log when they age
<ul>
<li>E.g., automatically remove events after 7 days</li>
</ul></li>
</ul></li>
<li><strong>Distributed</strong>: the unified log lives across a cluster of machines
<ul>
<li>Optionally divide events into shards (i.e., partitions)Still, the log is unified since we have a single (conceptual) log</li>
</ul></li>
<li>Distribution ensures
<ul>
<li>Scalability: work with streams larger than the capacity of single machines</li>
<li>Durability: replicate all events within the cluster to overcome data loss</li>
<li>Using a log as a universal integration mechanism is never going to be more than an elegant fantasy if we can’t build a log that is fast, cheap, and scalable</li>
</ul></li>
</ul>
<p><img data-src="imgs/slides360.jpg"></p>
<ul>
<li><strong>Ordered</strong>: events in a shard have a sequential IDs (unique in a shard)
<ul>
<li>Local ordering keeps things much simpler than global ordering</li>
<li>Applications maintain their own cursor for each shard</li>
</ul></li>
</ul>
<p><img data-src="imgs/slides361.jpg"></p>
<p>Lamport, Leslie. “Time, clocks, and the ordering of events in a distributed system.” <em>Concurrency: the Works of Leslie </em> <em>Lamport</em> . 2019. 179-196.</p>
<ul>
<li>Two types of processing
<ul>
<li><strong>Single-event:</strong> a single event produces zero or more events
<ul>
<li>Validating “Does this event contain all the required fields?”</li>
<li>Enriching “Where is this IP address located?”</li>
<li>Filtering “Is this error critical?”</li>
</ul></li>
<li><strong>Multiple-event:</strong> multiple events collectively produce zero or more events
<ul>
<li>Aggregating, functions such as minimum, maximum, sum</li>
<li>Pattern matching, looking for patterns or co-occurrence</li>
<li>Reordering events based on a sort key</li>
</ul></li>
</ul></li>
</ul>
<p><img data-src="imgs/slides362.png"></p>
<ul>
<li>Why not communicating directly using messaging protocols?</li>
<li>A log enables
<ul>
<li>Multi-subscriber: each data item is available to any processor that wants it</li>
<li>Order: maintained in the processing done by each consumer of data</li>
<li>Buffering and isolation to the individual processes
<ul>
<li>E.g., a that processor produces faster than its downstream consumer can keep up</li>
</ul></li>
<li>Reprocessing, maintaining state, etc.</li>
</ul></li>
<li>Indeed, logs are common:
<ul>
<li>MapReduce workflows use files to checkpoint and share their intermediate results</li>
<li>SQL processing pipelines create intermediate or temporary tables</li>
</ul></li>
</ul>
</section>

<section id="ingestion-stream-aws" class="title-slide slide level1 center">
<h1>Ingestion: stream (AWS)</h1>
<ul>
<li>Amazon Kinesis Data Streams
<ul>
<li>Created and provisioned by shard
<ul>
<li>Each shard provides 1 MBps and 1000 data puts per second</li>
</ul></li>
<li>A data record consists of
<ul>
<li>User-supplied partition key to balance records across shards</li>
<li>Incremental sequence number added by the shard</li>
<li>A data blob</li>
</ul></li>
<li>Consumers get records by shard
<ul>
<li>Records are sorted by partition key and sequence number</li>
<li>Ordering is not guaranteed across shards</li>
</ul></li>
<li>Records are retained for 7 days at maximum</li>
</ul></li>
</ul>

<img data-src="imgs/slides363.png" class="r-stretch"><p><a href="https://docs.aws.amazon.com/streams/latest/dev/key-concepts.html">https://docs.aws.amazon.com/streams/latest/dev/key-concepts.html</a></p>
<ul>
<li>Re-sharding (i.e., scaling)
<ul>
<li>Split a shard into two, or merge two shards</li>
<li>Users must scale shards up and down manually
<ul>
<li>Monitor usage with Amazon CloudWatch and modify scale as needed</li>
</ul></li>
<li>Avoid shard management by using Kinesis Data Firehose</li>
</ul></li>
<li>Kinesis is a regional service, with streams scoped to specific regions
<ul>
<li>All ingested data must travel to the region in which the stream is defined</li>
</ul></li>
<li>Costs
<ul>
<li>Priced by shard hour, data volume, and data retention period</li>
<li>Pay for resources you provision (even if not used)</li>
</ul></li>
</ul>
<p><a href="https://aws.amazon.com/cloudwatch/">https://aws.amazon.com/cloudwatch/</a><a href="https://aws.amazon.com/kinesis/data-firehose">https://aws.amazon.com/kinesis/data-firehose</a></p>
</section>

<section id="ingestion-stream-1" class="title-slide slide level1 center">
<h1>Ingestion: stream</h1>
<table>
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">Feature</th>
<th style="text-align: center;">AWS Kinesis</th>
<th style="text-align: center;">Google Pub/Sub</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Unit of deployment</td>
<td style="text-align: center;">Stream</td>
<td style="text-align: center;">Topic</td>
</tr>
<tr class="even">
<td style="text-align: center;">Unit of provisioning</td>
<td style="text-align: center;">Shard</td>
<td style="text-align: center;">N/A (fully managed)</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Data unit</td>
<td style="text-align: center;">Record</td>
<td style="text-align: center;">Message</td>
</tr>
<tr class="even">
<td style="text-align: center;">Data producer/destination</td>
<td style="text-align: center;">Producer/Consumer</td>
<td style="text-align: center;">Publisher/Subscriber</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Data partitioning</td>
<td style="text-align: center;">User-supplied partition key</td>
<td style="text-align: center;">N/A (fully managed)</td>
</tr>
<tr class="even">
<td style="text-align: center;">Retention period</td>
<td style="text-align: center;">Up to 7 days</td>
<td style="text-align: center;">Up to 7 days</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Pricing</td>
<td style="text-align: center;">Per shard-hour, PUT payload units,<br>and optional data retention</td>
<td style="text-align: center;">Message ingestion and delivery,<br>and optional message retention</td>
</tr>
</tbody>
</table>
</section>

<section id="section-7" class="title-slide slide level1 center">
<h1></h1>
<p>Supporting services</p>
<p>Serve (deciding)</p>
<p>BI tools (e.g., Tableau)</p>
<p>Analytics (analyzing)</p>
<p>Networking, etc.</p>
<p>Machine learning</p>
<p>Ingestion (acquiring)</p>
</section>

<section id="serverless-computingprocessing" class="title-slide slide level1 center">
<h1>Serverless computing/processing</h1>
<ul>
<li>AWS Lambda: compose code functions in a loose orchestration
<ul>
<li>Build modular back-end systems</li>
<li>Event-driven and push-based pipelines</li>
</ul></li>
<li>With Lambda, you are responsible only for your code (Lambda function)
<ul>
<li>Lambda manages the compute fleet that offers a balance of memory and CPU</li>
<li>Lambda performs operational and administrative activities on your behalf
<ul>
<li>Provisioning capacity, monitoring fleet health, applying security patches, etc.</li>
</ul></li>
</ul></li>
</ul>

<img data-src="imgs/slides364.png" class="r-stretch"></section>

<section id="serverless-computing-aws-lambda" class="title-slide slide level1 center">
<h1>Serverless computing (AWS Lambda)</h1>
<ul>
<li>AWS Lambda
<ul>
<li>A Lambda function is a granular service</li>
<li>The Lambda runtime invokes a lambda function multiple times in parallel</li>
<li>Compute service that executes code written in JavaScript/Python/C#/Java
<ul>
<li>Elastic Compute Cloud (EC2) servers run the code (e.g., a Linux server)</li>
</ul></li>
<li>A function is <code>code + configuration + dependencies</code>
<ul>
<li>Source code (JARs or DLLs) is zipped up and deployed to a container</li>
</ul></li>
<li>Invocation supports push/pull events</li>
</ul></li>
</ul>

<img data-src="imgs/slides365.png" class="r-stretch"></section>

<section id="serverless-computing-faas" class="title-slide slide level1 center">
<h1>Serverless computing (FaaS)</h1>
<ul>
<li>FaaS: write single-purpose stateless functions
<ul>
<li>Keep the single responsibility principle in mind</li>
<li>A function that does just one thing is more testable and robust</li>
<li>A function with a well-defined interface is also more likely to be reused</li>
<li>Code should be created in a stateless style
<ul>
<li>Statelessness allows scalability</li>
<li>Local resources or processes will not survive along sessions</li>
</ul></li>
<li>Functions that terminate sooner are cheaper
<ul>
<li>E.g., pricing is based on #requests, execution time, and allocated memory</li>
</ul></li>
</ul></li>
</ul>
</section>

<section id="patterns-for-data-pipelines" class="title-slide slide level1 center">
<h1>Patterns for data pipelines</h1>
<ul>
<li>Patterns are architectural solutions to problems in software design
<ul>
<li>A (design) pattern is a general, best-practice reusable solution to a commonly occurring problem within a given context in software design</li>
<li>It is a template for how to solve a problem in many different situations</li>
</ul></li>
<li>Patterns for serverless data pipelines
<ul>
<li>Command pattern</li>
<li>Messaging pattern</li>
<li>Priority queue pattern</li>
<li>Pipes and filters pattern</li>
</ul></li>
</ul>

<img data-src="imgs/slides366.jpg" class="r-stretch"><p><a href="https://www.manning.com/books/aws-lambda-in-action">https://www.manning.com/books/aws-lambda-in-action</a></p>
</section>

<section id="command-pattern" class="title-slide slide level1 center">
<h1>Command pattern</h1>
<ul>
<li>Command pattern
<ul>
<li>A behavioral design pattern in which an object is used to encapsulate the information needed to perform an action or trigger an event</li>
</ul></li>
<li>Encapsulate a request as an object
<ul>
<li>Issue requests to objects without knowing anything about the operation being requested or the receiver</li>
</ul></li>
</ul>

<img data-src="imgs/slides367.png" class="r-stretch"><p><a href="https://aws.amazon.com/api-gateway">https://aws.amazon.com/api-gateway</a></p>
</section>

<section id="pipes-and-filters-pattern" class="title-slide slide level1 center">
<h1>Pipes and filters pattern</h1>
<ul>
<li>Decompose a complex processing task into a sequence of manageable services
<ul>
<li>Components designed to transform data are referred to as filters</li>
<li>Connectors that pass data between components are referred to as pipes</li>
</ul></li>
</ul>

<img data-src="imgs/slides368.png" class="r-stretch"></section>

<section id="messaging-pattern" class="title-slide slide level1 center">
<h1>Messaging pattern</h1>
<ul>
<li>Messaging pattern
<ul>
<li>Describes how two different parts of a message passing system connect and communicate with each other</li>
</ul></li>
<li>Decouple services from direct dependence and allow storage of events in a queue
<ul>
<li>Reliability: if the consuming service goes offline, messages are retained in the queue and can still be processed</li>
<li>A message queue can have a single sender/receiver or multiple senders/receivers</li>
</ul></li>
</ul>

<img data-src="imgs/slides369.png" class="r-stretch"></section>

<section id="priority-queue-pattern" class="title-slide slide level1 center">
<h1>Priority queue pattern</h1>
<ul>
<li>Decouple and prioritize requests sent to services
<ul>
<li>Requests with a higher priority are received and processed more quickly than those with a lower priority</li>
<li>Useful in applications that offer different service level guarantees</li>
</ul></li>
<li>Control how and when messages are dealt with
<ul>
<li>Different queues, topics, or streams to feed messages to your functions</li>
<li>High-priority messages go through expensive services with more capacity</li>
</ul></li>
</ul>

<img data-src="imgs/slides370.png" class="r-stretch"></section>

<section id="thats-all-folks" class="title-slide slide level1 center">
<h1>That’s all, folks!</h1>

</section>

<section id="feedbacks" class="title-slide slide level1 center">
<h1>Feedbacks?</h1>

</section>

<section id="exams" class="title-slide slide level1 center">
<h1>Exams</h1>

</section>

<section id="newsection-8" class="title-slide slide level1 center">
<h1>– newsection –</h1>

</section>

<section id="hands-on-aws" class="title-slide slide level1 center">
<h1>Hands on AWS</h1>

</section>

<section id="a-tentative-organization-2" class="title-slide slide level1 center">
<h1>A tentative organization</h1>
<p>Supporting services</p>
<p>Serve (deciding)</p>
<p>BI tools (e.g., Tableau)</p>
<p>Analytics (analyzing)</p>
<p>Networking, etc.</p>
<p>Machine learning</p>
<p>Ingestion (acquiring)</p>
</section>

<section id="identity-and-access-management" class="title-slide slide level1 center">
<h1>Identity and Access Management</h1>
<ul>
<li>Identity and Access Management (IAM)
<ul>
<li>Web service that controls fine-grained access to AWS resources</li>
<li>IAM controls who is authenticated and authorized to use resources</li>
</ul></li>
<li>IAM user
<ul>
<li>Unique identity recognized by AWS services and applications</li>
<li>Similar to user in an operating system like Windows or UNIX</li>
</ul></li>
<li>IAM role
<ul>
<li>Set of policies for making AWS service requests</li>
<li>Trusted entities (e.g., such as IAM users) assume roles
<ul>
<li>Delegate access with defined permissions to trusted entities</li>
<li>There is no limit to the number of IAM roles a user can assume</li>
</ul></li>
</ul></li>
<li>User vs role
<ul>
<li>User has permanent long-term credentials and is used to directly interact with AWS services</li>
<li>Role does not have credentials and cannot make direct requests to AWS services</li>
<li>Roles are assumed by authorized entities, such as IAM users</li>
</ul></li>
<li>Alice (i.e., an IAM user) is a firewoman
<ul>
<li>She is the same person with or without her turnout gear</li>
<li>As a firewoman (i.e., a role)
<ul>
<li>If she speeds to a house fire and passes a police officer, he isn’t going to give her a ticket</li>
<li>In her role as a <em>firewoman</em> , she is allowed to speed to the house fire</li>
</ul></li>
<li>As a private citizen (i.e., another role)
<ul>
<li>When she is off duty, if she speeds past that same police officer, he’s going to give her a ticket</li>
<li>In her role as a <em>private citizen</em> , she is not allowed to speed</li>
</ul></li>
</ul></li>
</ul>
</section>

<section id="aws" class="title-slide slide level1 center">
<h1>AWS</h1>
<ul>
<li>Amazon Web Services (AWS) is a public-cloud platform</li>
<li>Services can be accessed in multiple ways
<ul>
<li>Web GUI: intuitive point and click access without any programming
<ul>
<li>Intuitive interfaces is part of the attraction of cloud services</li>
<li>Tedious if the same actions must be performed repeatedly</li>
</ul></li>
<li>(REST) Application programming interface (API)
<ul>
<li>Permits requests to be transmitted via Hypertext Transfer Protocol (HTTPS)</li>
</ul></li>
<li>Software development kits (SDKs) that you install on your computer
<ul>
<li>Access from programming languages such as Python, Java, etc.</li>
</ul></li>
</ul></li>
</ul>
</section>

<section id="aws-web-console" class="title-slide slide level1 center">
<h1>AWS Web console</h1>
<ul>
<li>We use the AWS Educate program
<ul>
<li>Login with the provided account</li>
<li>You got 150$ to work on AWS services</li>
<li>Provisioned services charge even if not used</li>
</ul></li>
</ul>
<p><img data-src="imgs/slides371.png"></p>
<p><a href="https://www.awseducate.com/signin/SiteLogin">https://www.awseducate.com/signin/SiteLogin</a></p>
<p><img data-src="imgs/slides372.png"></p>
</section>

<section>
<section id="aws-cli" class="title-slide slide level1 center">
<h1>AWS CLI</h1>
<ul>
<li>CLI interface
<ul>
<li>Necessary to install the CLI (version 2)</li>
<li>See <a href="https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2.html">https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2.html</a></li>
</ul></li>
</ul>
<p>Synopsis</p>
</section>
<section class="slide level2">

<p>aws [options] &lt;command&gt; &lt;subcommand&gt; [parameters]</p>
<p>Description</p>
</section>
<section class="slide level2">

<p>A unified tool to manage your AWS services.</p>
<p><a href="https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2-linux.html">https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2-linux.html</a></p>
<p><img data-src="imgs/slides373.png"></p>
<ul>
<li>CLI needs credentials to work
<ul>
<li>Go back to AWS Educate</li>
<li>Click on “Account Details”</li>
<li>Copy the content into the file ~/.aws/credentials</li>
<li>Henceforth, we assume that you have set up the credentials file</li>
<li>Credentials expire after some time; you need a manually refresh</li>
</ul></li>
</ul>
<p><img data-src="imgs/slides374.png"></p>
<ul>
<li>Run <code>aws configure</code>
<ul>
<li>Confirm AWS Access Key ID (press enter)</li>
<li>Confirm AWS Secret Access Key (press enter)</li>
<li>Set Default region name to <code>us-east-1</code></li>
<li>Set Default output format to <code>json</code></li>
</ul></li>
<li>It is also possible to configure an AWS profile
<ul>
<li>A (named) profile is a collection of settings and credentials</li>
<li>If profile is specified, its settings and credentials are used to run a command</li>
<li>When no profile is explicitly referenced, use <code>default</code>
<ul>
<li>We stick to <code>default</code></li>
</ul></li>
</ul></li>
</ul>
</section></section>
<section id="object-storage-s3" class="title-slide slide level1 center">
<h1>Object storage: S3</h1>
<ul>
<li>Create S3 bucket, the following rules apply for naming buckets
<ul>
<li>Must be between 3 and 63 characters long</li>
<li>Can consist only of lowercase letters, numbers, dots (.), and hyphens (-)</li>
<li>Must be unique within a partition (i.e., a group of regions)</li>
</ul></li>
</ul>
<p>$ git clone <a href="https://github.com/w4bo/bigdata-aws/">https://github.com/w4bo/bigdata-aws/</a></p>
<p>$ cd bigdata-aws/lab01-lambda</p>
<p>$ aws s3api create-bucket –bucket aws-bucket-bigdata2021</p>
<p>$ aws s3 cp datasets/inferno.txt s3://aws-bucket-bigdata2021/inferno.txt</p>
<p>$ aws s3api list-objects –bucket aws-bucket-bigdata2021</p>
<p><a href="https://s3.console.aws.amazon.com/s3/home?region=us-east-1">https://s3.console.aws.amazon.com/s3/home?region=us-east-1#</a></p>
</section>

<section id="newsection-9" class="title-slide slide level1 center">
<h1>– newsection –</h1>

</section>

<section id="data-pipelines-on-aws-lambda" class="title-slide slide level1 center">
<h1>Data pipelines on AWS Lambda</h1>

</section>

<section id="requirements" class="title-slide slide level1 center">
<h1>Requirements</h1>
<ul>
<li>To start this lecture, you need to
<ul>
<li>Activate your AWS Educate account</li>
<li>Either
<ul>
<li>Install the necessary software
<ul>
<li>git</li>
<li>IntelliJ IDEA (with AWS Toolkit and Scala plugins)</li>
<li>python</li>
<li>java 1.8</li>
<li>Docker</li>
<li>AWS CLI, AWS SAM CLI</li>
</ul></li>
<li>Be able to download and run the VM</li>
</ul></li>
</ul></li>
</ul>
</section>

<section id="aws-sam-cli" class="title-slide slide level1 center">
<h1>AWS SAM CLI</h1>
<ul>
<li>Serverless Application Model is a framework to build serverless applications
<ul>
<li>A serverless application is a combination of Lambda functions, event sources, etc.</li>
<li>Install AWS SAM CLI (on Linux)</li>
</ul></li>
</ul>
<p>sudo group add docker</p>
<p>sudo usermod –aG docker $USER</p>
<p>newgrp docker</p>
<p>sudo chmod 666 /var/run/docker.sock</p>
<p>wget <a href="https://github.com/aws/aws-sam-cli/releases/latest/download/aws-sam-cli-linux-x86_64.zip">https://github.com/aws/aws-sam-cli/releases/latest/download/aws-sam-cli-linux-x86_64.zip</a></p>
<p>unzip aws-sam-cli-linux-x86_64.zip -d sam-installation</p>
<p>sudo ./sam-installation/install</p>
<p>sam –version</p>
<p><a href="https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/serverless-sam-cli-install.html">https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/serverless-sam-cli-install.html</a></p>
</section>

<section id="aws-services" class="title-slide slide level1 center">
<h1>AWS services</h1>
<ul>
<li>AWS Educate (and AWS console)
<ul>
<li><a href="https://aws.amazon.com/it/education/awseducate/">https://aws.amazon.com/it/education/awseducate/</a></li>
<li><a href="https://console.aws.amazon.com/console/home?region=us-east-1">https://console.aws.amazon.com/console/home?region=us-east-1</a></li>
</ul></li>
<li>IAM (authentication)
<ul>
<li><a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/iam-ug.pdf">https://docs.aws.amazon.com/IAM/latest/UserGuide/iam-ug.pdf</a></li>
</ul></li>
<li>SDK (software API)
<ul>
<li><a href="https://docs.aws.amazon.com/sdk-for-java/latest/developer-guide/home.html">https://docs.aws.amazon.com/sdk-for-java/latest/developer-guide/home.html</a></li>
</ul></li>
<li>Lambda (serverless computing and processing)
<ul>
<li><a href="https://docs.aws.amazon.com/lambda/latest/dg/getting-started.html">https://docs.aws.amazon.com/lambda/latest/dg/getting-started.html</a></li>
<li><a href="https://console.aws.amazon.com/lambda/home?region=us-east-1#/functions">https://console.aws.amazon.com/lambda/home?region=us-east-1#/functions</a></li>
</ul></li>
<li>DynamoDB (key-value database)
<ul>
<li><a href="https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Introduction">https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Introduction</a></li>
</ul></li>
<li>S3 (object storage)
<ul>
<li><a href="https://s3.console.aws.amazon.com/s3/home?region=us-east-1">https://s3.console.aws.amazon.com/s3/home?region=us-east-1</a></li>
</ul></li>
</ul>
</section>

<section id="case-study-2" class="title-slide slide level1 center">
<h1>Case study</h1>
<p>Given a dataset of sales per customer</p>
<p>find the products frequently bought together</p>
<p>Dataset sample</p>
<p>%%%%%%%%%%%%%%</p>
<p>[ { customerName: Alice, products: [Pizza, Beer, Diaper] },</p>
<p>{ customerName: Bob, products: [Pizza, Beer, Diaper] },</p>
<p>{ customerName: Charlie, products: [Pizza, Cola] } ]</p>
<ul>
<li>The pipeline involves a single transformation
<ul>
<li>A classic mining problem, which one?</li>
</ul></li>
</ul>
</section>

<section id="frequent-itemset-mining" class="title-slide slide level1 center">
<h1>Frequent itemset mining</h1>
<p>Dataset sample</p>
<p>%%%%%%%%%%%%%%</p>
<p>[[Pizza, Beer, Diaper],</p>
<p>[Pizza, Beer, Diaper],</p>
<p>[Pizza, Cola]]</p>
<ul>
<li>Find sets of items (i.e., itemsets) frequently appearing together
<ul>
<li><strong>Item</strong>: a product</li>
<li><strong>Itemset</strong>: a set of products</li>
<li><strong>Frequently</strong>: support above threshold</li>
<li><strong>Support</strong>: number of clients buying a set of products</li>
</ul></li>
<li>Complexity: O(2|items|)</li>
</ul>
<p>{Pizza,Diaper,Beer}</p>
</section>

<section id="case-study-3" class="title-slide slide level1 center">
<h1>Case study</h1>
<p>Processed dataset sample</p>
<p>%%%%%%%%%%%%%%</p>
<p>[[Pizza, Beer, Diaper],</p>
<p>[Pizza, Beer, Diaper],</p>
<p>[Pizza, Cola]]</p>
<p>Raw dataset sample</p>
<p>%%%%%%%%%%%%%%</p>
<p>[ { customerName: Alice, products: [Pizza, Beer, Diaper] },</p>
<p>{ customerName: Bob, products: [Pizza, Beer, Diaper] },</p>
<p>{ customerName: Charlie, products: [Pizza, Cola] } ]</p>
</section>

<section id="reference-pipeline" class="title-slide slide level1 center">
<h1>Reference pipeline</h1>
<p><img data-src="imgs/slides375.png"></p>
<p><img data-src="imgs/slides376.png"></p>
</section>

<section id="nosql-storage-dynamodb" class="title-slide slide level1 center">
<h1>NOSQL storage: DynamoDB</h1>
<ul>
<li>Basic DynamoDB components: tables and items</li>
<li><strong>Tables</strong> , collection of (data) items</li>
<li><strong>Items</strong> , a group of attributes that is uniquely identifiable
<ul>
<li>Each table contains zero or more items
<ul>
<li>No limit to the number of items you can store in a table</li>
</ul></li>
<li>Each item in the table has a unique identifier, or primary key</li>
<li>E.g., in the table <code>people</code>, each item represents a <code>person</code>
<ul>
<li>The primary key consists of one attribute (<code>fiscalCode</code>)</li>
</ul></li>
</ul></li>
<li>Attributes
<ul>
<li>A data element that is not broken down any further
<ul>
<li>E.g., an item in the <code>people</code> table contains attributes <code>fiscalCode</code> and <code>lastName</code></li>
</ul></li>
<li>Most of the attributes are scalar (have only one value)</li>
<li>Some of the items have a nested attribute (<code>address</code>) up to 32 levels deep</li>
</ul></li>
<li>Schemaless
<ul>
<li>Other than the primary key, a table is schemaless
<ul>
<li>Neither the attributes nor their data types need to be defined beforehand</li>
<li>Each item can have its own distinct attributes</li>
</ul></li>
</ul></li>
<li>Primary Key
<ul>
<li>To create a table, you must specify the primary key of the table</li>
<li>No two items can have the same key</li>
</ul></li>
<li>Two types of primary keys
<ul>
<li>Partition key: a simple primary key composed of one attribute (partition key)
<ul>
<li>Keys are inputs to an internal hash function</li>
<li>The hash function determines the physical partition in which the item will be stored</li>
<li>E.g., access any item in the <code>people</code> table directly by providing the <code>fiscalCode</code></li>
</ul></li>
<li>Composite primary key: partition key and sort key (two attributes)
<ul>
<li>First attribute is the partition key</li>
<li>Second attribute is the sort key</li>
<li>Items in same partition key value are stored together and sorted by sort key</li>
</ul></li>
</ul></li>
</ul>

<img data-src="imgs/slides377.png" class="r-stretch"><p><a href="https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/bp-gsi-overloading.html">https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/bp-gsi-overloading.html</a></p>
<ul>
<li>Secondary Indexes
<ul>
<li>One or more secondary indexes per table</li>
<li>Indexes are automatically maintained on add, update, or delete</li>
<li>Query data using an alternate key (additionally to queries against primary key)</li>
</ul></li>
<li>Two types of indexes
<ul>
<li>Global secondary has partition and sort keys different from those on table</li>
<li>Local secondary has the same partition key but a different sort key</li>
<li>Each table has a limited quota of 20 global and 5 local indexes</li>
</ul></li>
<li>How do we shape the schema?
<ul>
<li><a href="https://cloud.google.com/bigtable/docs/schema-design">https://cloud.google.com/bigtable/docs/schema-design</a></li>
</ul></li>
<li>Create a table <code>frequent-sales</code> with a composite key
<ul>
<li><code>dataset</code>: String</li>
<li><code>timestamp</code>: String</li>
</ul></li>
</ul>
<p>$ aws dynamodb create-table \</p>
<p>–table-name frequent-sales \</p>
<p>–attribute-definitions AttributeName=dataset,AttributeType=S AttributeName=timestamp,AttributeType=S \</p>
<p>–key-schema AttributeName=dataset,KeyType=HASH AttributeName=timestamp,KeyType=RANGE \</p>
<p>–provisioned-throughput ReadCapacityUnits=1,WriteCapacityUnits=1</p>
<p>$ aws dynamodb list-tables</p>
<p>$ aws dynamodb delete-table –table-name frequent-sales</p>
<ul>
<li>Reading data from DynamoDB might not reflect the results of a recent write</li>
<li>Eventually Consistent Reads (default)
<ul>
<li>Response might include stale data</li>
<li>After short time, the response should return the latest data</li>
</ul></li>
<li>Strongly Consistent Reads
<ul>
<li>Response includes the most up-to-date data</li>
<li>A strongly consistent read might not be available if there is a network delay or outage
<ul>
<li>In this case, DynamoDB may return a server error (HTTP 500)</li>
</ul></li>
<li>Strongly consistent reads may have higher latency than eventually consistent reads</li>
<li>Strongly consistent reads are not supported on global secondary indexes</li>
</ul></li>
<li>Provisioned mode: specify the #reads and #writes per second
<ul>
<li>You have predictable application traffic or traffic ramps gradually</li>
<li>You can forecast capacity requirements to control costs</li>
</ul></li>
<li>One read capacity unit
<ul>
<li>One strongly consistent read per second, two eventually consistent reads per second</li>
<li>RCUs also depend on the item size (a read is up to 4 KB in size), if item size is 8 KB
<ul>
<li>2 RCUs to sustain one strongly consistent read per second</li>
<li>1 RCU if you choose eventually consistent reads</li>
</ul></li>
</ul></li>
<li>One write capacity unit represents one write per second for an item up to 1 KB in size</li>
</ul>
<p>Put a new item and get it back</p>
<p>$ aws dynamodb put-item –table-name frequent-sales –item ‘{“dataset”: {“S”: “sales”}, “timestamp”: {“S”: “1611226870”}, “bar”: {“S”: “foobar”}}’</p>
<p>$ aws dynamodb query –table-name frequent-sales –key-condition-expression “dataset =:n” –expression-attribute-values ‘{“:n”:{“S”:“sales”}}’</p>
</section>

<section id="lambda-create-a-function" class="title-slide slide level1 center">
<h1>Lambda: create a function</h1>

<img data-src="imgs/slides378.png" class="r-stretch"><p><a href="https://console.aws.amazon.com/lambda/home?region=us-east-1#/functions">https://console.aws.amazon.com/lambda/home?region=us-east-1#/functions</a></p>
</section>

<section id="lambda-attaching-a-role" class="title-slide slide level1 center">
<h1>Lambda: attaching a role</h1>
<p><img data-src="imgs/slides379.png"></p>
<p><img data-src="imgs/slides380.png"></p>
<p><img data-src="imgs/slides381.png"></p>
<p><img data-src="imgs/slides382.png"></p>
<p><img data-src="imgs/slides383.png"></p>
</section>

<section id="lambda-create-a-function-1" class="title-slide slide level1 center">
<h1>Lambda: create a function</h1>

<img data-src="imgs/slides384.png" class="r-stretch"><p><a href="https://console.aws.amazon.com/lambda/home?region=us-east-1#/functions">https://console.aws.amazon.com/lambda/home?region=us-east-1#/functions</a></p>
<ul>
<li>Manually creating the functions is cumbersome
<ul>
<li>We must copy and paste code</li>
<li>No automatic testing</li>
<li>No debugging</li>
<li>No IDE support (and not all languages are supported)</li>
</ul></li>
<li>Switch to IntelliJ IDEA + AWS Toolkit</li>
</ul>
</section>

<section id="aws-toolkit" class="title-slide slide level1 center">
<h1>AWS Toolkit</h1>
<ul>
<li>Get the latest IntelliJ IDEA</li>
<li>Install the <code>AWS Toolkit</code></li>
<li>Copy the credentialscp ~/.aws/credentials ~/.aws/config</li>
<li>Clone the repo git clone <a href="https://github.com/w4bo/bigdata-aws/">https://github.com/w4bo/bigdata-aws/</a></li>
<li>Import <code>lab01-lambda</code> as a Gradle project</li>
<li>Verify that the project builds./gradlew</li>
</ul>
<p><img data-src="imgs/slides385.png"></p>
<ul>
<li>Click on <code>AWS Explorer</code>
<ul>
<li>You can see the <code>helloworld</code> function</li>
<li>Plus <code>CloudWatch Logs</code> and <code>S3</code></li>
</ul></li>
</ul>
<p><img data-src="imgs/slides386.png"></p>
<ul>
<li>Test the existing code locally
<ul>
<li>With Gradle</li>
<li>Or with local Lambda execution</li>
</ul></li>
<li>Deploy a new Lambda function from the existing code
<ul>
<li>Right click on AWS Explorer &gt; Lambda</li>
<li>Select <code>Create new AWS Lambda...</code></li>
<li>Populate the settings</li>
<li><code>Create the function</code></li>
</ul></li>
</ul>
<p><img data-src="imgs/slides387.png"></p>
<p><a href="https://aws.amazon.com/lambda/pricing/">https://aws.amazon.com/lambda/pricing/</a></p>
<ul>
<li>Check the log for errors and pricing
<ul>
<li>AWS Toolkit &gt; CloudWatch Logs</li>
<li>Double click on the function name</li>
<li>Double click on the log entry</li>
</ul></li>
</ul>
<p><img data-src="imgs/slides388.png"></p>
<p><img data-src="imgs/slides389.png"></p>
</section>

<section id="data-pipeline-2" class="title-slide slide level1 center">
<h1>Data pipeline</h1>
<ul>
<li>Deploy and execute the HelloWorld.java lambda function</li>
<li>Given the created storage: S3 and DynamoDB
<ul>
<li>Deploy the function <code>FIM</code></li>
<li>Deploy the function <code>Preprocess</code></li>
<li>Run <code>ReadDataset.java</code></li>
<li>Check that the table <code>frequent-sales</code> has the FIs for the dataset <code>sales</code></li>
</ul></li>
<li>Some hints
<ul>
<li>Function names are case sensitive</li>
<li>Some function need more than 128MB of memory
<ul>
<li>Behold! The higher the RAM, the higher the costs</li>
</ul></li>
</ul></li>
</ul>
</section>

<section id="section-8" class="title-slide slide level1 center">
<h1></h1>
<p><img data-src="imgs/slides390.png"></p>
<p><img data-src="imgs/slides391.png"></p>
<div class="quarto-auto-generated-content">
<div class="footer footer-default">
<p>Matteo Francia - Big Data and Cloud Platforms (Module 2) - A.Y. 2024/25</p>
</div>
</div>
</section>
    </div>
  </div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="slides_files/libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="slides_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="slides_files/libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="slides_files/libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="slides_files/libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="slides_files/libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="slides_files/libs/revealjs/plugin/notes/notes.js"></script>
  <script src="slides_files/libs/revealjs/plugin/search/search.js"></script>
  <script src="slides_files/libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="slides_files/libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': true,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: true,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'bottom-right',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1100,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
        const config = {
          allowHTML: true,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start',
        };
        if (contentFn) {
          config.content = contentFn;
        }
        if (onTriggerFn) {
          config.onTrigger = onTriggerFn;
        }
        if (onUntriggerFn) {
          config.onUntrigger = onUntriggerFn;
        }
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          return note.innerHTML;
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    

</body></html>